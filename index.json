[{"content":"Docker 是一种广泛使用的容器化平台，它可以让开发者将应用程序和依赖打包到一个可移植的容器中，从而简化了应用程序的部署和管理。Docker Compose 是一个用于定义和运行多容器 Docker 应用程序的工具。本文将详细介绍如何在离线环境下安装 Docker 和 Docker Compose。\n准备工作 在开始安装之前，请确保您的系统满足以下要求：\nLinux 操作系统（本文以 CentOS 7 为例） 可以使用 root 用户或具有 sudo 权限的用户进行操作 已经下载了 Docker 和 Docker Compose 的二进制程序包 下载 Docker 二进制程序包 由于是离线安装，我们需要提前下载 Docker 的二进制程序包。您可以在有网络连接的机器上访问以下地址下载对应版本的程序包：\nhttps://download.docker.com/linux/static/stable/x86_64/docker-26.1.0.tgz 请将 x86_64 替换为您系统的实际架构，可以使用 uname -m 命令查看。\n安装 Docker 将下载好的 Docker 二进制程序包上传到目标机器上，并解压： tar -xvf docker-26.1.0.tgz 将 Docker 二进制文件移动到 /usr/local/bin 目录： mv docker/* /usr/local/bin/ 为 Docker 二进制文件创建软链接到 /usr/bin 目录： ln -s /usr/local/bin/docker /usr/bin/docker ln -s /usr/local/bin/dockerd /usr/bin/dockerd ln -s /usr/local/bin/docker-proxy /usr/bin/docker-proxy ln -s /usr/local/bin/docker-init /usr/bin/docker-init ln -s /usr/local/bin/ctr /usr/bin/ctr ln -s /usr/local/bin/runc /usr/bin/runc ln -s /usr/local/bin/containerd /usr/bin/containerd ln -s /usr/local/bin/containerd-shim-runc-v2 /usr/bin/containerd-shim-runc-v2 下载 Docker 的 systemd 服务文件： wget https://raw.githubusercontent.com/moby/moby/master/contrib/init/systemd/docker.service -O /etc/systemd/system/docker.service wget https://raw.githubusercontent.com/moby/moby/master/contrib/init/systemd/docker.target -O /etc/systemd/system/docker.target 下载 containerd 的 systemd 服务文件： wget https://raw.githubusercontent.com/containerd/containerd/main/containerd.service -O /etc/systemd/system/containerd.service 启用并启动 containerd 服务： systemctl enable --now containerd 启用并启动 Docker 服务： systemctl enable --now docker 安装 Docker Compose 下载 Docker Compose 二进制文件： curl -SL https://github.com/docker/compose/releases/download/v2.27.0/docker-compose-linux-x86_64 -o /usr/local/bin/docker-compose 请将 x86_64 替换为您系统的实际架构。\n为 Docker Compose 创建软链接到 /usr/bin 目录： ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose 为 Docker Compose 二进制文件添加执行权限： chmod +x /usr/local/bin/docker-compose 验证安装 安装完成后，可以使用以下命令验证 Docker 和 Docker Compose 是否安装成功：\ndocker version docker-compose version 如果能够看到 Docker 和 Docker Compose 的版本信息，说明安装成功。\n结语 本文详细介绍了如何在离线环境下安装 Docker 和 Docker Compose。通过下载 Docker 和 Docker Compose 的二进制程序包，并将其解压到指定目录，再配置 systemd 服务文件，最后启动 containerd 和 Docker 服务，就可以在离线环境下使用 Docker 和 Docker Compose 了。希望本文对您有所帮助，如有任何问题，欢迎留言讨论。\n","permalink":"https://mioto.me/posts/step-by-step-guide-to-offline-installation-of-docker-and-docker-compose/","summary":"Docker 是一种广泛使用的容器化平台，它可以让开发者将应用程序和依赖打包到一个可移植的容器中，从而简化了应用程序的部署和管理。Docker Compose 是一个用于定义和运行多容器 Docker 应用程序的工具。本文将详细介绍如何在离线环境下安装 Docker 和 Docker Compose。\n准备工作 在开始安装之前，请确保您的系统满足以下要求：\nLinux 操作系统（本文以 CentOS 7 为例） 可以使用 root 用户或具有 sudo 权限的用户进行操作 已经下载了 Docker 和 Docker Compose 的二进制程序包 下载 Docker 二进制程序包 由于是离线安装，我们需要提前下载 Docker 的二进制程序包。您可以在有网络连接的机器上访问以下地址下载对应版本的程序包：\nhttps://download.docker.com/linux/static/stable/x86_64/docker-26.1.0.tgz 请将 x86_64 替换为您系统的实际架构，可以使用 uname -m 命令查看。\n安装 Docker 将下载好的 Docker 二进制程序包上传到目标机器上，并解压： tar -xvf docker-26.1.0.tgz 将 Docker 二进制文件移动到 /usr/local/bin 目录： mv docker/* /usr/local/bin/ 为 Docker 二进制文件创建软链接到 /usr/bin 目录： ln -s /usr/local/bin/docker /usr/bin/docker ln -s /usr/local/bin/dockerd /usr/bin/dockerd ln -s /usr/local/bin/docker-proxy /usr/bin/docker-proxy ln -s /usr/local/bin/docker-init /usr/bin/docker-init ln -s /usr/local/bin/ctr /usr/bin/ctr ln -s /usr/local/bin/runc /usr/bin/runc ln -s /usr/local/bin/containerd /usr/bin/containerd ln -s /usr/local/bin/containerd-shim-runc-v2 /usr/bin/containerd-shim-runc-v2 下载 Docker 的 systemd 服务文件： wget https://raw.","title":"离线安装 Docker 和 Docker Compose 详细教程"},{"content":"本文旨在深入研究如何使用Go语言优化模拟数据生成性能。我们将介绍三个不同版本的代码实现，并详细分析它们的性能和优点。\n版本一：基础实现 首先，让我们来看看第一个版本的代码，这是一个基础实现，没有引入并发。以下是版本一的核心代码：\nfunc randomVersion1(labels []int) *strings.Builder { str := \u0026amp;strings.Builder{} for i := 0; i \u0026lt; len(labels); i++ { switch labels[i] { case 0: str.WriteString(strconv.Itoa(rand.Intn(2) - 1)) case 1: str.WriteString(fmt.Sprintf(\u0026#34;%.8f\u0026#34;, 0.1+rand.Float64()*(1-0.1))) } if i \u0026lt; len(labels)-1 { str.WriteString(\u0026#34;,\u0026#34;) } } return str } func TestVersion1(t *testing.T) { f, _ := os.OpenFile(filename, os.O_CREATE|os.O_RDWR|os.O_TRUNC, 0644) buf := bufio.NewWriter(f) s := time.Now() buf.WriteString(fmt.Sprintf(\u0026#34;%s\\n\u0026#34;, header)) for i := 0; i \u0026lt; 1000000; i++ { buf.WriteString(fmt.Sprintf(\u0026#34;%d,%s\\n\u0026#34;, i, randomVersion1(labels).String())) } fmt.Println(\u0026#34;version1 use time: \u0026#34;, time.Since(s)) } 版本一的特点： 使用 strings.Builder 和 bufio.Writer 进行字符串和文件操作，以提高性能。 利用 os.OpenFile 和 bufio.NewWriter 来进行文件操作，确保高效且安全。 版本二：引入并发 接下来，我们将介绍版本二的代码，它引入了并发处理，通过协程和通道来提高性能。以下是版本二的核心代码示例：\nfunc randomVersion2(labels []int, columnCh chan *strings.Builder) { str := \u0026amp;strings.Builder{} for i := 0; i \u0026lt; len(labels); i++ { switch labels[i] { case 0: str.WriteString(strconv.Itoa(rand.Intn(2) - 1)) case 1: str.WriteString(fmt.Sprintf(\u0026#34;%.8f\u0026#34;, 0.1+rand.Float64()*(1-0.1))) } if i \u0026lt; len(labels)-1 { str.WriteString(\u0026#34;,\u0026#34;) } } columnCh \u0026lt;- str } func TestVersion2(t *testing.T) { f, _ := os.OpenFile(filename, os.O_CREATE|os.O_RDWR|os.O_TRUNC, 0644) buf := bufio.NewWriter(f) s := time.Now() buf.WriteString(fmt.Sprintf(\u0026#34;%s\\n\u0026#34;, header)) columCh := make(chan *strings.Builder, 2000) countCh := make(chan int) wg := sync.WaitGroup{} worker := func(n chan int) { for { _, ok := \u0026lt;-n if !ok { wg.Done() return } randomVersion2(labels, columCh) } } for i := 0; i \u0026lt; runtime.NumCPU()*2; i++ { wg.Add(1) go worker(countCh) } go func() { for i := 0; i \u0026lt; 1000000; i++ { countCh \u0026lt;- i } close(countCh) }() for i := 0; i \u0026lt; 1000000; i++ { colum, ok := \u0026lt;-columCh if !ok { return } buf.WriteString(fmt.Sprintf(\u0026#34;%d,%s\\n\u0026#34;, i, colum.String())) } fmt.Println(\u0026#34;version2 use time: \u0026#34;, time.Since(s)) } 版本二的优势 卓越的性能：通过并发，版本二在多核 CPU 上表现出色。 最大程度地利用系统资源：根据CPU核心数创建工作线程，更有效地管理资源。 优越的扩展性：使用工作队列和协程模型，易于扩展。 精确的任务管理：结合 sync.WaitGroup 和通道，确保任务的准确执行。 增强的吞吐量：通过使用缓冲通道，提高性能。 版本三：进一步优化 版本三对性能和内存效率进行了更深层次的优化，引入了自定义随机源和对象池。以下是版本三的核心代码示例：\ntype randSource struct { rand.Source } func (r *randSource) Float64() float64 { // Change from Go 1 -- make results be uniform. return (float64(r.Int63() \u0026gt;\u0026gt; 10)) * (1.0 / 9007199254740992.0) } func (r *randSource) Int() int64 { // Change from Go 1 -- make results be uniform. return r.Int63() % 2 } func randomVersion2(labels []int, columnCh chan *strings.Builder) { str := \u0026amp;strings.Builder{} for i := 0; i \u0026lt; len(labels); i++ { switch labels[i] { case 0: str.WriteString(strconv.Itoa(rand.Intn(2) - 1)) case 1: str.WriteString(fmt.Sprintf(\u0026#34;%.8f\u0026#34;, 0.1+rand.Float64()*(1-0.1))) } if i \u0026lt; len(labels)-1 { str.WriteString(\u0026#34;,\u0026#34;) } } columnCh \u0026lt;- str } func TestVersion3(t *testing.T) { poolBuilder := sync.Pool{ New: func() interface{} { return bytes.NewBuffer(make([]byte, 0, 4096)) }, } poolBuf := sync.Pool{ New: func() interface{} { return make([]byte, 0, 8) }, } wg := sync.WaitGroup{} count := 1000000 countCh := make(chan int) columCh := make(chan *bytes.Buffer, 2000) random := func(labels []int, r *randSource, columCh chan *bytes.Buffer) { str := poolBuilder.Get().(*bytes.Buffer) buf := poolBuf.Get().([]byte) for i := 0; i \u0026lt; len(labels); i++ { switch labels[i] { case 0: str.Write(strconv.AppendInt(buf, r.Int(), 10)) case 1: str.Write(strconv.AppendFloat(buf, r.Float64(), \u0026#39;f\u0026#39;, 8, 64)) } if i \u0026lt; len(labels)-1 { str.WriteByte(\u0026#39;,\u0026#39;) } } poolBuf.Put(buf) columCh \u0026lt;- str } f, _ := os.OpenFile(filename, os.O_CREATE|os.O_RDWR|os.O_TRUNC, 0644) buf := bufio.NewWriter(f) s := time.Now() buf.WriteString(fmt.Sprintf(\u0026#34;%s\\n\u0026#34;, header)) worker := func(n chan int) { r := \u0026amp;randSource{ Source: rand.NewSource(rand.Int63()), } for { _, ok := \u0026lt;-n if !ok { wg.Done() return } random(labels, r, columCh) } } for i := 0; i \u0026lt; runtime.NumCPU()*2; i++ { wg.Add(1) go worker(countCh) } for i := 0; i \u0026lt; runtime.NumCPU()*2; i++ { wg.Add(1) go worker(countCh) } go func() { for i := 0; i \u0026lt; count; i++ { countCh \u0026lt;- i } close(countCh) }() for i := 0; i \u0026lt; count; i++ { colum, ok := \u0026lt;-columCh if !ok { return } b := poolBuf.Get().([]byte) buf.Write(strconv.AppendInt(b, int64(i), 10)) buf.WriteByte(\u0026#39;,\u0026#39;) buf.Write(colum.Bytes()) buf.WriteByte(\u0026#39;\\n\u0026#39;) colum.Reset() poolBuilder.Put(colum) poolBuf.Put(b) } buf.Flush() f.Close() fmt.Println(\u0026#34;version3 use time:\u0026#34;, time.Since(s)) } Go代码：TestVersion3 函数与 randomVersion2 函数的区别和优势 减少内存占用：使用 sync.Pool 重用内存，有效降低GC负担。 改进性能：借助字节操作和缓冲，提高性能。 更高的并发性：通过增加工作线程数量，充分发挥多核CPU的威力。 更精确的随机数生成：自定义随机数源生成更均匀的随机数，无需竞争全局锁。 优化的代码结构：将随机数生成逻辑封装在函数中，提高代码的可维护性和可重用性。 更快的数据写入：借助字节操作和缓冲，提高数据写入速度。 全局锁的区别：在版本三中，我们引入了自定义的 randSource 结构，并重写了 Float64 和 Int 方法，以自定义随机数生成的方式。通过这种方式，我们无需竞争 rand 包的全局锁，从而避免了在多线程环境下可能出现的性能瓶颈。 通过这些改进，TestVersion3在性能、内存效率和可扩展性方面都有明显的优势。\n","permalink":"https://mioto.me/posts/use-go-to-generate-millions-of-mock-data-generation-per-second/","summary":"本文旨在深入研究如何使用Go语言优化模拟数据生成性能。我们将介绍三个不同版本的代码实现，并详细分析它们的性能和优点。\n版本一：基础实现 首先，让我们来看看第一个版本的代码，这是一个基础实现，没有引入并发。以下是版本一的核心代码：\nfunc randomVersion1(labels []int) *strings.Builder { str := \u0026amp;strings.Builder{} for i := 0; i \u0026lt; len(labels); i++ { switch labels[i] { case 0: str.WriteString(strconv.Itoa(rand.Intn(2) - 1)) case 1: str.WriteString(fmt.Sprintf(\u0026#34;%.8f\u0026#34;, 0.1+rand.Float64()*(1-0.1))) } if i \u0026lt; len(labels)-1 { str.WriteString(\u0026#34;,\u0026#34;) } } return str } func TestVersion1(t *testing.T) { f, _ := os.OpenFile(filename, os.O_CREATE|os.O_RDWR|os.O_TRUNC, 0644) buf := bufio.NewWriter(f) s := time.Now() buf.WriteString(fmt.Sprintf(\u0026#34;%s\\n\u0026#34;, header)) for i := 0; i \u0026lt; 1000000; i++ { buf.","title":"使用 Go 语言每秒百万量级的模拟数据生成优化总结"},{"content":"1Password 太贵了，$2.99 和 $4.99 分别对应单人和家庭套餐！！！现在的 1password 收费模式也转向了订阅付费，同时架构也转向了 CS 架构，所以本质上和 Bitwarden 也差不多了。\nBitwarden 是一款自由且开源的密码管理服务，用户可在加密的保管库中存储敏感信息（例如网站登录凭据）。Bitwarden 平台提供有多种客户端应用程序，包括网页用户界面、桌面应用，浏览器扩展、移动应用以及命令行界面。Bitwarden 提供云端托管服务，并支持自行部署解决方案。 \u0026ndash; 维基百科\nBitwarden 安全原则 端到端加密：所有的密码和私人数据都通过 AES-256 进行加密。所有的加密密钥均在客户端生成和管理，加密过程均在客户端完成。 零知识加密：Bitwarden 服务端不存储你的主密钥以及加密密钥，你的数据使用你的个人邮箱以及主密钥进行加密。 源代码可用：代码完全开源，并可自行编译使用。 隐私设计：所有登录信息在你的设备中进行加密后在存储到 Bitwarden服务器的保管库中，并将保管库同步到所用你的设备，你的数据采用 AES-CBC 256 位加密、加盐散列和 PBKDF2 SHA-256 进行密封。 安全审计与合规：Open source and third-party audited, Bitwarden complies with AICPA SOC2 Type 2 / Privacy Shield, GDPR, and CCPA regulations. Bitwarden 核心概念 主密钥（Master Key） 最核心的密钥，所有后续的密钥和加密密钥均通过主密钥派生，主密钥也是解密所有登录信息以及私人数据的唯一密钥，丢失会导致无法获取已经保存的数据，泄漏将导致所有的数据公之于众。所以主密钥复杂点毕竟你所有的密钥都不需要记了，主密钥在特别简单岂不是很危险？\n伪代码：\nmasterKeyHash = pbkdf2(masterKey, email) 主密钥哈希 用来鉴权登录，身份认证，从 Bitwarden 服务端获取密码保管库。\n伪代码：\nmasterKeyHashHash = pbkdf2(masterKeyHash, masterKey) 扩展主密钥（Stretched Master Key） 通过主密钥派生出加密密钥和签名密钥，并将两个密钥拼接成扩展主密钥。\n扩展主密钥会基于 AES-CBC-256 算法加密一个用来加密你所有数据的对称密钥，所以加密密钥只能通过扩展主密钥解密获取，而扩展密钥又是基于主密钥派生而来。\n伪代码：\nencKey = hkdf.expand(masterKeyHash, \u0026#34;enc\u0026#34;) macKey = hkdf.expand(masterKeyHash, \u0026#34;mac\u0026#34;) stretchedMasterKey = append(encKey, macKey) 对称密钥（Symmetric Key） 用来对所有数据加密的加密密钥。\n加密密钥通过 CSPRNG（Cryptographically Secure Pseudo-Random Number Generator）伪随机数产生器生成。包含加密密钥和签名密钥，每个 key 长度均为 256 bits。\n伪代码:\nencKey = CSPRNG(256) macKey = CSPRNG(256) symmetricKey = append(encKey, macKey) 对称密钥会被扩展主密钥加密后存储到 Bitwarden 服务器，用户身份认证成功后会返回加密数据到客户端，客户端可以通过扩展主密钥解密出加密密钥并用来解密其他的数据。\n伪代码：\nprotectedSymmetricKey = append(encryptionType, \u0026#34;.\u0026#34;, base64(iv), \u0026#34;|\u0026#34;, base64(ciphertext), \u0026#34;|\u0026#34;, base64(signtext)) // example: 2.4GQFqhW/5oTd201fW1ypng==|PUTTd9HqXIyYTPcqkzEQrUY0C8/AiuRgRiA3ayJ1hKA=|BVpzevtEsMrCq0x3oFuARvWixusdEtdyYTaOgoGycgI= 非对称密钥（RSA Key Pair） 原理基本同上，主要用于组织共享密钥库的加解密，这里就不详细介绍了。\n简述原理 相信看了以上核心概念的朋友们已经大概理解的 Bitwarden 的设计理念了。\n所有的密钥都只存在于当前客户端的内存中，主密钥还存在于你的脑袋里，所有的加密解密都在客户端中完成，服务端仅存储加密后的数据。\n客户端到服务端 主密钥 \u0026ndash;（派生）\u0026ndash;\u0026gt; 扩展主密钥 扩展主密钥 \u0026ndash;（加密）\u0026ndash;\u0026gt; 随机生成的加密密钥（账户创建之初生成后续都是使用） 扩展主密钥 \u0026ndash;（加密）\u0026ndash;\u0026gt; 随机生成的非对称密钥（账户创建之初生成后续都是使用） 加密后的加密密钥和非对称密钥 \u0026ndash;（存储）\u0026ndash;\u0026gt; Bitwarden 服务器 加密密钥 \u0026ndash;（加密）\u0026ndash;\u0026gt; 登录信息、安全笔记、信用卡、身份等数据 加密数据 \u0026ndash;（存储）\u0026ndash;\u0026gt; Bitwarden 服务器 服务端到客户端 主密钥哈希 \u0026ndash;（身份认证）\u0026ndash;\u0026gt; 服务端 获取加密后的加密密钥和非对称密钥 \u0026ndash;（解密）\u0026ndash;\u0026gt; 通过扩展主密钥解密对应的数据放到内存中 获取加密数据 \u0026ndash;（解密）\u0026ndash;\u0026gt; 通过加密密钥以及非对称密钥解密所需要使用的数据 写在最后 如果主密钥不慎泄漏需要及时更换主密钥以及轮换加密密钥（主密钥泄漏会导致加密密钥不安全），轮换加密密钥会重新解加密所有的数据。\n参考资料 https://bitwarden.com/help/article/bitwarden-security-white-paper https://bitwarden.com/help/crypto.html ","permalink":"https://mioto.me/posts/bitwarden-security-white-paper/","summary":"1Password 太贵了，$2.99 和 $4.99 分别对应单人和家庭套餐！！！现在的 1password 收费模式也转向了订阅付费，同时架构也转向了 CS 架构，所以本质上和 Bitwarden 也差不多了。\nBitwarden 是一款自由且开源的密码管理服务，用户可在加密的保管库中存储敏感信息（例如网站登录凭据）。Bitwarden 平台提供有多种客户端应用程序，包括网页用户界面、桌面应用，浏览器扩展、移动应用以及命令行界面。Bitwarden 提供云端托管服务，并支持自行部署解决方案。 \u0026ndash; 维基百科\nBitwarden 安全原则 端到端加密：所有的密码和私人数据都通过 AES-256 进行加密。所有的加密密钥均在客户端生成和管理，加密过程均在客户端完成。 零知识加密：Bitwarden 服务端不存储你的主密钥以及加密密钥，你的数据使用你的个人邮箱以及主密钥进行加密。 源代码可用：代码完全开源，并可自行编译使用。 隐私设计：所有登录信息在你的设备中进行加密后在存储到 Bitwarden服务器的保管库中，并将保管库同步到所用你的设备，你的数据采用 AES-CBC 256 位加密、加盐散列和 PBKDF2 SHA-256 进行密封。 安全审计与合规：Open source and third-party audited, Bitwarden complies with AICPA SOC2 Type 2 / Privacy Shield, GDPR, and CCPA regulations. Bitwarden 核心概念 主密钥（Master Key） 最核心的密钥，所有后续的密钥和加密密钥均通过主密钥派生，主密钥也是解密所有登录信息以及私人数据的唯一密钥，丢失会导致无法获取已经保存的数据，泄漏将导致所有的数据公之于众。所以主密钥复杂点毕竟你所有的密钥都不需要记了，主密钥在特别简单岂不是很危险？\n伪代码：\nmasterKeyHash = pbkdf2(masterKey, email) 主密钥哈希 用来鉴权登录，身份认证，从 Bitwarden 服务端获取密码保管库。\n伪代码：\nmasterKeyHashHash = pbkdf2(masterKeyHash, masterKey) 扩展主密钥（Stretched Master Key） 通过主密钥派生出加密密钥和签名密钥，并将两个密钥拼接成扩展主密钥。","title":"Bitwarden 白皮书简析"},{"content":"只是写自己接手的项目迭代过程，单纯的记录。\n这个项目的目的是为了控制电话营销的投诉率，前前后后搞了也有小一年了，大的迭代基本上有三次，这篇文章主要就是记录一下迭代的过程以及自己的想法。\n项目伊始 需求：获取 SIP 协议中的手机号信息，去特定的网站查询该手机号在不在投诉黑名单中，并将命中的手机号缓存。\n开始的需求很简单，但是本身并不是这个行业的，对 SIP 协议也不是很了解，看了看资料用了最简单的方法实现了他的需求。\n实现后的流程如下：\n遇到的问题：\n由于对 SIP 不了解，所以代码只是单纯的对 SIP 协议做转发，导致中间层只能和前端在同一台机子上。 由于他的前端是破解版本，所以导致系统版本特别低（Centos5）都已经被弃用了，所以最开始设想的中间层运行在 docker 中也随之破灭。 以上问题间接的导致了我需要在他出问题的时候排查和我无关的错误，极大的浪费了个人时间。 第二阶段 由于运行期间间接产生的数据，如自己被投诉的号码，以及明确不愿意在接听到类似电话的人，以及低素质的人。\n所以他有了自己的私有数据，但是项目的第一阶段并没有这部分的功能，于是有了第二期的需求。\n需求如下：\n可以上传自己的黑名单。 可以上传自己的白名单。 可以设定拦截时间（请求过的数据在规定的时间不允许第二次请求）。 第二期的需求本质就是添加自己的黑名单数据，对 SIP 这快的逻辑改动并不大，所以第二期从简实现。\n实现后流程如下：\n可以看出私有数据服务被单独放到了一台机子，以 RESTful API 的形式给原中间层提供数据拦截状态。\n所以阶段二对中间层还是有稍微细小的改动的，但是并没有解决阶段一导致的问题。\n阶段二中的片段，由于他的需求一直在增加，导致阶段二变的异常复杂，以下是架构图：\n由于配置的繁琐，以及加入了一些新的脱敏数据，出现了一些新的需求，如，满足特定规则后才转发。\n介于阶段一，二的复杂程度实在不想基于原先的设计思想继续追加了，所以重新设计了现有的架构。\n新设计的架构解决了原先的问题。\n必须部署在一台机子上。 由于不完善的 SIP 实现导致处理流程异常耗时（前端的 3 秒 Timeout，3次重试机制）。 无限的堆叠原有服务导致项目结构异常复杂，难以维护。 中间层和和前端必须部署在一起，任何问题都需要登录机器查看，排查问题麻烦（前端属于破解版，系统又是 CentOS 5）。 以下是第三阶段的架构图：\n以上架构的优势：\n完全基于 K8S 部署，横向扩容，高可用。 我负责的模块完全独立于他的前后端，再也不需要因为前后端的机子出现问题，导致的被迫介入。 规则可配，插件可扩展，基本满足后续的需求。 前后端可 一对多，多对多，多对一，SIP 转发层基本实现了 SIP 协议的真正转发。 第四阶段（规划） 基于 TensorFlow 替换规则的手动设置！！！！\n以上 以上算是对接手这个项目的总结，在项目期间也确实接触了好多新的知识。\n如 GRPC 并不能在 K8S Service 层做到负载均衡，需要 Service Mesh 的介入（Linkerd2 等）。\n唉，总之工作好累，不想干活，不想学习！！！！\n","permalink":"https://mioto.me/posts/iteration-of-the-project/","summary":"只是写自己接手的项目迭代过程，单纯的记录。\n这个项目的目的是为了控制电话营销的投诉率，前前后后搞了也有小一年了，大的迭代基本上有三次，这篇文章主要就是记录一下迭代的过程以及自己的想法。\n项目伊始 需求：获取 SIP 协议中的手机号信息，去特定的网站查询该手机号在不在投诉黑名单中，并将命中的手机号缓存。\n开始的需求很简单，但是本身并不是这个行业的，对 SIP 协议也不是很了解，看了看资料用了最简单的方法实现了他的需求。\n实现后的流程如下：\n遇到的问题：\n由于对 SIP 不了解，所以代码只是单纯的对 SIP 协议做转发，导致中间层只能和前端在同一台机子上。 由于他的前端是破解版本，所以导致系统版本特别低（Centos5）都已经被弃用了，所以最开始设想的中间层运行在 docker 中也随之破灭。 以上问题间接的导致了我需要在他出问题的时候排查和我无关的错误，极大的浪费了个人时间。 第二阶段 由于运行期间间接产生的数据，如自己被投诉的号码，以及明确不愿意在接听到类似电话的人，以及低素质的人。\n所以他有了自己的私有数据，但是项目的第一阶段并没有这部分的功能，于是有了第二期的需求。\n需求如下：\n可以上传自己的黑名单。 可以上传自己的白名单。 可以设定拦截时间（请求过的数据在规定的时间不允许第二次请求）。 第二期的需求本质就是添加自己的黑名单数据，对 SIP 这快的逻辑改动并不大，所以第二期从简实现。\n实现后流程如下：\n可以看出私有数据服务被单独放到了一台机子，以 RESTful API 的形式给原中间层提供数据拦截状态。\n所以阶段二对中间层还是有稍微细小的改动的，但是并没有解决阶段一导致的问题。\n阶段二中的片段，由于他的需求一直在增加，导致阶段二变的异常复杂，以下是架构图：\n由于配置的繁琐，以及加入了一些新的脱敏数据，出现了一些新的需求，如，满足特定规则后才转发。\n介于阶段一，二的复杂程度实在不想基于原先的设计思想继续追加了，所以重新设计了现有的架构。\n新设计的架构解决了原先的问题。\n必须部署在一台机子上。 由于不完善的 SIP 实现导致处理流程异常耗时（前端的 3 秒 Timeout，3次重试机制）。 无限的堆叠原有服务导致项目结构异常复杂，难以维护。 中间层和和前端必须部署在一起，任何问题都需要登录机器查看，排查问题麻烦（前端属于破解版，系统又是 CentOS 5）。 以下是第三阶段的架构图：\n以上架构的优势：\n完全基于 K8S 部署，横向扩容，高可用。 我负责的模块完全独立于他的前后端，再也不需要因为前后端的机子出现问题，导致的被迫介入。 规则可配，插件可扩展，基本满足后续的需求。 前后端可 一对多，多对多，多对一，SIP 转发层基本实现了 SIP 协议的真正转发。 第四阶段（规划） 基于 TensorFlow 替换规则的手动设置！！！！\n以上 以上算是对接手这个项目的总结，在项目期间也确实接触了好多新的知识。\n如 GRPC 并不能在 K8S Service 层做到负载均衡，需要 Service Mesh 的介入（Linkerd2 等）。","title":"项目的迭代升级"},{"content":"2020 年，多灾多难的一年，戴了一年的口罩，过年也没回家，相比上一年并没有获得很大的进步，相反体重继续走高涨幅 3.9% 。\n工作 2020年8月加入了联通大数据，继续做着区块链方向，但是不做交付相关了，转向了 BaaS 平台，工资也小有涨幅，这里要感谢我的同事然而他并不活跃在社交网站就不 @他 了。\n学习 在前半年继续较为深入的了解了 Hyperledger Fabric 共识相关的底层实现，也写下了几篇自认为有用文章。 开了个 Fabric BaaS 的坑 Alkaid，但是后面慢慢的就没时间更新了（理直气壮）。 开始了新公司的工作，完成平台的区块链 BaaS。 朋友开了新坑还是跟 VOIP 有关，做了个稍微有点大的项目，预计 TPS 在 500/s 左右，数据量大概有个几亿的数据。 建了个 K8S 集群，搞了个高可用的 Mongo Sharded Cluster 集群。 研究了 Makefile 的编写。 看了看 Plan9 的汇编。 文章 今年共水了 9 篇文章。\n回顾 2019 Fabric 中 etcdraft 共识讲解 基于 Windows 的开发环境 Go 删除 Slice 中的某一个值 Hyperledger Fabric peer block 的交付流程详解 Hyperledger Fabric 加入通道时遇到 channel doesn\u0026rsquo;t exist 问题 神经网络的数据基础 Go HTTP Response 写超时导致的 EOF 错误 Plan9 汇编入门讲解 B站 还是晚上看视频，看的最多相关的视频是 彩虹六号 嗯，是个不错的游戏。\n今年一空看了 54 部番，相比去年确实少了好多。\nB站开始给我推跳舞的小姐姐了！！！\n关注的 UP 主 B站 硬核的半佛仙人：骚话连篇，还挺有意思。 B站 暴躁的仙人JUMP：同上，同一个人。 B站 吟游诗人基德：科普 UP，都是些很有意思的话题。 B站 波士顿圆脸 Youtube 波士顿自干五：圆胖子，自干五，主要都是在打脸西方，以及最新疫情，不喜欢可以不关注。 Youtube 理科男士K一米 同上，不喜欢可以不关注。 其他 买了台主机，性能够用。\n入坑彩虹六号，很不错的恐怖游戏。\n换了手机 iPhone 12 mini，握持感很好。\n入了图马斯特 T300 RS + TH8A 手排，开开赛车。\n以上！\n","permalink":"https://mioto.me/posts/2020review/","summary":"2020 年，多灾多难的一年，戴了一年的口罩，过年也没回家，相比上一年并没有获得很大的进步，相反体重继续走高涨幅 3.9% 。\n工作 2020年8月加入了联通大数据，继续做着区块链方向，但是不做交付相关了，转向了 BaaS 平台，工资也小有涨幅，这里要感谢我的同事然而他并不活跃在社交网站就不 @他 了。\n学习 在前半年继续较为深入的了解了 Hyperledger Fabric 共识相关的底层实现，也写下了几篇自认为有用文章。 开了个 Fabric BaaS 的坑 Alkaid，但是后面慢慢的就没时间更新了（理直气壮）。 开始了新公司的工作，完成平台的区块链 BaaS。 朋友开了新坑还是跟 VOIP 有关，做了个稍微有点大的项目，预计 TPS 在 500/s 左右，数据量大概有个几亿的数据。 建了个 K8S 集群，搞了个高可用的 Mongo Sharded Cluster 集群。 研究了 Makefile 的编写。 看了看 Plan9 的汇编。 文章 今年共水了 9 篇文章。\n回顾 2019 Fabric 中 etcdraft 共识讲解 基于 Windows 的开发环境 Go 删除 Slice 中的某一个值 Hyperledger Fabric peer block 的交付流程详解 Hyperledger Fabric 加入通道时遇到 channel doesn\u0026rsquo;t exist 问题 神经网络的数据基础 Go HTTP Response 写超时导致的 EOF 错误 Plan9 汇编入门讲解 B站 还是晚上看视频，看的最多相关的视频是 彩虹六号 嗯，是个不错的游戏。","title":"回顾 2020"},{"content":"为什么要看 Plan9 汇编？如果你是 Go 开发者，去学习和理解一下 Plan9 是很有必要的，因为它可以解决你对一段代码的理解（为什么这样不行？那样却可以？）。\nPlan9 不同于 AT\u0026amp;T 和 Intel 汇编器，但是懂这两个汇编语法的话对理解 Plan9 还是有很大帮助的。\n疑惑 // 为什么这个函数的返回值会是 -1 func demo1() int { ret := -1 defer func() { ret = 1 }() return ret } // output: -1 // 为什么这个函数的返回值会是 1 func demo2() (ret int) { defer func() { ret = 1 }() return ret } // output: 1 相信大部分人都看过类似的解答，demo1 中是临时变量导致的，而 demo2 中没有临时变量，这是最终结果。\n在汇编层面到底做了什么？本文将会探讨这个问题。（本文所使用的平台是 MacOS AMD64）不同的平台指令集和寄存器都不一样。\n基础 通用寄存器 下面是通用通用寄存器的名字在 IA64 和 plan9 中的对应关系：\nIA64 RAX RBX RCX RDX RDI RSI RBP RSP R8 R9 R10 R11 R12 R13 R14 RIP Plan9 AX BX CX DX DI SI BP SP R8 R9 R10 R11 R12 R13 R14 PC 应用代码层面会用到的通用寄存器主要是： AX, BX, CX, DX, DI, SI, R8~R15 这 14 个寄存器，虽然 BP 和 SP 也可以用，不过 BP 和 SP 会被用来管理栈顶和栈底，最好不要拿来进行运算。\nPlan9 汇编的操作数方向和 Intel 汇编相反的，与 AT\u0026amp;T 类似。\n伪寄存器 Go 汇编引入了 4 个伪寄存器，官方定义如下：\nFP: Frame pointer: arguments and locals. PC: Program counter: jumps and branches. SB: Static base pointer: global symbols. SP: Stack pointer: top of stack. 以下针对 FP，SP 做一些描述：\nFP：使用形式如 symbol+offset(FP) 的方式，引用函数的输入参数。eg：first_arg+0(FP)，second_arg+8(FP) SP：SP 是有对应的寄存器的，所以区分 SP 到底是指硬件 SP 还是指虚拟寄存器，需要以特定的格式来区分。eg：symbol+offset(SP) 则表示伪寄存器 SP。eg：offset(SP) 则表示硬件 SP。 变量声明 使用 DATA 结合 GLOBL 来定义一个变量。\nDATA\tsymbol+offset(SB)/width, value 使用 GLOBL 指令将变量声明为 global，额外接收两个参数，一个是 flag，另一个是变量的总大小。\nGLOBL divtab(SB), RODATA, $8 GLOBL 必须跟在 DATA 指令之后，下面是一个定义了多个 readonly 的全局变量的完整例子：\nDATA pi+0(SB)/8, $3.1415926 GLOBL pi(SB), RODATA, $8 在全局变量中定义数组，字符串，这时候就需要添加 \u0026lt;\u0026gt; ，\u0026lt;\u0026gt; 符号可以使变量使用偏移量操作。例子：\nDATA array\u0026lt;\u0026gt;+0(SB)/8, $1 DATA array\u0026lt;\u0026gt;+8(SB)/8, $2 通常建议直接使用 \u0026lt;\u0026gt; 进行变量声明。\n函数声明 // 函数声明 // 该声明一般写在任意一个 .go 文件中，例如：add.go func add(a, b int) int // 函数实现 // 该实现一般写在与声明同名的 _{Arch}.s 文件中，例如：add_amd64.s TEXT pkgname·add(SB), NOSPLIT, $0-16 MOVQ a+0(FP), AX MOVQ a+8(FP), BX ADDQ AX, BX MOVQ BX, ret+16(FP) RET pkgname 可以不写，一般都是不写的，可以参考 go 的源码， 另外 add 前的 · 不是 .\n参数及返回值大小 | TEXT pkgname·add(SB),NOSPLIT,$0-16 | | | 包名 函数名 栈帧大小(局部变量+可能需要的额外调用函数的参数空间的总大小， 但不包括调用其它函数时的 ret address 的大小) 以上使用的 RODATA，NOSPLIT flag，还有其他的值，可以参考：https://golang.org/doc/asm#directives，\n务必注意：对于编译输出 go tool compile -S / go tool objdump 的代码来讲，目前所有的 SP 都是硬件寄存器 SP，无论是否带 symbol。\n以下为上图的栈结构示意图，由于没有临时变量，所以伪 SP 和 硬件 SP 在同一个位置。\n+------------------+ | return parameter | +------------------+ | parameter b | +------------------+ | parameter a | \u0026lt;-- pseudo FP addr +------------------+ | caller ret addr | \u0026lt;-- pseudo SP addr and hardware SP addr +------------------+ 分析 编译 / 反编译 很多时候我们无法确定一块代码是如何执行的，需要通过生成汇编、反汇编来研究\n// 编译 go build -gcflags=\u0026#34;-S\u0026#34; go tool compile -S hello.go go tool compile -N -S hello.go // 禁止优化 // 反编译 go tool objdump \u0026lt;binary\u0026gt; 基础已经介绍的差不多了，接下来就是深究这两段代码的区别。\n// go tool compile -S demo1.go func demo1() int { ret := -1 defer func() { ret = 1 }() return ret } // 编译的汇编 demo1 部分代码 \u0026#34;\u0026#34;.demo1 STEXT size=158 args=0x8 locals=0x30 0x0000 00000 (.\\scratch.go:5) TEXT \u0026#34;\u0026#34;.demo1(SB), ABIInternal, $48-8 // 栈的初始化操作，以及 GC相关的标记等等操作，有兴趣的可以自己研究以下。 ... // 15(SP) 不知道为什么要操作这个，望大佬解释，本人猜测可能跟 deferreturn 有关。 0x002c 00044 (.\\scratch.go:5) MOVB $0, \u0026#34;\u0026#34;..autotmp_3+15(SP) // 这里对 56(SP) 地址进行了赋值操作写了个 0，这个位置其实是返回值地址 0x0031 00049 (.\\scratch.go:5) MOVQ $0, \u0026#34;\u0026#34;.~r0+56(SP) // 16(SP) 临时变量 ret，将 -1 写入到了栈中。 0x003a 00058 (.\\scratch.go:6) MOVQ $-1, \u0026#34;\u0026#34;.ret+16(SP) // 猜测与 deferreturn 有关。 0x0043 00067 (.\\scratch.go:7) LEAQ \u0026#34;\u0026#34;.demo1.func1·f(SB), AX 0x004a 00074 (.\\scratch.go:7) MOVQ AX, \u0026#34;\u0026#34;..autotmp_4+32(SP) // 将 16(SP) 的地址给了 AX 寄存器，这个地址里存的是 -1 0x004f 00079 (.\\scratch.go:7) LEAQ \u0026#34;\u0026#34;.ret+16(SP), AX // 将 AX 寄存器里的 16(SP) 的地址给了 24(SP) 0x0054 00084 (.\\scratch.go:7) MOVQ AX, \u0026#34;\u0026#34;..autotmp_5+24(SP) 0x0059 00089 (.\\scratch.go:7) MOVB $1, \u0026#34;\u0026#34;..autotmp_3+15(SP) // 将 16(SP) 的值给了 AX 寄存器，这个地址里存的是 -1 0x005e 00094 (.\\scratch.go:10) MOVQ \u0026#34;\u0026#34;.ret+16(SP), AX // 将 AX 的值给了 56(SP), 56(SP) 上面说过了是返回值地址， 所以当前的返回值是 -1 // 这里也是最后一次操作 56(SP)，所以最终的返回值是 -1 0x0063 00099 (.\\scratch.go:10) MOVQ AX, \u0026#34;\u0026#34;.~r0+56(SP) 0x0068 00104 (.\\scratch.go:10) MOVB $0, \u0026#34;\u0026#34;..autotmp_3+15(SP) // 24(SP) 的值给了 AX，24(SP) 存储的是 16(SP) 的地址， 也就是临时变量的地址 0x006d 00109 (.\\scratch.go:10) MOVQ \u0026#34;\u0026#34;..autotmp_5+24(SP), AX // 将 AX 的值给了 0(SP)， 也就是将 16(SP) 的地址给了 0(SP) // 这里可以 0(SP) 为调用 demo1.func1 的入参 0x0072 00114 (.\\scratch.go:10) MOVQ AX, (SP) 0x0076 00118 (.\\scratch.go:10) PCDATA $1, $1 // 调用 demo1.func1 0x0076 00118 (.\\scratch.go:10) CALL \u0026#34;\u0026#34;.demo1.func1(SB) 0x007b 00123 (.\\scratch.go:10) MOVQ 40(SP), BP 0x0080 00128 (.\\scratch.go:10) ADDQ $48, SP 0x0084 00132 (.\\scratch.go:10) RET 0x0085 00133 (.\\scratch.go:10) CALL runtime.deferreturn(SB) 0x008a 00138 (.\\scratch.go:10) MOVQ 40(SP), BP 0x008f 00143 (.\\scratch.go:10) ADDQ $48, SP 0x0093 00147 (.\\scratch.go:10) RET 0x0094 00148 (.\\scratch.go:10) NOP 0x0094 00148 (.\\scratch.go:5) PCDATA $1, $-1 0x0094 00148 (.\\scratch.go:5) PCDATA $0, $-2 0x0094 00148 (.\\scratch.go:5) CALL runtime.morestack_noctxt(SB) 0x0099 00153 (.\\scratch.go:5) PCDATA $0, $-1 0x0099 00153 (.\\scratch.go:5) JMP 0 \u0026#34;\u0026#34;.demo1.func1 STEXT nosplit size=13 args=0x8 locals=0x0 // 这里的 $0-8 就是只有一个参数没有返回值， go 代码中 defer 后面的函数 0x0000 00000 (.\\scratch.go:8) TEXT \u0026#34;\u0026#34;.demo1.func1(SB), NOSPLIT|ABIInternal, $0-8 0x0000 00000 (.\\scratch.go:8) FUNCDATA $0, gclocals·1a65e721a2ccc325b382662e7ffee780(SB) 0x0000 00000 (.\\scratch.go:8) FUNCDATA $1, gclocals·69c1753bd5f81501d95132d08af04464(SB) // 将 8(SP) 的值给了 AX 寄存器，也就是将 16(SP) 的地址给了 AX 0x0000 00000 (.\\scratch.go:9) MOVQ \u0026#34;\u0026#34;.\u0026amp;ret+8(SP), AX // 将 1 给了 AX 寄存器保存的地址的位置上。这个操作像 *a = 1 0x0005 00005 (.\\scratch.go:9) MOVQ $1, (AX) 0x000c 00012 (.\\scratch.go:10) RET 这里有了第一段汇编的讲解就不做特别具体的描述了，只标注重点关注的地方。\n// go tool compile -S demo2.go func demo2() (ret int) { defer func() { ret = 1 }() return ret } // 编译的汇编 demo2 部分代码 \u0026#34;\u0026#34;.demo2 STEXT size=138 args=0x8 locals=0x28 0x0000 00000 (.\\scratch.go:6) TEXT \u0026#34;\u0026#34;.demo2(SB), ABIInternal, $40-8 ... 0x002c 00044 (.\\scratch.go:6) MOVB $0, \u0026#34;\u0026#34;..autotmp_2+15(SP) 0x0031 00049 (.\\scratch.go:6) MOVQ $0, \u0026#34;\u0026#34;.ret+48(SP) 0x003a 00058 (.\\scratch.go:7) LEAQ \u0026#34;\u0026#34;.demo2.func1·f(SB), AX 0x0041 00065 (.\\scratch.go:7) MOVQ AX, \u0026#34;\u0026#34;..autotmp_3+24(SP) // 将返回值地址给了 AX 寄存器 0x0046 00070 (.\\scratch.go:7) LEAQ \u0026#34;\u0026#34;.ret+48(SP), AX // 返回值地址给了 16(SP) 0x004b 00075 (.\\scratch.go:7) MOVQ AX, \u0026#34;\u0026#34;..autotmp_4+16(SP) 0x0050 00080 (.\\scratch.go:10) MOVB $0, \u0026#34;\u0026#34;..autotmp_2+15(SP) // 又将 返回值地址给了 AX 寄存器 0x0055 00085 (.\\scratch.go:10) MOVQ \u0026#34;\u0026#34;..autotmp_4+16(SP), AX // 将返回值地址给了 0(SP) // 这里可以 0(SP) 为调用 demo2.func1 的入参 0x005a 00090 (.\\scratch.go:10) MOVQ AX, (SP) 0x005e 00094 (.\\scratch.go:10) PCDATA $1, $1 0x005e 00094 (.\\scratch.go:10) NOP // 调用了 demo2.func1 0x0060 00096 (.\\scratch.go:10) CALL \u0026#34;\u0026#34;.demo2.func1(SB) 0x0065 00101 (.\\scratch.go:10) MOVQ 32(SP), BP 0x006a 00106 (.\\scratch.go:10) ADDQ $40, SP 0x006e 00110 (.\\scratch.go:10) RET 0x006f 00111 (.\\scratch.go:10) CALL runtime.deferreturn(SB) 0x0074 00116 (.\\scratch.go:10) MOVQ 32(SP), BP 0x0079 00121 (.\\scratch.go:10) ADDQ $40, SP 0x007d 00125 (.\\scratch.go:10) RET 0x007e 00126 (.\\scratch.go:10) NOP 0x007e 00126 (.\\scratch.go:6) PCDATA $1, $-1 0x007e 00126 (.\\scratch.go:6) PCDATA $0, $-2 0x007e 00126 (.\\scratch.go:6) NOP 0x0080 00128 (.\\scratch.go:6) CALL runtime.morestack_noctxt(SB) 0x0085 00133 (.\\scratch.go:6) PCDATA $0, $-1 0x0085 00133 (.\\scratch.go:6) JMP 0 \u0026#34;\u0026#34;.demo2.func1 STEXT nosplit size=13 args=0x8 locals=0x0 0x0000 00000 (.\\scratch.go:7) TEXT \u0026#34;\u0026#34;.demo2.func1(SB), NOSPLIT|ABIInternal, $0-8 0x0000 00000 (.\\scratch.go:7) FUNCDATA $0, gclocals·1a65e721a2ccc325b382662e7ffee780(SB) 0x0000 00000 (.\\scratch.go:7) FUNCDATA $1, gclocals·69c1753bd5f81501d95132d08af04464(SB) 0x0000 00000 (.\\scratch.go:8) MOVQ \u0026#34;\u0026#34;.\u0026amp;ret+8(SP), AX // 这里将返回值的值修改成了 1 0x0005 00005 (.\\scratch.go:8) MOVQ $1, (AX) 0x000c 00012 (.\\scratch.go:9) RET 以上就是两个方法的汇编源码解析，从两个栗子中可以得到结果。\ndemo1 中的 ret 是临时变量，虽然 defer 确实改了 ret 的值，但这个值跟返回值没一毛钱关系，而且在汇编中 demo1 的返回值在还没调用 demo1.func1 的时候就已经确定了，所以 demo1 返回了 -1。\ndemo2 中的 ret 则直接指向了返回值的地址，defer 也改了返回值的值， 所以 demo2 就返回了 1。\n参考 https://golang.org/doc/asm#directives https://xargin.com/plan9-assembly/ https://www.doxsey.net/blog/go-and-assembly https://davidwong.fr/goasm/ ","permalink":"https://mioto.me/posts/plan9-assembly/","summary":"为什么要看 Plan9 汇编？如果你是 Go 开发者，去学习和理解一下 Plan9 是很有必要的，因为它可以解决你对一段代码的理解（为什么这样不行？那样却可以？）。\nPlan9 不同于 AT\u0026amp;T 和 Intel 汇编器，但是懂这两个汇编语法的话对理解 Plan9 还是有很大帮助的。\n疑惑 // 为什么这个函数的返回值会是 -1 func demo1() int { ret := -1 defer func() { ret = 1 }() return ret } // output: -1 // 为什么这个函数的返回值会是 1 func demo2() (ret int) { defer func() { ret = 1 }() return ret } // output: 1 相信大部分人都看过类似的解答，demo1 中是临时变量导致的，而 demo2 中没有临时变量，这是最终结果。\n在汇编层面到底做了什么？本文将会探讨这个问题。（本文所使用的平台是 MacOS AMD64）不同的平台指令集和寄存器都不一样。\n基础 通用寄存器 下面是通用通用寄存器的名字在 IA64 和 plan9 中的对应关系：","title":"Plan9 汇编入门讲解"},{"content":"前天在联调过程中出现了一个神奇的错误, 错误在 client 端的表现为 http 请求错误 Get \u0026quot;http://127.0.0.1:8800\u0026quot;: EOF, 但是服务端却没有任何 异常 所有的日志都是正常执行\n由于只有 client 端的错误, 所以 Google 搜索的处理结果全都不是实际场景导致的(并没有怀疑到服务端出了问题), 无奈只能抓包, 最终问题得以解决\n原因 server 端处理请求耗时 30s, 但是 http.Server 的 write timeout 设置的时间是 10s, 所以在 handler 处理请求完毕的时候, server 端和 client 端的连接已经被关闭了\n但是由于 server 端写入的 data 远远小于 http/net 包中设定的 write buffer 缓冲大小(4096 byte), 所以 bufio 的 Write 方法并没有返回 error\n抓包 源码: https://github.com/yakumioto/demo-response-write-timeout\n由于测试环境太过复杂, 所以写了个 demo 复现了整个流程， 以下是 wireshark 导出的 svc 由此可以看出:\n客户端通过三次握手和服务端建立了 TCP 连接 客户端正常的发送了 HTTP Request 请求 正常的保持了一段时间的 Keep-Alive 服务端通过四次挥手和客户端断开了连接 \u0026#34;No.\u0026#34;,\u0026#34;Time\u0026#34;,\u0026#34;Source\u0026#34;,\u0026#34;Destination\u0026#34;,\u0026#34;Protocol\u0026#34;,\u0026#34;Length\u0026#34;,\u0026#34;Info\u0026#34; \u0026#34;85\u0026#34;,\u0026#34;3.662590\u0026#34;,\u0026#34;127.0.0.1\u0026#34;,\u0026#34;127.0.0.1\u0026#34;,\u0026#34;TCP\u0026#34;,\u0026#34;68\u0026#34;,\u0026#34;55585 \u0026gt; 8800 [SYN] Seq=0 Win=65535 Len=0 MSS=16344 WS=64 TSval=465914251 TSecr=0 SACK_PERM=1\u0026#34; \u0026#34;86\u0026#34;,\u0026#34;3.662666\u0026#34;,\u0026#34;127.0.0.1\u0026#34;,\u0026#34;127.0.0.1\u0026#34;,\u0026#34;TCP\u0026#34;,\u0026#34;68\u0026#34;,\u0026#34;8800 \u0026gt; 55585 [SYN, ACK] Seq=0 Ack=1 Win=65535 Len=0 MSS=16344 WS=64 TSval=465914251 TSecr=465914251 SACK_PERM=1\u0026#34; \u0026#34;87\u0026#34;,\u0026#34;3.662675\u0026#34;,\u0026#34;127.0.0.1\u0026#34;,\u0026#34;127.0.0.1\u0026#34;,\u0026#34;TCP\u0026#34;,\u0026#34;56\u0026#34;,\u0026#34;55585 \u0026gt; 8800 [ACK] Seq=1 Ack=1 Win=408256 Len=0 TSval=465914251 TSecr=465914251\u0026#34; \u0026#34;88\u0026#34;,\u0026#34;3.662681\u0026#34;,\u0026#34;127.0.0.1\u0026#34;,\u0026#34;127.0.0.1\u0026#34;,\u0026#34;TCP\u0026#34;,\u0026#34;56\u0026#34;,\u0026#34;[TCP Window Update] 8800 \u0026gt; 55585 [ACK] Seq=1 Ack=1 Win=408256 Len=0 TSval=465914251 TSecr=465914251\u0026#34; \u0026#34;89\u0026#34;,\u0026#34;3.662802\u0026#34;,\u0026#34;127.0.0.1\u0026#34;,\u0026#34;127.0.0.1\u0026#34;,\u0026#34;HTTP\u0026#34;,\u0026#34;151\u0026#34;,\u0026#34;GET / HTTP/1.1 \u0026#34; \u0026#34;90\u0026#34;,\u0026#34;3.662813\u0026#34;,\u0026#34;127.0.0.1\u0026#34;,\u0026#34;127.0.0.1\u0026#34;,\u0026#34;TCP\u0026#34;,\u0026#34;56\u0026#34;,\u0026#34;8800 \u0026gt; 55585 [ACK] Seq=1 Ack=96 Win=408192 Len=0 TSval=465914251 TSecr=465914251\u0026#34; \u0026#34;160\u0026#34;,\u0026#34;18.792318\u0026#34;,\u0026#34;127.0.0.1\u0026#34;,\u0026#34;127.0.0.1\u0026#34;,\u0026#34;TCP\u0026#34;,\u0026#34;44\u0026#34;,\u0026#34;[TCP Keep-Alive] 8800 \u0026gt; 55585 [ACK] Seq=0 Ack=96 Win=408192 Len=0\u0026#34; \u0026#34;161\u0026#34;,\u0026#34;18.792325\u0026#34;,\u0026#34;127.0.0.1\u0026#34;,\u0026#34;127.0.0.1\u0026#34;,\u0026#34;TCP\u0026#34;,\u0026#34;44\u0026#34;,\u0026#34;[TCP Keep-Alive] 55585 \u0026gt; 8800 [ACK] Seq=95 Ack=1 Win=408256 Len=0\u0026#34; \u0026#34;162\u0026#34;,\u0026#34;18.792359\u0026#34;,\u0026#34;127.0.0.1\u0026#34;,\u0026#34;127.0.0.1\u0026#34;,\u0026#34;TCP\u0026#34;,\u0026#34;56\u0026#34;,\u0026#34;[TCP Keep-Alive ACK] 55585 \u0026gt; 8800 [ACK] Seq=96 Ack=1 Win=408256 Len=0 TSval=465929251 TSecr=465914251\u0026#34; \u0026#34;163\u0026#34;,\u0026#34;18.792363\u0026#34;,\u0026#34;127.0.0.1\u0026#34;,\u0026#34;127.0.0.1\u0026#34;,\u0026#34;TCP\u0026#34;,\u0026#34;56\u0026#34;,\u0026#34;[TCP Dup ACK 90#1] 8800 \u0026gt; 55585 [ACK] Seq=1 Ack=96 Win=408192 Len=0 TSval=465929251 TSecr=465914251\u0026#34; \u0026#34;283\u0026#34;,\u0026#34;33.925723\u0026#34;,\u0026#34;127.0.0.1\u0026#34;,\u0026#34;127.0.0.1\u0026#34;,\u0026#34;TCP\u0026#34;,\u0026#34;44\u0026#34;,\u0026#34;[TCP Keep-Alive] 8800 \u0026gt; 55585 [ACK] Seq=0 Ack=96 Win=408192 Len=0\u0026#34; \u0026#34;284\u0026#34;,\u0026#34;33.925731\u0026#34;,\u0026#34;127.0.0.1\u0026#34;,\u0026#34;127.0.0.1\u0026#34;,\u0026#34;TCP\u0026#34;,\u0026#34;44\u0026#34;,\u0026#34;[TCP Keep-Alive] 55585 \u0026gt; 8800 [ACK] Seq=95 Ack=1 Win=408256 Len=0\u0026#34; \u0026#34;285\u0026#34;,\u0026#34;33.925741\u0026#34;,\u0026#34;127.0.0.1\u0026#34;,\u0026#34;127.0.0.1\u0026#34;,\u0026#34;TCP\u0026#34;,\u0026#34;56\u0026#34;,\u0026#34;[TCP Keep-Alive ACK] 55585 \u0026gt; 8800 [ACK] Seq=96 Ack=1 Win=408256 Len=0 TSval=465944251 TSecr=465929251\u0026#34; \u0026#34;286\u0026#34;,\u0026#34;33.925749\u0026#34;,\u0026#34;127.0.0.1\u0026#34;,\u0026#34;127.0.0.1\u0026#34;,\u0026#34;TCP\u0026#34;,\u0026#34;56\u0026#34;,\u0026#34;[TCP Dup ACK 90#2] 8800 \u0026gt; 55585 [ACK] Seq=1 Ack=96 Win=408192 Len=0 TSval=465944251 TSecr=465929251\u0026#34; \u0026#34;345\u0026#34;,\u0026#34;49.031897\u0026#34;,\u0026#34;127.0.0.1\u0026#34;,\u0026#34;127.0.0.1\u0026#34;,\u0026#34;TCP\u0026#34;,\u0026#34;44\u0026#34;,\u0026#34;[TCP Keep-Alive] 8800 \u0026gt; 55585 [ACK] Seq=0 Ack=96 Win=408192 Len=0\u0026#34; \u0026#34;346\u0026#34;,\u0026#34;49.031903\u0026#34;,\u0026#34;127.0.0.1\u0026#34;,\u0026#34;127.0.0.1\u0026#34;,\u0026#34;TCP\u0026#34;,\u0026#34;44\u0026#34;,\u0026#34;[TCP Keep-Alive] 55585 \u0026gt; 8800 [ACK] Seq=95 Ack=1 Win=408256 Len=0\u0026#34; \u0026#34;347\u0026#34;,\u0026#34;49.031929\u0026#34;,\u0026#34;127.0.0.1\u0026#34;,\u0026#34;127.0.0.1\u0026#34;,\u0026#34;TCP\u0026#34;,\u0026#34;56\u0026#34;,\u0026#34;[TCP Keep-Alive ACK] 55585 \u0026gt; 8800 [ACK] Seq=96 Ack=1 Win=408256 Len=0 TSval=465959251 TSecr=465944251\u0026#34; \u0026#34;348\u0026#34;,\u0026#34;49.031932\u0026#34;,\u0026#34;127.0.0.1\u0026#34;,\u0026#34;127.0.0.1\u0026#34;,\u0026#34;TCP\u0026#34;,\u0026#34;56\u0026#34;,\u0026#34;[TCP Dup ACK 90#3] 8800 \u0026gt; 55585 [ACK] Seq=1 Ack=96 Win=408192 Len=0 TSval=465959251 TSecr=465944251\u0026#34; \u0026#34;469\u0026#34;,\u0026#34;63.667058\u0026#34;,\u0026#34;127.0.0.1\u0026#34;,\u0026#34;127.0.0.1\u0026#34;,\u0026#34;TCP\u0026#34;,\u0026#34;56\u0026#34;,\u0026#34;8800 \u0026gt; 55585 [FIN, ACK] Seq=1 Ack=96 Win=408192 Len=0 TSval=465973767 TSecr=465959251\u0026#34; \u0026#34;470\u0026#34;,\u0026#34;63.667081\u0026#34;,\u0026#34;127.0.0.1\u0026#34;,\u0026#34;127.0.0.1\u0026#34;,\u0026#34;TCP\u0026#34;,\u0026#34;56\u0026#34;,\u0026#34;55585 \u0026gt; 8800 [ACK] Seq=96 Ack=2 Win=408256 Len=0 TSval=465973767 TSecr=465973767\u0026#34; \u0026#34;471\u0026#34;,\u0026#34;63.667119\u0026#34;,\u0026#34;127.0.0.1\u0026#34;,\u0026#34;127.0.0.1\u0026#34;,\u0026#34;TCP\u0026#34;,\u0026#34;56\u0026#34;,\u0026#34;55585 \u0026gt; 8800 [FIN, ACK] Seq=96 Ack=2 Win=408256 Len=0 TSval=465973767 TSecr=465973767\u0026#34; \u0026#34;472\u0026#34;,\u0026#34;63.667147\u0026#34;,\u0026#34;127.0.0.1\u0026#34;,\u0026#34;127.0.0.1\u0026#34;,\u0026#34;TCP\u0026#34;,\u0026#34;56\u0026#34;,\u0026#34;8800 \u0026gt; 55585 [ACK] Seq=2 Ack=97 Win=408192 Len=0 TSval=465973767 TSecr=465973767\u0026#34; 源码解析 既然是源码分析那就从头跟起!!!\n入口方法, 为了方便定位追踪源码 // file: /usr/local/Cellar/go/1.15.2/libexec/src/net/http/server.go:2854 // 入口函数, 没啥好解释的 func (srv *Server) ListenAndServe() error { ... return srv.Serve(ln) } // file: /usr/local/Cellar/go/1.15.2/libexec/src/net/http/server.go:2907 // 死循环, 监听请求, 并开一个协程处理 func (srv *Server) Serve(l net.Listener) error { ... for { ... c := srv.newConn(rw) c.setState(c.rwc, StateNew) // before Serve can return go c.serve(connCtx) } } 这里有一些重要的变量需要记录以下, 后续的源码中会涉及到 b.bufr: conn 的读 buffer b.bufw: conn 的写 buffer, 大小为 4096 byte c.readRequest(ctx): 处理了 req 请求, 同时返回了一个 *response ServeHTTP(w, w.req): 最终 w 会一路下传, 到我们自己所写的处理函数中\n接下来就看这个 w 是如何产生的\n// file: /usr/local/Cellar/go/1.15.2/libexec/src/net/http/server.go:1794 func (c *conn) serve(ctx context.Context) { ... // HTTP/1.x from here on. ctx, cancelCtx := context.WithCancel(ctx) c.cancelCtx = cancelCtx defer cancelCtx() c.r = \u0026amp;connReader{conn: c} c.bufr = newBufioReader(c.r) c.bufw = newBufioWriterSize(checkConnErrorWriter{c}, 4\u0026lt;\u0026lt;10) for { w, err := c.readRequest(ctx) ... serverHandler{c.server}.ServeHTTP(w, w.req) ... } } w.w: 可见 w.w 是 w.cw 的 bufio.Writer 相当于调用 w.w.Write(p []byte) == w.cw.Write(p []byte) w.cw: 可见其类型是 chunkWriter 所以如果调用到 w.w.Write(p []byte) == chunkWriter.Write([]byte)\n// file: /usr/local/Cellar/go/1.15.2/libexec/src/net/http/server.go:418 type response struct { ... w *bufio.Writer // buffers output in chunks to chunkWriter cw chunkWriter ... } // file: /usr/local/Cellar/go/1.15.2/libexec/src/net/http/server.go:955 func (c *conn) readRequest(ctx context.Context) (w *response, err error) { ... w = \u0026amp;response{ conn: c, cancelCtx: cancelCtx, req: req, reqBody: req.Body, handlerHeader: make(Header), contentLength: -1, closeNotifyCh: make(chan bool, 1), // We populate these ahead of time so we\u0026#39;re not // reading from req.Header after their Handler starts // and maybe mutates it (Issue 14940) wants10KeepAlive: req.wantsHttp10KeepAlive(), wantsClose: req.wantsClose(), } if isH2Upgrade { w.closeAfterReply = true } w.cw.res = w w.w = newBufioWriterSize(\u0026amp;w.cw, bufferBeforeChunkingSize) ... } cw.res.conn: 根据上面的代码发现 conn == w.conn == srv.newConn(rw) cw.res.conn.bufw: 就是 c.bufw = newBufioWriterSize(checkConnErrorWriter{c}, 4\u0026laquo;10), 由此可见 conn write 的缓冲区就是 4096 byte\nfunc (cw *chunkWriter) Write(p []byte) (n int, err error) { ... n, err = cw.res.conn.bufw.Write(p) if cw.chunking \u0026amp;\u0026amp; err == nil { _, err = cw.res.conn.bufw.Write(crlf) } if err != nil { cw.res.conn.rwc.Close() } return } bufio: 如果数据长度没有超过 len(b.buf) 数据会 copy 到 b.buf 中, 并不会真正写入 b.wr 中\n// file: /usr/local/Cellar/go/1.15.2/libexec/src/bufio/bufio.go:558 type Writer struct { err error buf []byte n int wr io.Writer } // file: /usr/local/Cellar/go/1.15.2/libexec/src/net/http/server.go:368 func (b *Writer) Write(p []byte) (nn int, err error) { for len(p) \u0026gt; b.Available() \u0026amp;\u0026amp; b.err == nil { var n int if b.Buffered() == 0 { // Large write, empty buffer. // Write directly from p to avoid copy. n, b.err = b.wr.Write(p) } else { n = copy(b.buf[b.n:], p) b.n += n b.Flush() } nn += n p = p[n:] } if b.err != nil { return nn, b.err } n := copy(b.buf[b.n:], p) b.n += n nn += n return nn, nil } 参考 https://github.com/golang/go/issues/21389 ","permalink":"https://mioto.me/posts/http-response-write-timeout/","summary":"前天在联调过程中出现了一个神奇的错误, 错误在 client 端的表现为 http 请求错误 Get \u0026quot;http://127.0.0.1:8800\u0026quot;: EOF, 但是服务端却没有任何 异常 所有的日志都是正常执行\n由于只有 client 端的错误, 所以 Google 搜索的处理结果全都不是实际场景导致的(并没有怀疑到服务端出了问题), 无奈只能抓包, 最终问题得以解决\n原因 server 端处理请求耗时 30s, 但是 http.Server 的 write timeout 设置的时间是 10s, 所以在 handler 处理请求完毕的时候, server 端和 client 端的连接已经被关闭了\n但是由于 server 端写入的 data 远远小于 http/net 包中设定的 write buffer 缓冲大小(4096 byte), 所以 bufio 的 Write 方法并没有返回 error\n抓包 源码: https://github.com/yakumioto/demo-response-write-timeout\n由于测试环境太过复杂, 所以写了个 demo 复现了整个流程， 以下是 wireshark 导出的 svc 由此可以看出:\n客户端通过三次握手和服务端建立了 TCP 连接 客户端正常的发送了 HTTP Request 请求 正常的保持了一段时间的 Keep-Alive 服务端通过四次挥手和客户端断开了连接 \u0026#34;No.","title":"Go HTTP Response 写超时导致的 EOF 错误"},{"content":"神经网络的数据表示 张量(tensor) 是一个数据容器, 它包含的数据几乎总是数值数据, 因此它的数字容器, 张量是矩阵向任意维度的推广, 维度(dimension) 通常也叫作 轴(axis).\n标量(scalar): 仅包含一个数字的张量叫作 标量(标量张量, 零维张量, 0D 张量), 一个 float32 或 float64 的数字就是一个标量张量.\nx = numpy.array(12) 向量(vector): 数字组成的数组叫作 向量(一维张量, 1D 张量), 张量有一个轴.\nx = numpy.array([12, 3, 6, 14, 7]) 矩阵(matrix): 向量组成的数组叫作 矩阵(二维张量, 2D 张量), 矩阵有两个轴(行, 列).\nx = numpy.array([ [5, 78, 2, 34, 0], [6, 79, 3, 35, 1], [7, 80, 4, 36, 2]]) 3D张量与更高维的张量: 矩阵组成的数据叫作 3D 张量, 3D 张量组成的数组叫作 4D 张量, 以此类推.\nx = numpy.array([ [[5, 78, 2, 34, 0], [6, 79, 3, 35, 1], [7, 80, 4, 36, 2]], [[5, 78, 2, 34, 0], [6, 79, 3, 35, 1], [7, 80, 4, 36, 2]], [[5, 78, 2, 34, 0], [6, 79, 3, 35, 1], [7, 80, 4, 36, 2]], ]) 深度学习处理的一般是 0D 到 4D 的张量, 但处理视频数据时可能会遇到 5D 张量.\n关键属性 张量是由三个关键属性来定义的.\n轴的个数(阶): 3D 张量有 3 个轴, 矩阵有 2 个轴, 这在 Numpy 等 Python 库中也叫作张量的 ndim. 形状: 这是一个整数元组, 表示张量沿每个轴的维度大小, 举例: 1.1 中的矩阵形状为 (3, 5), 3D 张量为 (3, 3, 5), 向量为 (5,) 标量为 (). 数据类型: 在 Python 库中通常叫作 dtype, 这是张量中包含数据的类型, 张量的类型可以是 uint8, float32, float64 等, 在极少情况下会遇到 字符(char) 张量.\n在 Numpy 中操作张量 # 选择第 10-100 个数字(不包括 100), 有以下三种写法 my_slice = train_images[10:100] my_slice = train_images[10:100, :, :] my_slice = train_images[10:100, 0:28, 0:28] # 取出所有图像右下角 14*14 的像素区域 my_slice = train_images[:, 14:, 14:] # 取出所有图像中间 14*14 的像素区域 my_slice = train_images[:, 7:-7, 7:-7] 数据批量的概念 深度学习中所有数据的张量的第一个 轴(0 轴) 都是 样本轴(samples axis), 深度学习模型不会同时处理整个数据集, 而是将数据分成 N 个小批量.\nbatch = train_images[:128] # 下一批 batch = train_images[128:256] # 然后是第 N 批 batch = train_images[128 * n: 128 * (n + 1)] 现实中的数据张量 在现实中, 需要处理的数据几乎是以下几类别之一.\n向量数据: 2D 张量, 形状为 (samples, features).\n人口统计数据集, 每个人包含 年龄, 收入, 100 000个人的数据集形状为 (100000[samples], 2[features]). 文本文档数据集, 每个文档表示为单词出现的个数 (字典中包含 20 000 个常见的单词), 每个文档可以被编码为包含 20 000 个值的向量中, 整个数据集包含 500 个文档, 因此可以存储在形状为 (500, 20000) 的 2D 张量中. 时间序列\u0026amp;序列数据: 3D 张量, 形状为 (samples, timesteps, features).\n依照惯例, 时间始终是第二轴.\n股票价格数据集, 股票当前价格, 前一分钟最高价格, 前一分钟最低价格 可以看作为 4D 向量形状为 (3[features]), 整个交易日(390分钟)可以编码为一个 2D 张量形状为 (390[samples], 3[features]), 250天的数据集形状为 (250[samples], 390[timesteps], 3[features]). 推文数据集, 每个推文编码为 280 个字符组成的序列, 而每个字又来自与 20 000 个常用单词的字典中, 这种情况下每个字符可以被编码为 20000D 的向量中, 那么每个推文可以被编码为一个形状为 (280[samples], 20000[features]) 的 2D 向量中, 100 万推文的数据集则可以存储在一个形状为 (1000000[samples], 280[steps], 20000[features]) 的 3D 张量. 图像: 4D 张量, 形状为 (samples, height, width, channels) 或 (samples, channels, height, width).\n图片具有三个维度: 高度, 宽度, 和颜色深度 (虽然灰度图像 比如 MNIST 数字图像 只有一个颜色通道, 因此可以保存在 2D 张量中, 但按照惯例图像张量始终都是 3D 张量).\n灰度图像的颜色通道只有一维, 因此如果图像大小为 256*256 ,那么 128 张组成的批量可以保存在形状为 (128, 256, 256, 1) 的 4D 张量中. 彩色图像的颜色通道有 3 个 (R G B), 那么 128 张组成的批量可以保存在形状为 (128, 256, 256, 3) 的 4D 张量中. 图像张量的形状有两种约定: 通道在后(channels-last) 的约定 (在 TensorFlow 中使用) 和 通道在前(channels-first) 的约定 (在 Theano 中使用).\n视频: 5D 张量, 形状为 (samples, frames, height, width, channels) 或 (samples, frames, channels, height, width).\n一个以每秒 24 帧采样的 60 秒 YouTube 视频片段, 视频尺寸为 144*256 这个视频一共有 240 帧, 4 个这样的视频组成的批量将保存在形状为(4[samples], 240[frames], 144[height], 256[width], 3[channels]) 的 5D 张量中. ","permalink":"https://mioto.me/posts/the-data-foundation-of-neural-networks/","summary":"神经网络的数据表示 张量(tensor) 是一个数据容器, 它包含的数据几乎总是数值数据, 因此它的数字容器, 张量是矩阵向任意维度的推广, 维度(dimension) 通常也叫作 轴(axis).\n标量(scalar): 仅包含一个数字的张量叫作 标量(标量张量, 零维张量, 0D 张量), 一个 float32 或 float64 的数字就是一个标量张量.\nx = numpy.array(12) 向量(vector): 数字组成的数组叫作 向量(一维张量, 1D 张量), 张量有一个轴.\nx = numpy.array([12, 3, 6, 14, 7]) 矩阵(matrix): 向量组成的数组叫作 矩阵(二维张量, 2D 张量), 矩阵有两个轴(行, 列).\nx = numpy.array([ [5, 78, 2, 34, 0], [6, 79, 3, 35, 1], [7, 80, 4, 36, 2]]) 3D张量与更高维的张量: 矩阵组成的数据叫作 3D 张量, 3D 张量组成的数组叫作 4D 张量, 以此类推.","title":"神经网络的数据基础"},{"content":"据同事说 node sdk@v2.x.x 版本中没有对网络操作相关的 API 实现, 所以只能自己照着 v1.4.x 版本的 手撸底层代码, 但是在实现 JoinChain 这个功能时出现了 channel doesn't exist 错误\n原因 // SignedProposal 部分结构 { \u0026#34;proposal_bytes\u0026#34;: { \u0026#34;header\u0026#34;: { \u0026#34;channel_header\u0026#34;: { \u0026#34;channel_id\u0026#34;: \u0026#34;\u0026#34; }, \u0026#34;signature_header\u0026#34;: { \u0026#34;creator\u0026#34;: { \u0026#34;mspid\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;id_bytes\u0026#34;: \u0026#34;\u0026#34; } } }, \u0026#34;payload\u0026#34;: \u0026#34;\u0026#34; }, \u0026#34;signature\u0026#34;: \u0026#34;\u0026#34; } 当 peer 收到 client 发来的 SignedProposal 时, 会进行签名校验\n根据 proposal_bytes.header.channel_header.channel_id 获取对应的 mspMgmtMgr, 如果此时通道不存在, 则会创建一个未经初始化的 mspMgmtMgr 根据 proposal_bytes.header.signature_header.creator.mspid 获取对应的 mspManagerImpl, 但是由于 mspMgmtMgr 未初始化, 所以直接返回了 channel doesn't exist 源码追踪 重要的事情说三遍\n注释!!!\n注释!!!\n注释!!!\n// core/endorser/endorser.go:423 // endorser server 的入口函数, GRPC 消息都会发到这个 handler 中进行处理 func (e *Endorser) ProcessProposal(ctx context.Context, signedProp *pb.SignedProposal) (*pb.ProposalResponse, error) { ... // 0 -- check and validate vr, err := e.preProcess(signedProp) if err != nil { resp := vr.resp return resp, err } ... } // core/endorser/endorser.go:348 // 做提前校验相关的工作, 比如验证这个消息是否是本人发送的等. func (e *Endorser) preProcess(signedProp *pb.SignedProposal) (*validateResult, error) { ... // at first, we check whether the message is valid prop, hdr, hdrExt, err := validation.ValidateProposalMessage(signedProp) ... } // core/common/validation/msgvalidation.go:76 // 校验 Proposal message 的方法 func ValidateProposalMessage(signedProp *pb.SignedProposal) (*pb.Proposal, *common.Header, *pb.ChaincodeHeaderExtension, error) { if signedProp == nil { return nil, nil, nil, errors.New(\u0026#34;nil arguments\u0026#34;) } putilsLogger.Debugf(\u0026#34;ValidateProposalMessage starts for signed proposal %p\u0026#34;, signedProp) // 从 proposalBytes 中 反序列化出 *peer.Proposal 实例 prop, err := utils.GetProposal(signedProp.ProposalBytes) if err != nil { return nil, nil, nil, err } // 从 prop.Header 反序列化得到 *common.Header hdr, err := utils.GetHeader(prop.Header) if err != nil { return nil, nil, nil, err } // 从 hdr 中反序列化得到 *common.ChannelHeader 和 *common.SignatureHeader chdr, shdr, err := validateCommonHeader(hdr) if err != nil { return nil, nil, nil, err } // 校验签名 err = checkSignatureFromCreator(shdr.Creator, signedProp.Signature, signedProp.ProposalBytes, chdr.ChannelId) if err != nil { // log the exact message on the peer but return a generic error message to // avoid malicious users scanning for channels putilsLogger.Warningf(\u0026#34;channel [%s]: %s\u0026#34;, chdr.ChannelId, err) sId := \u0026amp;msp.SerializedIdentity{} err := proto.Unmarshal(shdr.Creator, sId) if err != nil { // log the error here as well but still only return the generic error err = errors.Wrap(err, \u0026#34;could not deserialize a SerializedIdentity\u0026#34;) putilsLogger.Warningf(\u0026#34;channel [%s]: %s\u0026#34;, chdr.ChannelId, err) } return nil, nil, nil, errors.Errorf(\u0026#34;access denied: channel [%s] creator org [%s]\u0026#34;, chdr.ChannelId, sId.Mspid) } ... } // core/common/validation/msgvalidation.go:153 func checkSignatureFromCreator(creatorBytes []byte, sig []byte, msg []byte, ChainID string) error { ... // 通过获取身份解析器 mspObj := mspmgmt.GetIdentityDeserializer(ChainID) if mspObj == nil { return errors.Errorf(\u0026#34;could not get msp for channel [%s]\u0026#34;, ChainID) } // 反系列化签名者的信息 creator, err := mspObj.DeserializeIdentity(creatorBytes) if err != nil { return errors.WithMessage(err, \u0026#34;MSP error\u0026#34;) } ... } // msp/mgmt/mgmt.go:184 // 这一步是出错的主要方法, 由于设置了 chainID 导致没有获取 LocalMSP func GetIdentityDeserializer(chainID string) msp.IdentityDeserializer { if chainID == \u0026#34;\u0026#34; { return GetLocalMSP() } return GetManagerForChain(chainID) } // msp/mgmt/mgmt.go:85 func GetManagerForChain(chainID string) msp.MSPManager { m.Lock() defer m.Unlock() // 由于 chainID 当前并不存在, 所以会走 if 分支然后会创建一个新的 mspMgr 并返回, // 初始化 mspMgmtMgr 时 up 参数被设置为 false mspMgr, ok := mspMap[chainID] if !ok { mspLogger.Debugf(\u0026#34;Created new msp manager for channel `%s`\u0026#34;, chainID) mspMgmtMgr := \u0026amp;mspMgmtMgr{msp.NewMSPManager(), false} mspMap[chainID] = mspMgmtMgr mspMgr = mspMgmtMgr } else { ... } return mspMgr } // msp/mgmt/mgmt.go:68 // 在 GetManagerForChain 方法中被生成 // 在 checkSignatureFromCreator 方法中被调用, 且 up 被设置为了 false 所以返回了 error func (mgr *mspMgmtMgr) DeserializeIdentity(serializedIdentity []byte) (msp.Identity, error) { if !mgr.up { return nil, errors.New(\u0026#34;channel doesn\u0026#39;t exist\u0026#34;) } return mgr.MSPManager.DeserializeIdentity(serializedIdentity) } 参考 https://github.com/hyperledger/fabric/tree/v1.4.6\n","permalink":"https://mioto.me/posts/fab-join-channel-issue/","summary":"据同事说 node sdk@v2.x.x 版本中没有对网络操作相关的 API 实现, 所以只能自己照着 v1.4.x 版本的 手撸底层代码, 但是在实现 JoinChain 这个功能时出现了 channel doesn't exist 错误\n原因 // SignedProposal 部分结构 { \u0026#34;proposal_bytes\u0026#34;: { \u0026#34;header\u0026#34;: { \u0026#34;channel_header\u0026#34;: { \u0026#34;channel_id\u0026#34;: \u0026#34;\u0026#34; }, \u0026#34;signature_header\u0026#34;: { \u0026#34;creator\u0026#34;: { \u0026#34;mspid\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;id_bytes\u0026#34;: \u0026#34;\u0026#34; } } }, \u0026#34;payload\u0026#34;: \u0026#34;\u0026#34; }, \u0026#34;signature\u0026#34;: \u0026#34;\u0026#34; } 当 peer 收到 client 发来的 SignedProposal 时, 会进行签名校验\n根据 proposal_bytes.header.channel_header.channel_id 获取对应的 mspMgmtMgr, 如果此时通道不存在, 则会创建一个未经初始化的 mspMgmtMgr 根据 proposal_bytes.header.signature_header.creator.mspid 获取对应的 mspManagerImpl, 但是由于 mspMgmtMgr 未初始化, 所以直接返回了 channel doesn't exist 源码追踪 重要的事情说三遍","title":"Hyperledger Fabric 加入通道时遇到 channel doesn't exist 问题"},{"content":"本文基于 hyperldeger fabric 1.4.7 进行代码追踪讲解\n假设场景描述:\npeer 重启场景 peer 有 user channel peer 使用的是 goleveldb peer 的 core.peer.gossip.orgLeader 为 true 流程简介 初始化账本根据账本中保存的 channel id 创建通道实例, 并初始化与之对等的 gossip 服务, 用 来接收对应通道的最新的 配置或交易 block, 接收到 block 后, 经过 Verify, Validate, Validate RW sets 三个验证步骤, 提交给 Ledger Commiter 进行写入文件, 并将当前通道的 blkMgrInfo 更新到最新状态\n源码追踪 伊始: main -\u0026gt; node.Cmd -\u0026gt; startCmd -\u0026gt; nodeStartCmd -\u0026gt; serve\npeer.Initialize 文件: core/peer/peer.go:241\n初始化 ledgermgmt, 里面做的事情太多了, 要讲清楚有点困难建议大家自己去看看, 里面主要做的就是 各种初始化工作\n// /var/hyperledger/production/ledgersData 下有这些东西, 这里面的工作跟此目录有关 // chains/index goleveldb: 保存了所有通道的最新状态信息 // fileLock goleveldb: 用于锁程序的,文章最末尾有介绍 // historyLeveldb goleveldb: 保存历史交易的 // ledgerProvider goleveldb: 保存的是 chain ids, 也就是通道id // pvtdataStore goleveldb: 存储私有数据库 // stateLeveldb goleveldb: 世界状态数据库, 可以替换为 couchdb // 这两个我不确定没有细追 // configHistory 看名字应该是保存了 config block 相关的东西. // bookkeeper 不知道. ledgermgmt.Initialize(\u0026amp;ledgermgmt.Initializer{ CustomTxProcessors: ConfigTxProcessors, PlatformRegistry: pr, DeployedChaincodeInfoProvider: deployedCCInfoProvider, MembershipInfoProvider: membershipProvider, MetricsProvider: metricsProvider, }) // 就是通过 /var/hyperledger/production/ledgersData/ledgerProvider 获取的 id 列表 ledgerIds, err := ledgermgmt.GetLedgerIDs() ... for _, cid := range ledgerIds { // 打开对应通道的账本, 例如打开 block 的最新文件, 加载最新的账本信息等 if ledger, err = ledgermgmt.OpenLedger(cid); err != nil { ... } // 获取最新的交易块, 通过交易块获取最新的配置块的 number, 在通过 number 查询到最新的配置块 // 有兴趣可以往下追一追看看 if cb, err = getCurrConfigBlockFromLedger(ledger); err != nil { ... } // 创建通道实例, 传了 通道id, 账本实例, 最新的配置块等. if err = createChain(cid, ledger, cb, ccp, sccp, pm); err != nil { ... } InitChain(cid) } func createChain( cid string, ledger ledger.PeerLedger, cb *common.Block, ccp ccprovider.ChaincodeProvider, sccp sysccprovider.SystemChaincodeProvider, pm txvalidator.PluginMapper, ) error { // 初始化 gossip 服务用到的配置, vscc, 等相关资源初始化, 有兴趣的可以看看这个函数, // 这里就不做介绍了 ... // 初始化 gossip service 方法 service.GetGossipService().InitializeChannel(bundle.ConfigtxValidator().ChainID(), oac, service.Support{ Validator: validator, Committer: c, Store: store, Cs: simpleCollectionStore, IdDeserializeFactory: csStoreSupport, CapabilityProvider: cp, }) ... return nil } service.gossipServiceImpl.InitializeChannel 文件: gossip/service/gossip_service.go:273\ngossip service 的作用是管理 gossip client, 每个 channel 会启动一个 gossip client 每个 gossip client 会启动一个 deliver block\n在 InitializeChannel 主要是初始化工作的\n初始化 private data fetcher 初始化 coordinator 初始化 gossip 参数 func (g *gossipServiceImpl) InitializeChannel(chainID string, oac OrdererAddressConfig, support Support) { ... // Delivery service might be nil only if it was not able to get connected // to the ordering service if g.deliveryService[chainID] != nil { // 根据 core.yaml 或者 环境变量设置的两个个值在下方有不同的启动方式 leaderElection := viper.GetBool(\u0026#34;peer.gossip.useLeaderElection\u0026#34;) isStaticOrgLeader := viper.GetBool(\u0026#34;peer.gossip.orgLeader\u0026#34;) ... if leaderElection { logger.Debug(\u0026#34;Delivery uses dynamic leader election mechanism, channel\u0026#34;, chainID) g.leaderElection[chainID] = g.newLeaderElectionComponent(chainID, g.onStatusChangeFactory(chainID, support.Committer), g.metrics.ElectionMetrics) } else if isStaticOrgLeader { logger.Debug(\u0026#34;This peer is configured to connect to ordering service for blocks delivery, channel\u0026#34;, chainID) g.deliveryService[chainID].StartDeliverForChannel(chainID, support.Committer, func() {}) } else { logger.Debug(\u0026#34;This peer is not configured to connect to ordering service for blocks delivery, channel\u0026#34;, chainID) } } else { logger.Warning(\u0026#34;Delivery client is down won\u0026#39;t be able to pull blocks for chain\u0026#34;, chainID) } } blocksprovider.blocksProviderImpl.DeliverBlocks 文件: core/deliverservice/blocksprovider/blocksprovider.go:110\n获取到最新的 gossip message, 根据类型判断是否是区块, 然后调用 VerifyBlock 进行验, 最后在添加到账本中\nfunc (b *blocksProviderImpl) DeliverBlocks() { ... for !b.isDone() { ... switch t := msg.Type.(type) { case *orderer.DeliverResponse_Status: ... case *orderer.DeliverResponse_Block: ... if err := b.mcs.VerifyBlock(gossipcommon.ChainID(b.chainID), blockNum, marshaledBlock); err != nil { logger.Errorf(\u0026#34;[%s] Error verifying block with sequence number %d, due to %s\u0026#34;, b.chainID, blockNum, err) continue } ... if err := b.gossip.AddPayload(b.chainID, payload); err != nil { logger.Warningf(\u0026#34;Block [%d] received from ordering service wasn\u0026#39;t added to payload buffer: %v\u0026#34;, blockNum, err) } ... default: logger.Warningf(\u0026#34;[%s] Received unknown: %v\u0026#34;, b.chainID, t) return } } } state.GossipStateProviderImpl.commitBlock 文件: gossip/state/state.go:805\nblock 经过一层层的传递, 最终到了 gossip state 中, 这也是 block 在 gossip 中的最后一环\nfunc (s *GossipStateProviderImpl) commitBlock(block *common.Block, pvtData util.PvtDataCollections) error { ... // 将 block 和 pvtdata 交给 ledger 进行存储 if err := s.ledger.StoreBlock(block, pvtData); err != nil { logger.Errorf(\u0026#34;Got error while committing(%+v)\u0026#34;, errors.WithStack(err)) return err } ... } privdata.coordinator.StoreBlock 文件: gossip/privdata/coordinator.go:163\n在这里面会校验 block 的签名, 读写集等, 然后传给 CommitWithPvtData 方法\nfunc (c *coordinator) StoreBlock(block *common.Block, privateDataSets util.PvtDataCollections) error { ... validationStart := time.Now() err := c.Validator.Validate(block) c.reportValidationDuration(time.Since(validationStart)) if err != nil { logger.Errorf(\u0026#34;Validation failed: %+v\u0026#34;, err) return err } ... // commit block and private data commitStart := time.Now() err = c.CommitWithPvtData(blockAndPvtData, \u0026amp;ledger.CommitOptions{}) c.reportCommitDuration(time.Since(commitStart)) if err != nil { return errors.Wrap(err, \u0026#34;commit failed\u0026#34;) } ... return nil } committer.LedgerCommitter.CommitWithPvtData 文件: core/committer/committer_impl.go:87\n块会交给 kvledger 进行存储, 以下追踪就跟主题无关了, 我把方法列到下面, 有需求可以自己看\nkvledger.kvLedger.CommitWithPvtData: core/ledger/ledgerstorage/store.go:113\nfsblkstorage.fsBlockStore.AddBlock: common/ledger/blkstorage/fsblkstorage/fs_blockstore.go:51\nfsblkstorage.blockfileMgr.addBlock: common/ledger/blkstorage/fsblkstorage/blockfile_mgr.go:240\n额外收获 fileLock Fabric 中的 ledger management 有一个数据库叫做 fileLock, 最开始不理解为什么要这 么实现,后来读这部分 UnLock 的代码发现, 这是类似于一个君子协议的东西, peer reset 命令里 会打开该数据库, 如果失败就证明有其他程序在使用.\n栗子:\npeer node start 启动时会打开 fileLock 的数据库连接, 这时如果你想执行peer reset 这个进程启动是也会去对 fileLock 创建连接, 但是会失败, peer reset 会终止.\n参考 https://github.com/hyperledger/fabric/tree/v1.4.7\n","permalink":"https://mioto.me/posts/fab-peer-deliver-block/","summary":"本文基于 hyperldeger fabric 1.4.7 进行代码追踪讲解\n假设场景描述:\npeer 重启场景 peer 有 user channel peer 使用的是 goleveldb peer 的 core.peer.gossip.orgLeader 为 true 流程简介 初始化账本根据账本中保存的 channel id 创建通道实例, 并初始化与之对等的 gossip 服务, 用 来接收对应通道的最新的 配置或交易 block, 接收到 block 后, 经过 Verify, Validate, Validate RW sets 三个验证步骤, 提交给 Ledger Commiter 进行写入文件, 并将当前通道的 blkMgrInfo 更新到最新状态\n源码追踪 伊始: main -\u0026gt; node.Cmd -\u0026gt; startCmd -\u0026gt; nodeStartCmd -\u0026gt; serve\npeer.Initialize 文件: core/peer/peer.go:241\n初始化 ledgermgmt, 里面做的事情太多了, 要讲清楚有点困难建议大家自己去看看, 里面主要做的就是 各种初始化工作\n// /var/hyperledger/production/ledgersData 下有这些东西, 这里面的工作跟此目录有关 // chains/index goleveldb: 保存了所有通道的最新状态信息 // fileLock goleveldb: 用于锁程序的,文章最末尾有介绍 // historyLeveldb goleveldb: 保存历史交易的 // ledgerProvider goleveldb: 保存的是 chain ids, 也就是通道id // pvtdataStore goleveldb: 存储私有数据库 // stateLeveldb goleveldb: 世界状态数据库, 可以替换为 couchdb // 这两个我不确定没有细追 // configHistory 看名字应该是保存了 config block 相关的东西.","title":"Hyperledger Fabric peer block 的交付流程详解"},{"content":"方法一 优点: 速度最快 缺点: 会导致切片数据顺序改变\na := []string{\u0026#34;A\u0026#34;, \u0026#34;B\u0026#34;, \u0026#34;C\u0026#34;, \u0026#34;D\u0026#34;, \u0026#34;E\u0026#34;} i := 2 a[i] = a[len(a)-1] // 将数组的最后一位赋值给需要删除的 index 上 a = a[:len(a)-1] // 移除掉最后一个没用的数据 // Output: // [A B E D] 方法二 优点: 速度会随着切片长度改变 缺点: 保持原有切片顺序\na := []string{\u0026#34;A\u0026#34;, \u0026#34;B\u0026#34;, \u0026#34;C\u0026#34;, \u0026#34;D\u0026#34;, \u0026#34;E\u0026#34;} i := 2 a = append(a[:i], a[i+1:]...) // Output: // [A B D E] Benchmark goos: linux goarch: amd64 pkg: github.com/yakumioto/go-example/benchmark/delete-element-slice Benchmark1 Benchmark1-4 1000000000 0.700 ns/op Benchmark2 Benchmark2-4 93140385 12.9 ns/op PASS ok github.com/yakumioto/go-example/benchmark/delete-element-slice 4.169s 参考 https://yourbasic.org/golang/delete-element-slice https://blog.golang.org/slices ","permalink":"https://mioto.me/posts/delete-element-slice/","summary":"方法一 优点: 速度最快 缺点: 会导致切片数据顺序改变\na := []string{\u0026#34;A\u0026#34;, \u0026#34;B\u0026#34;, \u0026#34;C\u0026#34;, \u0026#34;D\u0026#34;, \u0026#34;E\u0026#34;} i := 2 a[i] = a[len(a)-1] // 将数组的最后一位赋值给需要删除的 index 上 a = a[:len(a)-1] // 移除掉最后一个没用的数据 // Output: // [A B E D] 方法二 优点: 速度会随着切片长度改变 缺点: 保持原有切片顺序\na := []string{\u0026#34;A\u0026#34;, \u0026#34;B\u0026#34;, \u0026#34;C\u0026#34;, \u0026#34;D\u0026#34;, \u0026#34;E\u0026#34;} i := 2 a = append(a[:i], a[i+1:]...) // Output: // [A B D E] Benchmark goos: linux goarch: amd64 pkg: github.com/yakumioto/go-example/benchmark/delete-element-slice Benchmark1 Benchmark1-4 1000000000 0.","title":"Go 删除 Slice 中的某一个值"},{"content":"换电脑啦！！！退役了用了 6 年的笔记本！！！由于未知错误原因导致无法安装 Manjaro Linux，所以决定尝试使用 Windows 进行开发。\n由于最开始并没有考虑使用 Windows 所以显卡选择比较随意 GTX 1660 Super，导致无法玩大作，后悔啊！！！\n目前的开发工具主要是：\nJetBrains Goland Microsoft VSCode （主要用来编辑一些非项目的文件，如 Terminal 的配置文件等） Windows Terminal （主要用于打开 WSL2 子系统的，偶尔用来开 PowerShell） Windows Ubuntu WSL2 （用来 编译，调试 项目，启停 docker） Docker For Windows （WSL2 中操作 docker 容器 都会启动在这个里面） Chocolatey （类似 Linux 中的包管理工具，如 Ubuntu 的 apt） VirtualBox （甲骨文的虚拟机软件，如创建一个 Kubernetes 集群什么的） Vagrant （虚拟机管理工具，如用于一键启动 Kubernetes 集群） Putty （SSH 客户端） 以上就是我目前主要用到的开发工具。\nChocolatey https://chocolatey.org/\n无意中接触到的一个工具，很对胃口所以就决定尝试一下了。\n安装也很简单，以管理员模式启动 PowerShell.exe，然后执行一下命令就可以了。\nSet-ExecutionPolicy Bypass -Scope Process -Force; [System.Net.ServicePointManager]::SecurityProtocol = [System.Net.ServicePointManager]::SecurityProtocol -bor 3072; iex ((New-Object System.Net.WebClient).DownloadString(\u0026#39;https://chocolatey.org/install.ps1\u0026#39;)) 常用的命令\nchoco -h # 查看帮助 choco \u0026lt;command\u0026gt; -h # 查看相应命令的帮助 choco install \u0026lt;package\u0026gt; # 安装软件包 choco search \u0026lt;filter\u0026gt; # 搜索软件包 choco upgrade \u0026lt;package\u0026gt; # 升级软件包 choco uninstall \u0026lt;package\u0026gt; # 卸载软件包 choco list --local-only # 列出本地安装的软件包 以下是我的常用软件\nchoco install -y ccleaner ` golang ` googlechrome ` putty ` vagrant ` vim ` virtualbox ` virtualbox.extensionpack ` visualstudiocode ` wget ` winrar ` wireshark Terminal 从 Microsoft Store 中下载安装，颜值不错，但还是需要一些调整。\n{ \u0026#34;profiles\u0026#34;: { \u0026#34;defaults\u0026#34;: { // Put settings here that you want to apply to all profiles \u0026#34;fontFace\u0026#34;: \u0026#34;Monaco\u0026#34;, // Monaco 字体，苹果里面的我觉的好看就一直再用 \u0026#34;fontSize\u0026#34;: 11, // 字体大小 \u0026#34;colorScheme\u0026#34; : \u0026#34;Solarized Dark\u0026#34;, // 终端配色 \u0026#34;cursorShape\u0026#34;: \u0026#34;filledBox\u0026#34;, // 光标样式 \u0026#34;useAcrylic\u0026#34;: true, // 毛玻璃效果 \u0026#34;acrylicOpacity\u0026#34;: 0.5 // 模糊度 } } } Goland \u0026amp; VSCode 终端配置 Goland: File -\u0026gt; Settings -\u0026gt; Tools -\u0026gt; Terminal -\u0026gt; Shell path\n\u0026#34;cmd.exe\u0026#34; /k \u0026#34;wsl.exe\u0026#34; VSCode: 开启一个新的 Terminal 在下方选择 wsl 既可\n个人的开发规范 GOSDK 由于从事 Go 相关的开发, 这里只讲我关于Go语言的个人开发规范\nGOSDK 安装的路径规范: C:\\\\Users\\mioto\\.sdk\\gox.xx\n这样的好处是, 我可以装很多个版本, 然后在 Goland 中自行选择, 有时候会用到低版本的情况\nGOPATH 设定目录: C:\\\\Users\\mioto\\.golib\n这个习惯是沿用了 Linux 遗留下来的, 这种目录结构的原因还要从 go 1.11 之前说起, 那时并没有 go mod 所以代码都写在GOPATH 下\n所以原先的 GOPATH 是: /home/mioto/.golib:/home/mioto/workspace/go, 这样的好处是 依赖和代码分离, 可以保证工作目录下的 go/src 干净\n但是在 go 1.11 以后这种多 GOPATH 就被撤销了, 所以就留只留下了 /home/mioto/.golib\nWorkspace 工作目录: C:\\\\Users\\mioto\\Workspace\n. ├── me (个人项目) │ ├── alkaid │ ├── dockerfiles │ ├── example-go │ ├── fabric │ ├── fabric-network │ ├── fabric-sdk-go │ └── glog ├── mioto.me (博客) ├── opensource (研究开源项目) │ ├── caliper │ ├── fabric │ ├── fabric-samples │ ├── fabric-sdk-go │ └── tendermint └── trustslink (公司) 我觉的已经比较清晰啦, 所以就不多做介绍了\n","permalink":"https://mioto.me/posts/working-on-windows10/","summary":"换电脑啦！！！退役了用了 6 年的笔记本！！！由于未知错误原因导致无法安装 Manjaro Linux，所以决定尝试使用 Windows 进行开发。\n由于最开始并没有考虑使用 Windows 所以显卡选择比较随意 GTX 1660 Super，导致无法玩大作，后悔啊！！！\n目前的开发工具主要是：\nJetBrains Goland Microsoft VSCode （主要用来编辑一些非项目的文件，如 Terminal 的配置文件等） Windows Terminal （主要用于打开 WSL2 子系统的，偶尔用来开 PowerShell） Windows Ubuntu WSL2 （用来 编译，调试 项目，启停 docker） Docker For Windows （WSL2 中操作 docker 容器 都会启动在这个里面） Chocolatey （类似 Linux 中的包管理工具，如 Ubuntu 的 apt） VirtualBox （甲骨文的虚拟机软件，如创建一个 Kubernetes 集群什么的） Vagrant （虚拟机管理工具，如用于一键启动 Kubernetes 集群） Putty （SSH 客户端） 以上就是我目前主要用到的开发工具。\nChocolatey https://chocolatey.org/\n无意中接触到的一个工具，很对胃口所以就决定尝试一下了。\n安装也很简单，以管理员模式启动 PowerShell.exe，然后执行一下命令就可以了。\nSet-ExecutionPolicy Bypass -Scope Process -Force; [System.","title":"基于 Windows 的开发环境"},{"content":"为什么要通过 etcdraft 来进行共识?\n我觉得有以下原因\nsolo 并不适合大多数场景, 例如: 组织A, 组织B, 都想在自己放置共识节点 kafka 虽然能满足以上需求, 但是 kafka 加上 zookeeper 需要额外部署并且实在是太重了, 不方便部署 所以基于 etcdraft 的共识来了, 解决了以上的痛点\n重要的话说三遍!\n千万不要错过文章中的源码部分, 里面有很多很多的注释!!! 千万不要错过文章中的源码部分, 里面有很多很多的注释!!! 千万不要错过文章中的源码部分, 里面有很多很多的注释!!!\n核心接口 以下是我认为实现 etcdraft 共识核心的接口\n// ClusterServer 集群Server接口 type ClusterServer interface { Step(Cluster_StepServer) error } // ClusterClient 集群Client接口 type ClusterClient interface { Step(ctx context.Context, opts ...grpc.CallOption) (orderer.Cluster_StepClient, error) } // Handler 用于共识的两个接口 type Handler interface { OnConsensus(channel string, sender uint64, req *orderer.ConsensusRequest) error OnSubmit(channel string, sender uint64, req *orderer.SubmitRequest) error } // Consenter 共识排序接口 type Consenter interface { HandleChain(support ConsenterSupport, metadata *cb.Metadata) (Chain, error) } // Chain 共识核心的接口 type Chain interface { // 接收普通的交易消息 Order(env *cb.Envelope, configSeq uint64) error // 接收配置消息 Configure(config *cb.Envelope, configSeq uint64) error WaitReady() error Errored() \u0026lt;-chan struct{} Start() Halt() } Orderer初始化 启动 etcd 节点是需要设置 ETCD_NAME 的, 也就是节点的 ID, 但是在启动 Orderer 的时候我们并没有做相关的设置, 我觉得设计很巧妙\n如果你启动过 fabric-samples/first-network 你应该知道里面的 configtx.yaml, 用于生成 genesis.blok\ngenesis.block 中可以设置 OrdererType, 以及 EtcdRaft 相关的配置\n... Profiles: SampleMultiNodeEtcdRaft: ... Orderer: \u0026lt;\u0026lt;: *OrdererDefaults OrdererType: etcdraft EtcdRaft: Consenters: - Host: orderer.example.com Port: 7050 ClientTLSCert: crypto-config/ordererOrganizations/example.com/orderers/orderer.example.com/tls/server.crt ServerTLSCert: crypto-config/ordererOrganizations/example.com/orderers/orderer.example.com/tls/server.crt - Host: orderer2.example.com Port: 7050 ... Addresses: - orderer.example.com:7050 - orderer2.example.com:7050 ... ... 如果你做过添加组织的操作, 或者反序列化过 genesis.block, 就可以看到这个 block 中的 json 数据\n数据做过删减, 只抽出了需要讲解的地方, 如下\n{ \u0026#34;data\u0026#34;:{ \u0026#34;data\u0026#34;:[ { \u0026#34;payload\u0026#34;:{ \u0026#34;config\u0026#34;:{ \u0026#34;channel_group\u0026#34;:{ \u0026#34;groups\u0026#34;:{ \u0026#34;Orderer\u0026#34;:{ \u0026#34;values\u0026#34;:{ \u0026#34;ConsensusType\u0026#34;:{ \u0026#34;value\u0026#34;:{ \u0026#34;metadata\u0026#34;:{ \u0026#34;consenters\u0026#34;:[ { \u0026#34;client_tls_cert\u0026#34;:\u0026#34;client tls cert\u0026#34;, \u0026#34;host\u0026#34;:\u0026#34;orderer.example.com\u0026#34;, \u0026#34;port\u0026#34;:7050, \u0026#34;server_tls_cert\u0026#34;:\u0026#34;server tls cert\u0026#34; }, { \u0026#34;client_tls_cert\u0026#34;:\u0026#34;client tls cert\u0026#34;, \u0026#34;host\u0026#34;:\u0026#34;orderer2.example.com\u0026#34;, \u0026#34;port\u0026#34;:7050, \u0026#34;server_tls_cert\u0026#34;:\u0026#34;server tls cert\u0026#34; } ], \u0026#34;options\u0026#34;:{ \u0026#34;election_tick\u0026#34;:10, \u0026#34;heartbeat_tick\u0026#34;:1, \u0026#34;max_inflight_blocks\u0026#34;:5, \u0026#34;snapshot_interval_size\u0026#34;:20971520, \u0026#34;tick_interval\u0026#34;:\u0026#34;500ms\u0026#34; } }, \u0026#34;state\u0026#34;:\u0026#34;STATE_NORMAL\u0026#34;, \u0026#34;type\u0026#34;:\u0026#34;etcdraft\u0026#34; } } } } } } } }, \u0026#34;signature\u0026#34;:null } ] }, \u0026#34;header\u0026#34;:{ }, \u0026#34;metadata\u0026#34;:{ } } 在 Orderer 启动之处, 会去读取 system channel 最新的配置块, 如果没有则会读取 genesis.blok\n判断其中的 ConsensusType 如果是 etcdraft, 就会使用 clusterGRPCServer 并传入 initializeMultichannelRegistrar(...) 中\ninitializeMultichannelRegistrar(...) 会再次判断 ConsensusType 如果是 etcdraft 就会通过 initializeEtcdraftConsenter(...) 初始化 etcdraft 的 Consenter 实例对象\n同时也会初始化 cluster.Service, 它实现了 ClusterServer 核心接口\n最后将 所有的 consenters 传入 multichannel.Initialize 并在其中进行初始化\n在 multichannel.Initialize 会调用 etcdraft.Consenter 的 HandleChain() 也就是上面说的核心接口\n// orderer/common/server/main.go func Start(cmd string, conf *localconfig.TopLevel) { // 读取 genesis.blok bootstrapBlock := extractBootstrapBlock(conf) ... // 创建 LedgerFactory, 如果不存在 system channel 的配置块返回 nil lf, _ := createLedgerFactory(conf, metricsProvider) sysChanLastConfigBlock := extractSysChanLastConfig(lf, bootstrapBlock) // 选择引导块, 在 sysChanLastConfigBlock 和 bootstrapBlock 块中选择, 如果 sysChanLastConfigBlock 不为 nil, 则优先返回 clusterBootBlock := selectClusterBootBlock(bootstrapBlock, sysChanLastConfigBlock) ... // 判断 clusterBootBlock 中的共识类型如果是 `etcdraft` 就进行集群的初始化工作 clusterType := isClusterType(clusterBootBlock) ... // 初始化多通道 manager := initializeMultichannelRegistrar(clusterBootBlock, r, clusterDialer, clusterServerConfig, clusterGRPCServer, conf, signer, metricsProvider, opsSystem, lf, tlsCallback) } // orderer/common/server/main.go func initializeMultichannelRegistrar(...) *multichannel.Registrar { genesisBlock := extractBootstrapBlock(conf) ... registrar := multichannel.NewRegistrar(*conf, lf, signer, metricsProvider, callbacks...) ... // 加载 solo, kafka 共识 consenters[\u0026#34;solo\u0026#34;] = solo.New() var kafkaMetrics *kafka.Metrics consenters[\u0026#34;kafka\u0026#34;], kafkaMetrics = kafka.New(conf.Kafka, metricsProvider, healthChecker) ... // 判断是否是 `etcdraft` 共识, 如果是就将 etcdraft 的实例也加入到 consenters 中 if isClusterType(bootstrapBlock) { initializeEtcdraftConsenter(consenters, conf, lf, clusterDialer, bootstrapBlock, ri, srvConf, srv, registrar, metricsProvider) } registrar.Initialize(consenters) return registrar } // orderer/common/multichannel/registrar.go func (r *Registrar) Initialize(consenters map[string]consensus.Consenter) { r.consenters = consenters existingChains := r.ledgerFactory.ChainIDs() for _, chainID := range existingChains { ... // 这里判断是否是 system channel if _, ok := ledgerResources.ConsortiumsConfig(); ok { ... chain := newChainSupport( r, ledgerResources, r.consenters, r.signer, r.blockcutterMetrics, ) ... defer chain.start() } else { ... } } ... } // orderer/common/multichannel/chainsupport.go func newChainSupport(...) *ChainSupport { ... // 这里会根据 ledger 获取 ConsensusType 选择最终要用到的共识算法, 根据本文会选出 `etcdraft` consenterType := ledgerResources.SharedConfig().ConsensusType() consenter, ok := consenters[consenterType] ... // 调用 HandleChain cs.Chain, err = consenter.HandleChain(cs, metadata) ... return cs } EtcdRaft初始化 代码从现在起就进入了 etcdraft 中的核心部分, 里面可以看到系统是如何自动设置 raftID 的, 始于 HandleChain, 终于\u0026hellip;\n在 HandleChain 中会取出当前 channel 也就是 system channel 最新的配置信息并获取 ConsensusMetadata 也就是上面 json 中的 channel_group.groups.Orderer.ConsensusType.value.metadata\n这是一个数组, 系统会根据当前 orderer 所设置的证书在这个数组中的 index 来设置 raftID, 妙啊,真是妙啊!\n在这个方法中会初始化 cluster.RPC, 没错这个东西实现了上面所说 ClusterClient 核心接口, 也就是说 ClusterServer 和 ClusterClient 是一对多关系\n最终调用 etcdraft.NewChain(...) 进行 etcdraft.Chain 的创建, etcdraft.Chain 实现了 Chain 这个核心接口\n到此, 上面所说的核心接口已全部出现了\n// orderer/consensus/etcdraft/consenter.go func (c *Consenter) HandleChain(support consensus.ConsenterSupport, metadata *common.Metadata) (consensus.Chain, error) { // 获取 ConsensusMetadata m := \u0026amp;etcdraft.ConfigMetadata{} if err := proto.Unmarshal(support.SharedConfig().ConsensusMetadata(), m); err != nil { return nil, errors.Wrap(err, \u0026#34;failed to unmarshal consensus metadata\u0026#34;) } ... consenters := map[uint64]*etcdraft.Consenter{} for i, consenter := range m.Consenters { consenters[blockMetadata.ConsenterIds[i]] = consenter } // 设置ID id, err := c.detectSelfID(consenters) ... // 初始化 cluster.RPC 每一个 chan 都会有个 rpc, 也印证了我上面说的, cluster.server 和 cluster.client 是一对一关系 rpc := \u0026amp;cluster.RPC{ Timeout: c.OrdererConfig.General.Cluster.RPCTimeout, Logger: c.Logger, Channel: support.ChainID(), Comm: c.Communication, StreamsByType: cluster.NewStreamsByType(), } return NewChain( support, opts, c.Communication, rpc, func() (BlockPuller, error) { return newBlockPuller(support, c.Dialer, c.OrdererConfig.General.Cluster) }, func() { c.InactiveChainRegistry.TrackChain(support.ChainID(), nil, func() { c.CreateChain(support.ChainID()) }) }, nil, ) } // orderer/consensus/etcdraft/chan.go func NewChain(...) (*Chain, error) { ... // 此方法基本都是初始化工作, 需要注意的是 rpc 给了 chan c := \u0026amp;Chain{ configurator: conf, rpc: rpc, channelID: support.ChainID(), raftID: opts.RaftID, ... } ... // raft 的配置文件, 也是从 block 中获取的. config := \u0026amp;raft.Config{ ... } // node, 里面有 raft 的 node c.Node = \u0026amp;node{ ... } return c, nil } EtcdRaft启动 这里又要回到 newChainSupport() 中了, 这里就复制那边的代码了, 在此函数退出的时候 defer chain.start() 会调用 start 的方法\n里面会启动 etcdraft 中的 node.start() 在里面又会启动 etcd 中的 node.start().\n// orderer/consensus/etcdraft/chan.go func (c *Chain) Start() { ... // 启动了 etcdraft.Node c.Node.start(c.fresh, isJoin) ... // serveRequest 是个核心的函数, 在里面会做 raft 的角色切换等一堆的操作 go c.serveRequest() es := c.newEvictionSuspector() interval := DefaultLeaderlessCheckInterval if c.opts.LeaderCheckInterval != 0 { interval = c.opts.LeaderCheckInterval } c.periodicChecker = \u0026amp;PeriodicCheck{ Logger: c.logger, Report: es.confirmSuspicion, CheckInterval: interval, Condition: c.suspectEviction, } c.periodicChecker.Run() } // orderer/consensus/etcdraft/node.go func (n *node) start(fresh, join bool) { ... var campaign bool // 是否是新节点标记位 if fresh { // 是否是新加入标记位 if join { raftPeers = nil n.logger.Info(\u0026#34;Starting raft node to join an existing channel\u0026#34;) } else { n.logger.Info(\u0026#34;Starting raft node as part of a new channel\u0026#34;) // determine the node to start campaign by selecting the node with ID equals to: // hash(channelID) % cluster_size + 1 sha := sha256.Sum256([]byte(n.chainID)) number, _ := proto.DecodeVarint(sha[24:]) if n.config.ID == number%uint64(len(raftPeers))+1 { campaign = true } } // 最终会启动 raft 的 node. // 有点像设置配置文件. // raftPeers, 对应的就是 ETCD_INITIAL_CLUSTER n.Node = raft.StartNode(n.config, raftPeers) } else { n.logger.Info(\u0026#34;Restarting raft node\u0026#34;) n.Node = raft.RestartNode(n.config) } go n.run(campaign) } 一笔交易 Chain 接口中的 Order(...) 方法, 用于接收普通交易消息\n当一个消息进入 Order 方法中后, 会将消息封装成 orderer.SubmitRequest 并发送\n在 Chain.Submit(...) 方法中, 会先消息在封装 orderer.submit 并存入 chan Chain.submitC 通道中\n在判断 leader 是否是当前节点, 如果不是, 就会把数据通过 rpc 发送给 leader\nChain.rpc 是一个实现了 ClusterClient 可以用于将消息发送到其他的 orderer\nst=\u0026gt;start e=\u0026gt;end opOrder=\u0026gt;operation: Order(...) condLeader=\u0026gt;condition: IsLeader opRPC=\u0026gt;operation: rpc.SendSubmit(...) st-\u0026gt;opOrder-\u0026gt;condLeader(no)-\u0026gt;opRPC-\u0026gt;e condLeader(yes)-\u0026gt;e // orderer/consensus/etcdraft/chain.go func (c *Chain) Order(env *common.Envelope, configSeq uint64) error { c.Metrics.NormalProposalsReceived.Add(1) // 这里将 env, configSeq 以及 channelID 封装成了 SubmitRequest 并发给了 Submit 方法 return c.Submit(\u0026amp;orderer.SubmitRequest{LastValidationSeq: configSeq, Payload: env, Channel: c.channelID}, 0) } // orderer/consensus/etcdraft/chain.go func (c *Chain) Submit(req *orderer.SubmitRequest, sender uint64) error { ... // 获取一个 chan 用于接收网络当前的 leader leadC := make(chan uint64, 1) select { // 这个 case 就是将 req, 以及用于接收 leader 的 chan, 再次封装发给了 Chain 中的 chan submitC case c.submitC \u0026lt;- \u0026amp;submit{req, leadC}: // 等待 submitC 被处理, 并返回 leader 的 id lead := \u0026lt;-leadC // 如果没有 leader 就报错 if lead == raft.None { c.Metrics.ProposalFailures.Add(1) return errors.Errorf(\u0026#34;no Raft leader\u0026#34;) } // 如果自己不是 leader, 就会将消息发给 leader. if lead != c.raftID { if err := c.rpc.SendSubmit(lead, req); err != nil { c.Metrics.ProposalFailures.Add(1) return err } } ... return nil } 一个块的同步 这个方法, 我认为算是 etcdraft 核心方法了, 有兴趣的小伙伴可以深究一下这个方法\n里面涉及到了 Leader, Follower 的角色切换, 共识等实现\n这里还是跟着上一步继续向下深究, 在交易消息到达 Leader 后就要开始共识了\n如果节点是 Leader 则会进行排序\n// orderer/consensus/etcdraft/chain.go func (c *Chain) serveRequest() { ... // 下方会使用到里面的协程 becomeLeader := func() (chan\u0026lt;- *common.Block, context.CancelFunc) { ... ctx, cancel := context.WithCancel(context.Background()) go func(ctx context.Context, ch \u0026lt;-chan *common.Block) { for { select { case b := \u0026lt;-ch: data := utils.MarshalOrPanic(b) // 这里会丢给 raft node 进行同步 block, 里面的处理非常复杂.., 属于 raft 中的东西了, 这里就不细追了. if err := c.Node.Propose(ctx, data); err != nil { c.logger.Errorf(\u0026#34;Failed to propose block [%d] to raft and discard %d blocks in queue: %s\u0026#34;, b.Header.Number, len(ch), err) return } c.logger.Debugf(\u0026#34;Proposed block [%d] to raft consensus\u0026#34;, b.Header.Number) case \u0026lt;-ctx.Done(): c.logger.Debugf(\u0026#34;Quit proposing blocks, discarded %d blocks in the queue\u0026#34;, len(ch)) return } } }(ctx, ch) return ch, cancel } ... for { select { case s := \u0026lt;-submitC: // leader 进行出块操作, 如果未符合要求,比如大小不够, 就会 pending batches, pending, err := c.ordered(s.req) if err != nil { c.logger.Errorf(\u0026#34;Failed to order message: %s\u0026#34;, err) continue } if pending { startTimer() // no-op if timer is already started } else { stopTimer() } // 生成生成 block 并将 block 传给 propC, propC 是一个 chan 结构, 所以会给上面的协程做处理 c.propose(propC, bc, batches...) if c.configInflight { c.logger.Info(\u0026#34;Received config transaction, pause accepting transaction till it is committed\u0026#34;) submitC = nil } else if c.blockInflight \u0026gt;= c.opts.MaxInflightBlocks { c.logger.Debugf(\u0026#34;Number of in-flight blocks (%d) reaches limit (%d), pause accepting transaction\u0026#34;, c.blockInflight, c.opts.MaxInflightBlocks) submitC = nil } ... case \u0026lt;-timer.C(): ticking = false batch := c.support.BlockCutter().Cut() if len(batch) == 0 { c.logger.Warningf(\u0026#34;Batch timer expired with no pending requests, this might indicate a bug\u0026#34;) continue } c.logger.Debugf(\u0026#34;Batch timer expired, creating block\u0026#34;) c.propose(propC, bc, batch) // we are certain this is normal block, no need to block } } } 一个块的存储 根据 raft 共识同步消息的流程是 uncommitted -\u0026gt; committed 两个阶段, 都会在上面完成\n如果是 committed 就会去写块\n// orderer/consensus/etcdraft/chain.go func (c *Chain) serveRequest() { ... // 下方会使用到里面的协程 becomeLeader := func() (chan\u0026lt;- *common.Block, context.CancelFunc) { ... ctx, cancel := context.WithCancel(context.Background()) go func(ctx context.Context, ch \u0026lt;-chan *common.Block) { for { select { case b := \u0026lt;-ch: data := utils.MarshalOrPanic(b) // 这里会丢给 raft node 进行同步 block, 里面的处理非常复杂.., 属于 raft 中的东西了, 这里就不细追了. if err := c.Node.Propose(ctx, data); err != nil { c.logger.Errorf(\u0026#34;Failed to propose block [%d] to raft and discard %d blocks in queue: %s\u0026#34;, b.Header.Number, len(ch), err) return } c.logger.Debugf(\u0026#34;Proposed block [%d] to raft consensus\u0026#34;, b.Header.Number) case \u0026lt;-ctx.Done(): c.logger.Debugf(\u0026#34;Quit proposing blocks, discarded %d blocks in the queue\u0026#34;, len(ch)) return } } }(ctx, ch) return ch, cancel } ... for { select { ... case app := \u0026lt;-c.applyC: ... // 这里面会讲 raftlog 中的 block 落地. c.apply(app.entries) ... } } } // orderer/consensus/etcdraft/chain.go func (c *Chain) apply(ents []raftpb.Entry) { ... for i := range ents { // 只有两种类型 EntryNormal, EntryConfChange, block 消息是 EntryNormal switch ents[i].Type { case raftpb.EntryNormal: ... block := utils.UnmarshalBlockOrPanic(ents[i].Data) // 这里就会写入 block 了 c.writeBlock(block, ents[i].Index) c.Metrics.CommittedBlockNumber.Set(float64(block.Header.Number)) ... case raftpb.EntryConfChange: ... } if ents[i].Index \u0026gt; c.appliedIndex { c.appliedIndex = ents[i].Index } } if c.accDataSize \u0026gt;= c.sizeLimit { b := utils.UnmarshalBlockOrPanic(ents[position].Data) select { case c.gcC \u0026lt;- \u0026amp;gc{index: c.appliedIndex, state: c.confState, data: ents[position].Data}: c.logger.Infof(\u0026#34;Accumulated %d bytes since last snapshot, exceeding size limit (%d bytes), \u0026#34;+ \u0026#34;taking snapshot at block [%d] (index: %d), last snapshotted block number is %d, current nodes: %+v\u0026#34;, c.accDataSize, c.sizeLimit, b.Header.Number, c.appliedIndex, c.lastSnapBlockNum, c.confState.Nodes) c.accDataSize = 0 c.lastSnapBlockNum = b.Header.Number c.Metrics.SnapshotBlockNumber.Set(float64(b.Header.Number)) default: c.logger.Warnf(\u0026#34;Snapshotting is in progress, it is very likely that SnapshotIntervalSize is too small\u0026#34;) } } return } ","permalink":"https://mioto.me/posts/etcdraft-exploration-in-fabric-orderer/","summary":"为什么要通过 etcdraft 来进行共识?\n我觉得有以下原因\nsolo 并不适合大多数场景, 例如: 组织A, 组织B, 都想在自己放置共识节点 kafka 虽然能满足以上需求, 但是 kafka 加上 zookeeper 需要额外部署并且实在是太重了, 不方便部署 所以基于 etcdraft 的共识来了, 解决了以上的痛点\n重要的话说三遍!\n千万不要错过文章中的源码部分, 里面有很多很多的注释!!! 千万不要错过文章中的源码部分, 里面有很多很多的注释!!! 千万不要错过文章中的源码部分, 里面有很多很多的注释!!!\n核心接口 以下是我认为实现 etcdraft 共识核心的接口\n// ClusterServer 集群Server接口 type ClusterServer interface { Step(Cluster_StepServer) error } // ClusterClient 集群Client接口 type ClusterClient interface { Step(ctx context.Context, opts ...grpc.CallOption) (orderer.Cluster_StepClient, error) } // Handler 用于共识的两个接口 type Handler interface { OnConsensus(channel string, sender uint64, req *orderer.ConsensusRequest) error OnSubmit(channel string, sender uint64, req *orderer.","title":"Fabric 中 etcdraft 共识讲解"},{"content":"第一次写年终总结, 每次准备写脑海里都飘过 \u0026ldquo;你比上一年又重了N公斤\u0026rdquo;, 今年可以写的感觉也并不多, 但是总结一下总是好的.\n体重 涨幅 0.052, 目前体重算 95KG 好了, 另外明年的目标一定要下降到 70 左右!!!\n加薪 涨幅 0.428, 虽然加薪来的迟了, 但是总比没有要好.\n学习 虽然 Hyperledger Fabric 国密支持并不是我实现, 但是我也充分参与到了其中, 算是对 TLS, 加密, 签名, 证书 有了较为深入的研究. 完成了对 Hyperledger Fabric statedb 的扩展, 支持了 TiDB. 部署实施了两个 Hyperledger Fabric 的落地项目. 对 Hyperledger Fabric 以及 Hyperledger Fabric Go SDK 有了较为深入的了解. 给 Hyperledger Fabric Go SDK 贡献了2次源码, 支持了 Java Chaincode 的 安装, 实例化, 升级. 编写了 hlf-deploy 项目, 支持了几乎所有的 Hyperledger Fabric 所有的操作, 例如: 动态更新通道, 动态切换共识算法 等. Drone CI项目的部署以及应用, 并贡献了一个插件 drone-serverchan. 编写了自己的简易 Log 包, glog. SIP 协议, 有稍微的涉足, 来源于朋友的项目. 稍微了解了 Tendermint 项目. 文章 今年一共水了 6 篇文章.\n破解某Wi-Fi探针魔盒的过程 部署 Kubernetes 遇到的问题 Go HTTP POST 附件 Negroni 源码分析 Go 解析 ECPrivate Key 遇到的问题 i3wm 更换默认打开的文件管理器 动漫 数不过来了, 今天 bilibili 正好推送了2019年度报告, 经常在 晚上, 深夜 看番, 一共看了 94 部动画, 可见我的时间都去哪里了!\n这里就列出我最喜欢的 6 部好了, 排名不分先后.\n鬼灭之刃 紫罗兰永恒花园 月色真美 终将成为你 文学少女 冰海战记 ","permalink":"https://mioto.me/posts/2019review/","summary":"第一次写年终总结, 每次准备写脑海里都飘过 \u0026ldquo;你比上一年又重了N公斤\u0026rdquo;, 今年可以写的感觉也并不多, 但是总结一下总是好的.\n体重 涨幅 0.052, 目前体重算 95KG 好了, 另外明年的目标一定要下降到 70 左右!!!\n加薪 涨幅 0.428, 虽然加薪来的迟了, 但是总比没有要好.\n学习 虽然 Hyperledger Fabric 国密支持并不是我实现, 但是我也充分参与到了其中, 算是对 TLS, 加密, 签名, 证书 有了较为深入的研究. 完成了对 Hyperledger Fabric statedb 的扩展, 支持了 TiDB. 部署实施了两个 Hyperledger Fabric 的落地项目. 对 Hyperledger Fabric 以及 Hyperledger Fabric Go SDK 有了较为深入的了解. 给 Hyperledger Fabric Go SDK 贡献了2次源码, 支持了 Java Chaincode 的 安装, 实例化, 升级. 编写了 hlf-deploy 项目, 支持了几乎所有的 Hyperledger Fabric 所有的操作, 例如: 动态更新通道, 动态切换共识算法 等.","title":"回顾 2019"},{"content":"目标是现实一个 HTTP HTTPS 的代理服务器, 目前代理的实现方法有两种\n普通代理: 这种代理扮演的是中间人角色, 对于客户端来说, 它就服务器, 对于服务端来说, 它是客户端, 它负责在中间来回传递 HTTP 报文\n隧道代理: 它是通过 HTTP 正文部分(body) 完成代理, 以 HTTP 的方式实现基于 TCP 的应用层协议代理, 这种代理使用 HTTP 的 CONNECT 方法建立连接\n这是一次 HTTP 的请求, 用 \\r\\n 进行换行, 碰到连续两个 \\r\\n 后内容为请求数据, 分为以下几个部分\n请求行 (request line) 请求头 (header) 空行 请求数据 (body) curl -Lv http://baidu.com \u0026gt; GET / HTTP/1.1 \u0026gt; Host: baidu.com \u0026gt; User-Agent: curl/7.68.0 \u0026gt; Accept: */* \u0026gt; * Mark bundle as not supporting multiuse \u0026lt; HTTP/1.1 200 OK \u0026lt; Date: Thu, 25 Jun 2020 12:12:32 GMT \u0026lt; Server: Apache \u0026lt; Last-Modified: Tue, 12 Jan 2010 13:48:00 GMT \u0026lt; ETag: \u0026#34;51-47cf7e6ee8400\u0026#34; \u0026lt; Accept-Ranges: bytes \u0026lt; Content-Length: 81 \u0026lt; Cache-Control: max-age=86400 \u0026lt; Expires: Fri, 26 Jun 2020 12:12:32 GMT \u0026lt; Connection: Keep-Alive \u0026lt; Content-Type: text/html \u0026lt; \u0026lt;html\u0026gt; \u0026lt;meta http-equiv=\u0026#34;refresh\u0026#34; content=\u0026#34;0;url=http://www.baidu.com/\u0026#34;\u0026gt; \u0026lt;/html\u0026gt; 实现 package main import ( \u0026#34;io\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;time\u0026#34; ) func handleTunneling(w http.ResponseWriter, r *http.Request) { destConn, err := net.DialTimeout(\u0026#34;tcp\u0026#34;, r.Host, 10*time.Second) if err != nil { http.Error(w, err.Error(), http.StatusServiceUnavailable) return } w.WriteHeader(http.StatusOK) hijacker, ok := w.(http.Hijacker) if !ok { http.Error(w, \u0026#34;Hijacking not supported\u0026#34;, http.StatusInternalServerError) return } clientConn, _, err := hijacker.Hijack() if err != nil { http.Error(w, err.Error(), http.StatusServiceUnavailable) } go transfer(destConn, clientConn) go transfer(clientConn, destConn) } func transfer(destination io.WriteCloser, source io.ReadCloser) { defer destination.Close() defer source.Close() io.Copy(destination, source) } func handleHTTP(w http.ResponseWriter, req *http.Request) { resp, err := http.DefaultTransport.RoundTrip(req) if err != nil { http.Error(w, err.Error(), http.StatusServiceUnavailable) return } defer resp.Body.Close() copyHeader(w.Header(), resp.Header) w.WriteHeader(resp.StatusCode) io.Copy(w, resp.Body) } func copyHeader(dst, src http.Header) { for k, vv := range src { for _, v := range vv { dst.Add(k, v) } } } func main() { server := \u0026amp;http.Server{ Addr: \u0026#34;:8888\u0026#34;, Handler: http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) { if r.Method == http.MethodConnect { handleTunneling(w, r) } else { handleHTTP(w, r) } }), // Disable HTTP/2. TLSNextProto: make(map[string]func(*http.Server, *tls.Conn, http.Handler)), } log.Fatal(server.ListenAndServe()) } 以上代码不适用于生产环境\n上述代码实现了普通代理和隧道代理两个方法, 通过判断请求方是否使用 CONNECT 方法请求代理服务器 来区分不同的处理逻辑\nhttp.HandlerFunc(func(w http.ResponseWriter, r *http.Request) { if r.Method == http.MethodConnect { handleTunneling(w, r) } else { handleHTTP(w, r) } }) 基于普通代理的逻辑是容易理解的, 这里主要看一下是如何实现基于隧道代理的, handleTunneling 第一步是建立和目标服务器的连接\ndestConn, err := net.DialTimeout(\u0026#34;tcp\u0026#34;, r.Host, 10*time.Second) if err != nil { http.Error(w, err.Error(), http.StatusServiceUnavailable) return } w.WriteHeader(http.StatusOK) 下一步是劫持 HTTP 服务维持的连接, net.Conn 类型\nhijacker, ok := w.(http.Hijacker) if !ok { http.Error(w, \u0026#34;Hijacking not supported\u0026#34;, http.StatusInternalServerError) return } clientConn, _, err := hijacker.Hijack() if err != nil { http.Error(w, err.Error(), http.StatusServiceUnavailable) } Hijacker interface 获取连接后, 调用者来 维护此连接, HTTP 标准库就不会在负责管理了\n这时已经建立了两个 TCP 连接(客户端 -\u0026gt; 代理端, 代理端 -\u0026gt; 目标服务器), 最后一步就是互相转发 他们的消息\ngo transfer(destConn, clientConn) go transfer(clientConn, destConn) 测试 使用 Chrome:\nChrome --proxy-server=https://localhost:8888 使用 Curl:\ncurl -Lv --proxy https://localhost:8888 --proxy-cacert server.pem https://baidu.com 参考 https://medium.com/@mlowicki/http-s-proxy-in-golang-in-less-than-100-lines-of-code-6a51c2f2c38c https://imququ.com/post/web-proxy.html ","permalink":"https://mioto.me/posts/http-s-proxy-in-golang-in-less-than-100-lines-of-code/","summary":"目标是现实一个 HTTP HTTPS 的代理服务器, 目前代理的实现方法有两种\n普通代理: 这种代理扮演的是中间人角色, 对于客户端来说, 它就服务器, 对于服务端来说, 它是客户端, 它负责在中间来回传递 HTTP 报文\n隧道代理: 它是通过 HTTP 正文部分(body) 完成代理, 以 HTTP 的方式实现基于 TCP 的应用层协议代理, 这种代理使用 HTTP 的 CONNECT 方法建立连接\n这是一次 HTTP 的请求, 用 \\r\\n 进行换行, 碰到连续两个 \\r\\n 后内容为请求数据, 分为以下几个部分\n请求行 (request line) 请求头 (header) 空行 请求数据 (body) curl -Lv http://baidu.com \u0026gt; GET / HTTP/1.1 \u0026gt; Host: baidu.com \u0026gt; User-Agent: curl/7.68.0 \u0026gt; Accept: */* \u0026gt; * Mark bundle as not supporting multiuse \u0026lt; HTTP/1.","title":"Go 100 行实现 HTTP(S) 正向代理"},{"content":"有个老同学，在老家做销售工作， 某一天忽然联系我说我有个路由器可以扫描周边的 MAC Address 直接得到手机号，我一听这个牛逼啊，然后就让把路由器发来玩玩了\n这东西有两个部分一个是手机应用程序，一个是路由器。\nApp抓包 最初设想路由器既然要用 Wi-Fi 手机当作热点数据必定经过手机，说干就干，下载了个 HttpCanary 然后对 App 抓包\n过滤掉没用的接口后得到了两个核心接口（说真的 App 设计的真心让人恶心，所有权限都要可能为了读取手机上的联系人把）\n用来获取已经匹配到的手机号的接口 GET http://x.hnyzlp.com/api/merchart/Operative/phone 用来设置心跳的接口，同时设置经纬度 GET http://x.hnyzlp.com/api/merchart/Operative/set_address 到此为止并没有 MAC 实际发出的地址， 所以由此可证明路由器直接将数据发送到了远端服务器，这条路被斩断了\n路由器抓包 起初想的是通过 ARP 诈骗让自己家的路由器把数据发送到我指定的设备来实现抓包，但是！Mac 下各种问题，搞了一个多小时没搞定，卒！\n后来想起来我的路由器是可编程的啊！，于是乎找了个 AC68U 可用的 tcpdump 路由器上抓指定网卡的的指定IP，然后！又得到了两个核心接口\n用来设置路由器心跳， 一分钟请求一次 获取路由器上的运行时间， ARM 状况 等。 POST http://api.swsf3.cn/api_v1/remotecontrol 用来发送 mac 地址到服务端， 频率是 30 秒一次 POST http://api.swsf3.cn/api_v2/report 由此可见所有东西都全了！， 上传数据的接口， 以及查看数据的接口\n","permalink":"https://mioto.me/posts/cracking-mohe-process/","summary":"有个老同学，在老家做销售工作， 某一天忽然联系我说我有个路由器可以扫描周边的 MAC Address 直接得到手机号，我一听这个牛逼啊，然后就让把路由器发来玩玩了\n这东西有两个部分一个是手机应用程序，一个是路由器。\nApp抓包 最初设想路由器既然要用 Wi-Fi 手机当作热点数据必定经过手机，说干就干，下载了个 HttpCanary 然后对 App 抓包\n过滤掉没用的接口后得到了两个核心接口（说真的 App 设计的真心让人恶心，所有权限都要可能为了读取手机上的联系人把）\n用来获取已经匹配到的手机号的接口 GET http://x.hnyzlp.com/api/merchart/Operative/phone 用来设置心跳的接口，同时设置经纬度 GET http://x.hnyzlp.com/api/merchart/Operative/set_address 到此为止并没有 MAC 实际发出的地址， 所以由此可证明路由器直接将数据发送到了远端服务器，这条路被斩断了\n路由器抓包 起初想的是通过 ARP 诈骗让自己家的路由器把数据发送到我指定的设备来实现抓包，但是！Mac 下各种问题，搞了一个多小时没搞定，卒！\n后来想起来我的路由器是可编程的啊！，于是乎找了个 AC68U 可用的 tcpdump 路由器上抓指定网卡的的指定IP，然后！又得到了两个核心接口\n用来设置路由器心跳， 一分钟请求一次 获取路由器上的运行时间， ARM 状况 等。 POST http://api.swsf3.cn/api_v1/remotecontrol 用来发送 mac 地址到服务端， 频率是 30 秒一次 POST http://api.swsf3.cn/api_v2/report 由此可见所有东西都全了！， 上传数据的接口， 以及查看数据的接口","title":"破解某Wi-Fi探针魔盒的过程"},{"content":"Unable to update cni config: No networks found in /etc/cni/net.d 由于设置了代理导致的错误, kubelet 无法通过代理链接到 kube-apiserve\n解决办法:\nunset http_proxy https_proxy # or export no_proxy=\u0026lt;your_kube_apiserver_ip\u0026gt; port 10251 and 10252 are in use 多次 init 导致的错误\n解决办法:\nkubeadm reset ROLES none 关于 ROLES \u0026lt;none\u0026gt; 的问题, 据说在 kubeadm join 的时候可以指定, 不过我每次都没看..\n解决办法:\n# 添加标签 kubectl label node {node name} node-role.kubernetes.io/{key}={value} # example kubectl label node host2 node-role.kubernetes.io/node2=node2 # 删除标签 kubectl label node {node name} node-role.kubernetes.io/{key}- # example kubectl label node host2 node-role.kubernetes.io/node2- 让 Master 也进行 Pod 调度 在开发环境上 master 也进行 Pod 调度是个不错的选择\n# 允许调度 pod kubectl taint node {node name} node-role.kubernetes.io/master- # example kubectl taint node host1 node-role.kubernetes.io/master- # 禁止调度 pod kubectl taint node {node name} node-role.kubernetes.io/master=master # example kubectl taint node host1 node-role.kubernetes.io/master=master 有时可能过了一段时间需要添加新的 node # 生成一个 token kubeadm token generate # 获取证书的 hash 值 openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2\u0026gt;/dev/null | \\ \u0026gt; openssl dgst -sha256 -hex | sed \u0026#39;s/^.* //\u0026#39; # kubeadm join --token \u0026lt;token\u0026gt; \u0026lt;master-ip\u0026gt;:\u0026lt;master-port\u0026gt; --discovery-token-ca-cert-hash sha256:\u0026lt;hash\u0026gt; # example kubeadm join --token xf96mj.aq2c5v14r62rf2aw 172.16.50.10:6443 --discovery-token-ca-cert-hash sha256:a18c59189884451f71305a0107d15b79a8ac091ef9a8b9e394cad5d4b9f18162 ","permalink":"https://mioto.me/posts/problem-swith-deploying-kubernetes/","summary":"Unable to update cni config: No networks found in /etc/cni/net.d 由于设置了代理导致的错误, kubelet 无法通过代理链接到 kube-apiserve\n解决办法:\nunset http_proxy https_proxy # or export no_proxy=\u0026lt;your_kube_apiserver_ip\u0026gt; port 10251 and 10252 are in use 多次 init 导致的错误\n解决办法:\nkubeadm reset ROLES none 关于 ROLES \u0026lt;none\u0026gt; 的问题, 据说在 kubeadm join 的时候可以指定, 不过我每次都没看..\n解决办法:\n# 添加标签 kubectl label node {node name} node-role.kubernetes.io/{key}={value} # example kubectl label node host2 node-role.kubernetes.io/node2=node2 # 删除标签 kubectl label node {node name} node-role.kubernetes.io/{key}- # example kubectl label node host2 node-role.","title":"部署 Kubernetes 遇到的问题"},{"content":"前段时间为了使用 adb 进行钉钉打卡, 写了个 Go 的程序, 想着万一没打上怎么办, 不如截个图发给自己(现在以 root, 辣鸡钉钉), 文章只为了记录一下实现.\n// curl -X POST https://example.com/sendPhoto -F photo=@./screen.png // 以下代码是根据以上 curl 命令的实现 buf := \u0026amp;bytes.Buffer{} mu := multipart.NewWriter(buf) part, err := mu.CreatePart(textproto.MIMEHeader{ \u0026#34;Content-Disposition\u0026#34;: []string{`form-data; name=\u0026#34;photo\u0026#34;; filename=\u0026#34;screen.png\u0026#34;`}, \u0026#34;Content-Type\u0026#34;:[]string{\u0026#34;application/octet-stream\u0026#34;}, }) checkError(err) fp, _ := os.Open(\u0026#34;/home/mioto/screen.png\u0026#34;) io.Copy(part, fp) mu.Close() req, err := http.NewRequest(http.MethodPost, \u0026#34;https://example.com/sendPhoto\u0026#34;, bf) checkError(err) req.Header.Set(\u0026#34;Content-Type\u0026#34;, mu.FormDataContentType()) res, err := http.DefaultClient.Do(req) checkError(err) ","permalink":"https://mioto.me/posts/go-http-post-attachment/","summary":"前段时间为了使用 adb 进行钉钉打卡, 写了个 Go 的程序, 想着万一没打上怎么办, 不如截个图发给自己(现在以 root, 辣鸡钉钉), 文章只为了记录一下实现.\n// curl -X POST https://example.com/sendPhoto -F photo=@./screen.png // 以下代码是根据以上 curl 命令的实现 buf := \u0026amp;bytes.Buffer{} mu := multipart.NewWriter(buf) part, err := mu.CreatePart(textproto.MIMEHeader{ \u0026#34;Content-Disposition\u0026#34;: []string{`form-data; name=\u0026#34;photo\u0026#34;; filename=\u0026#34;screen.png\u0026#34;`}, \u0026#34;Content-Type\u0026#34;:[]string{\u0026#34;application/octet-stream\u0026#34;}, }) checkError(err) fp, _ := os.Open(\u0026#34;/home/mioto/screen.png\u0026#34;) io.Copy(part, fp) mu.Close() req, err := http.NewRequest(http.MethodPost, \u0026#34;https://example.com/sendPhoto\u0026#34;, bf) checkError(err) req.Header.Set(\u0026#34;Content-Type\u0026#34;, mu.FormDataContentType()) res, err := http.DefaultClient.Do(req) checkError(err) ","title":"Go HTTP POST 附件"},{"content":"最近在做 fabric 证书私钥管理系统, 遇到的一个问题, 在使用 x509.ParseECPrivateKey() 方法的时候会直接报错, 而 fabric 确实用的是 椭圆曲线算法\n错误输出: x509: failed to parse EC private key: asn1: structure error: tags don't match (4 vs {class:0 tag:16 length:19 isCompound:true}) {optional:false explicit:false application:false private:false defaultValue:\u0026lt;nil\u0026gt; tag:\u0026lt;nil\u0026gt; stringType:0 timeType:0 set:false omitEmpty:false} @5\n原因是 fabric 将私钥转成 pem 格式的时候使用的方法是 x509.MarshalPKCS8PrivateKey()\n解决办法 block, _ := pem.Decode(pemBytes) key, err := x509.ParsePKCS8PrivateKey(block.Bytes) checkErr(err) switch priv := key.(type) { case *ecdsa.PrivateKey: // do something } ","permalink":"https://mioto.me/posts/go-parse-ec-private-key/","summary":"最近在做 fabric 证书私钥管理系统, 遇到的一个问题, 在使用 x509.ParseECPrivateKey() 方法的时候会直接报错, 而 fabric 确实用的是 椭圆曲线算法\n错误输出: x509: failed to parse EC private key: asn1: structure error: tags don't match (4 vs {class:0 tag:16 length:19 isCompound:true}) {optional:false explicit:false application:false private:false defaultValue:\u0026lt;nil\u0026gt; tag:\u0026lt;nil\u0026gt; stringType:0 timeType:0 set:false omitEmpty:false} @5\n原因是 fabric 将私钥转成 pem 格式的时候使用的方法是 x509.MarshalPKCS8PrivateKey()\n解决办法 block, _ := pem.Decode(pemBytes) key, err := x509.ParsePKCS8PrivateKey(block.Bytes) checkErr(err) switch priv := key.(type) { case *ecdsa.PrivateKey: // do something } ","title":"Go 解析 ECPrivate Key 遇到的问题"},{"content":"可以通过 xdg-mime 来查询当前默认的文件管理器 xdg-mime query default inode/directory\nmioto:~/ $ xdg-mime query default inode/directory visual-studio-code.desktop 方法一 还是可以通过 xdg-mime 来设置默认文件管理器 xdg-mime default {file manager}.desktop inode/directory\nmioto:~/ $ xdg-mime default ranger.desktop inode/directory mioto:~/ $ xdg-mime query default inode/directory ranger.desktop 方法二 我记录有2个 mimeapps.list 文件修改点\n~/.local/share/applications/mimeapps.list, ~/.config/mimeapps.list 选一个修改(没有添加) inode/directory=ranger.desktop\n但是我的系统 Manjaro-I3 使用的是 ~/.config/mimeapps.list, 所以有针对性的修改就行\n","permalink":"https://mioto.me/posts/i3-change-default-file-manager/","summary":"可以通过 xdg-mime 来查询当前默认的文件管理器 xdg-mime query default inode/directory\nmioto:~/ $ xdg-mime query default inode/directory visual-studio-code.desktop 方法一 还是可以通过 xdg-mime 来设置默认文件管理器 xdg-mime default {file manager}.desktop inode/directory\nmioto:~/ $ xdg-mime default ranger.desktop inode/directory mioto:~/ $ xdg-mime query default inode/directory ranger.desktop 方法二 我记录有2个 mimeapps.list 文件修改点\n~/.local/share/applications/mimeapps.list, ~/.config/mimeapps.list 选一个修改(没有添加) inode/directory=ranger.desktop\n但是我的系统 Manjaro-I3 使用的是 ~/.config/mimeapps.list, 所以有针对性的修改就行","title":"i3wm 更换默认打开的文件管理器"},{"content":"默认得到的序列化后的结果是 {\u0026quot;t\u0026quot;:\u0026quot;2018-11-25T20:04:51.362485618+08:00\u0026quot;}, 但如果我想得到 {\u0026quot;t\u0026quot;:\u0026quot;2018-11-25 20:04:51\u0026quot;} 该怎么办呢?\n方法一 实现 MarshalJSON 接口, 同时可能也需要反序列化, 所以还需要实现 UnmarshalJSON, 以下代码为实现\npackage main import ( \u0026#34;encoding/json\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) type Time struct { T time.Time `json:\u0026#34;t,omitempty\u0026#34;` } func (t *Time) MarshalJSON() ([]byte, error) { type alias Time return json.Marshal(struct { *alias T string `json:\u0026#34;t,omitempty\u0026#34;` }{ alias: (*alias)(t), T: t.T.Format(\u0026#34;2006-01-02 15:04:05\u0026#34;), }) } func (t *Time) UnmarshalJSON(data []byte) error { type alias Time tmp := \u0026amp;struct { *alias T string `json:\u0026#34;t,omitempty\u0026#34;` }{ alias: (*alias)(t), } err := json.Unmarshal(data, tmp) if err != nil { return err } t.T, err = time.Parse(`2006-01-02 15:04:05`, tmp.T) if err != nil { return err } return nil } func main() { t := \u0026amp;Time{ T: time.Now(), } tBytes, _ := json.Marshal(t) fmt.Println(string(tBytes)) t = \u0026amp;Time{} _ = json.Unmarshal(tBytes, t) fmt.Println(t.T) } // output: // // {\u0026#34;t\u0026#34;:\u0026#34;2018-11-25 20:17:53\u0026#34;} // 2018-11-25 21:03:35 +0000 UTC 方法二 不使用 time.Time, 而是自己重新定义一个时间类型, 例如 JSONTime, 并实现它的 MarshalJSON UnmarshalJSON 接口, 这样做的好处是 所有都通用, 不需要在用到的类型中反复实现 这两个接口, 以下为实现\npackage main import ( \u0026#34;encoding/json\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) type JSONTime struct { time.Time } func (t *JSONTime) MarshalJSON() ([]byte, error) { return []byte(fmt.Sprintf(`\u0026#34;%s\u0026#34;`, t.Format(\u0026#34;2006-01-02 15:04:05\u0026#34;))), nil } func (t *JSONTime) UnmarshalJSON(data []byte) error { var err error t.Time, err = time.Parse(`\u0026#34;2006-01-02 15:04:05\u0026#34;`, string(data)) if err != nil { return err } return nil } type Time struct { T JSONTime `json:\u0026#34;t,omitempty\u0026#34;` } func main() { t := \u0026amp;Time{ T: JSONTime{time.Now()}, } tBytes, _ := json.Marshal(t) fmt.Println(string(tBytes)) t = \u0026amp;Time{} _ = json.Unmarshal(tBytes, t) fmt.Println(t.T) } // output: // // {\u0026#34;t\u0026#34;:\u0026#34;2018-11-25 21:14:33\u0026#34;} // 2018-11-25 21:14:33 +0000 UTC 参考 https://stackoverflow.com/questions/23695479/format-timestamp-in-outgoing-json-in-golang http://choly.ca/post/go-json-marshalling ","permalink":"https://mioto.me/posts/go-serialize-json-fromat-time/","summary":"默认得到的序列化后的结果是 {\u0026quot;t\u0026quot;:\u0026quot;2018-11-25T20:04:51.362485618+08:00\u0026quot;}, 但如果我想得到 {\u0026quot;t\u0026quot;:\u0026quot;2018-11-25 20:04:51\u0026quot;} 该怎么办呢?\n方法一 实现 MarshalJSON 接口, 同时可能也需要反序列化, 所以还需要实现 UnmarshalJSON, 以下代码为实现\npackage main import ( \u0026#34;encoding/json\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) type Time struct { T time.Time `json:\u0026#34;t,omitempty\u0026#34;` } func (t *Time) MarshalJSON() ([]byte, error) { type alias Time return json.Marshal(struct { *alias T string `json:\u0026#34;t,omitempty\u0026#34;` }{ alias: (*alias)(t), T: t.T.Format(\u0026#34;2006-01-02 15:04:05\u0026#34;), }) } func (t *Time) UnmarshalJSON(data []byte) error { type alias Time tmp := \u0026amp;struct { *alias T string `json:\u0026#34;t,omitempty\u0026#34;` }{ alias: (*alias)(t), } err := json.","title":"Go反序列化JSON格式化时间"},{"content":"买 Raspberry Zero 的原因呢, 是因为钉钉打卡, 每次可能晚了那么几分钟, 但我就是起不来啊\u0026hellip;\n这篇文章主要讲三个点 无屏幕 SSH, Static IP, 开启OTG模式\nSSH 当然在 ssh 的时候要保证 Raspberry Zero 是有网的状态, 编辑第二个分区 wpa-supplicant 的配置文件 /etc/wpa_supplicant/wpa_supplicant.conf\n基本网络配置 network={ ssid=\u0026#34;testing\u0026#34; psk=\u0026#34;testingPassword\u0026#34; } ssid 无线网络名称, psk 无线网络密码\n隐藏网络配置 network={ ssid=\u0026#34;testing\u0026#34; scan_ssid=1 psk=\u0026#34;testingPassword\u0026#34; } 多个网络配置 network={ ssid=\u0026#34;HomeOneSSID\u0026#34; psk=\u0026#34;passwordOne\u0026#34; priority=1 id_str=\u0026#34;homeOne\u0026#34; } network={ ssid=\u0026#34;HomeTwoSSID\u0026#34; psk=\u0026#34;passwordTwo\u0026#34; priority=2 id_str=\u0026#34;homeTwo\u0026#34; } priority 网络优先级\n连接 SSH 如果网络配置没问题的话,现在应该已经连接上了无线网络了, 接下来就是在无屏幕状态下如何 ssh 到 Raspberry Zero\n挂载第一分区在 / 目录创建 SSH 文件就可以了, 然后插电启动 Raspberry Zero 等待自动连接到网络后进行后续操作\n如果能进路由器管理页面, 那很简单了找到 Raspberry 的 IP, 然后直接 ssh\n如果没有路由器管理页面的权限, 需要做的事情是 扫描网络中 22 端口 开启的机器, 然后找出 Raspberry Zero 的 IP\nsudo nmap -sS -O 192.168.199.0/24 扫描整个网段 22 端口开启的设备, 然后一个一个试过去\u0026hellip;\nStatic IP 编辑 /etc/dhcpcd.conf\ninterface eth0 static ip_address=192.168.0.2/24 static routers=192.168.0.1 static domain_name_servers=192.168.0.1 interface wlan0 static ip_address=192.168.0.2/24 static routers=192.168.0.1 static domain_name_servers=192.168.0.1 照着这个格式写好, 就万事大吉了!\n开启OTG模式 挂载SD卡的第一个分区 编辑 config.txt 在尾部添加一行 dtoverlay=dwc2 保存退出 编辑 cmdline.txt 在 rootwait 后面添加 modules-load=dwc2,g_ether 保存退出 插卡重启! 参考 https://www.raspberrypi.org/documentation/configuration/wireless/wireless-cli.md https://www.raspberrypi.org/learning/networking-lessons/rpi-static-ip-address/ https://www.raspberrypi.org/documentation/remote-access/ssh/ https://gist.github.com/gbaman/975e2db164b3ca2b51ae11e45e8fd40a ","permalink":"https://mioto.me/posts/raspberry-zero-network-and-otg-configuration/","summary":"买 Raspberry Zero 的原因呢, 是因为钉钉打卡, 每次可能晚了那么几分钟, 但我就是起不来啊\u0026hellip;\n这篇文章主要讲三个点 无屏幕 SSH, Static IP, 开启OTG模式\nSSH 当然在 ssh 的时候要保证 Raspberry Zero 是有网的状态, 编辑第二个分区 wpa-supplicant 的配置文件 /etc/wpa_supplicant/wpa_supplicant.conf\n基本网络配置 network={ ssid=\u0026#34;testing\u0026#34; psk=\u0026#34;testingPassword\u0026#34; } ssid 无线网络名称, psk 无线网络密码\n隐藏网络配置 network={ ssid=\u0026#34;testing\u0026#34; scan_ssid=1 psk=\u0026#34;testingPassword\u0026#34; } 多个网络配置 network={ ssid=\u0026#34;HomeOneSSID\u0026#34; psk=\u0026#34;passwordOne\u0026#34; priority=1 id_str=\u0026#34;homeOne\u0026#34; } network={ ssid=\u0026#34;HomeTwoSSID\u0026#34; psk=\u0026#34;passwordTwo\u0026#34; priority=2 id_str=\u0026#34;homeTwo\u0026#34; } priority 网络优先级\n连接 SSH 如果网络配置没问题的话,现在应该已经连接上了无线网络了, 接下来就是在无屏幕状态下如何 ssh 到 Raspberry Zero\n挂载第一分区在 / 目录创建 SSH 文件就可以了, 然后插电启动 Raspberry Zero 等待自动连接到网络后进行后续操作","title":"RaspberryZero网络与OTG配置.md"},{"content":"现在一般都是使用 SS FQ 了吧, 所以都是 SOCKS5 代理, 但是在终端有些程序是不支持 SOCKS5 的, 比如 go get\n方法一 如果你的 SS 目前 Cow 支持的加密算法有: aes-128-cfb, aes-192-cfb, aes-256-cfb, bf-cfb, cast5-cfb, des-cfb, rc4-md5, chacha20, salsa20, rc4, table\n安装教程参见 https://github.com/cyfdecyf/cow#快速开始\n方法二 如果你用的 SS 加密算法不在以上支持的情况\n可以先使用 ss-local 在本地开启 SOCKS5 然后在通过 Cow 将 SOCKS5 转 HTTP\n","permalink":"https://mioto.me/posts/setting-up-agents-for-terminals/","summary":"现在一般都是使用 SS FQ 了吧, 所以都是 SOCKS5 代理, 但是在终端有些程序是不支持 SOCKS5 的, 比如 go get\n方法一 如果你的 SS 目前 Cow 支持的加密算法有: aes-128-cfb, aes-192-cfb, aes-256-cfb, bf-cfb, cast5-cfb, des-cfb, rc4-md5, chacha20, salsa20, rc4, table\n安装教程参见 https://github.com/cyfdecyf/cow#快速开始\n方法二 如果你用的 SS 加密算法不在以上支持的情况\n可以先使用 ss-local 在本地开启 SOCKS5 然后在通过 Cow 将 SOCKS5 转 HTTP","title":"为终端设置代理"},{"content":"用 Manjaro I3 差不多快半年了, 重装了两三次, 记录一下自己的安装记录, 避免以后遇到一些坑\n配置文件 配置文件使用 [Mackup](https://github.com/lra/mackup) 进行备份, 备份至 Dropbox 中\n输入法 搜狗输入法\u0026hellip;, 怎么说呢, 用起来很可以,简单方便. 但是在 Manjro 下安装简直是一种煎熬, 需要自己 building QTwebkit, 所需要的时间你自己想\u0026hellip; 可能有更简单的方法, 但是我不知道\u0026hellip;\n我现在使用的输入法是 ibus rime, 简单好用, 虽然不能同步输入习惯,但是通过 Mackup 解决了\n字体 编程字体主要是用 manoco, Dejavu Sans Mono 两个都很好看, 可以尝试一下, 因为使用 zsh 可能还需要装一下 [Powerline Font](https://github.com/powerline/fonts)\n常用软件 JetBrain 全家桶, 主要用 Goland Google Chrome 浏览器 VSCode 用来写 Markdown zeal 类似于 Mac 下的 Dash, 用起来还不错 Dropbox 同步 dotfiles, 以及一堆的资料 Ibus Rime 中文输入法, 台湾人开发的?, 文档有点难读\u0026hellip; End 剩余的想起来在写\u0026hellip;\n","permalink":"https://mioto.me/posts/install-manjaro-i3-records/","summary":"用 Manjaro I3 差不多快半年了, 重装了两三次, 记录一下自己的安装记录, 避免以后遇到一些坑\n配置文件 配置文件使用 [Mackup](https://github.com/lra/mackup) 进行备份, 备份至 Dropbox 中\n输入法 搜狗输入法\u0026hellip;, 怎么说呢, 用起来很可以,简单方便. 但是在 Manjro 下安装简直是一种煎熬, 需要自己 building QTwebkit, 所需要的时间你自己想\u0026hellip; 可能有更简单的方法, 但是我不知道\u0026hellip;\n我现在使用的输入法是 ibus rime, 简单好用, 虽然不能同步输入习惯,但是通过 Mackup 解决了\n字体 编程字体主要是用 manoco, Dejavu Sans Mono 两个都很好看, 可以尝试一下, 因为使用 zsh 可能还需要装一下 [Powerline Font](https://github.com/powerline/fonts)\n常用软件 JetBrain 全家桶, 主要用 Goland Google Chrome 浏览器 VSCode 用来写 Markdown zeal 类似于 Mac 下的 Dash, 用起来还不错 Dropbox 同步 dotfiles, 以及一堆的资料 Ibus Rime 中文输入法, 台湾人开发的?","title":"安装 Manjaro I3 记录"},{"content":"简介 这个东西可能并没有你想象中的那么完美, 适合个人使用, 上传后无法删除镜像, 但是有第三方工具帮你删除后面会讲. 如果这几点你都不介意的话, 可以继续往下看了!!!\ndocker 的基础操作我都不会讲, 如果不太了解的话建议去官网学习\n必备的程序 docker-ce, docker-compose.\n本机搭建 registry 的默认端口为 5000\n如果想将 hub.docker.com 上的 alpine 做个镜像.\ndocker pull alpine:latest docker tag alpine:latest localhost:5000/alpine:latest docker push localhost:5000/alpine:latest --- version: \u0026#34;2\u0026#34; services: registry: image: registry:latest restart: always volumes: - registry:/var/lib/registry volumes: registry: 配置前端 registry-frontend 是 registry 的前端, 如果想详细设置可以去 konradkleine/docker-registry-frontend 这里看.\n效果图如下:\n--- version: \u0026#34;2\u0026#34; services: registry: image: registry:latest restart: always volumes: - registry:/var/lib/registry registry-frontend: image: konradkleine/docker-registry-frontend:v2 environment: ENV_DOCKER_REGISTRY_HOST: registry ENV_DOCKER_REGISTRY_PORT: \u0026#34;5000\u0026#34; ENV_MODE_BROWSE_ONLY: \u0026#34;true\u0026#34; depends_on: - registry volumes: registry: 配置域名与认证 我使用的是 caddy 作为我的反向代理服务器, 当然你也可以使用 nginx 等.\n# docker-compose.yaml --- version: \u0026#34;2\u0026#34; services: caddy: image: abiosoft/caddy:latest environment: ACME_AGREE: \u0026#34;true\u0026#34; ports: - \u0026#34;80:80\u0026#34; - \u0026#34;443:443\u0026#34; volumes: - ./config/caddy/Caddyfile:/etc/Caddyfile - ./config/caddy/.caddy:/root/.caddy registry: image: registry:latest restart: always volumes: - registry:/var/lib/registry registry-frontend: image: konradkleine/docker-registry-frontend:v2 environment: ENV_DOCKER_REGISTRY_HOST: registry ENV_DOCKER_REGISTRY_PORT: \u0026#34;5000\u0026#34; ENV_REGISTRY_PROXY_FQDN: docker.mioto.me ENV_REGISTRY_PROXY_PORT: \u0026#34;443\u0026#34; ENV_MODE_BROWSE_ONLY: \u0026#34;true\u0026#34; depends_on: - registry volumes: registry: # Caddyfile # {domains} 提换成自己的域名 # 如果不要认证 可以注释掉 `basicauth` 那一行 {domains} { tls admin@mioto.me basicauth / admin P3MWcbWCV6nyE8imHBbC proxy / registry:5000 { transparent } redir 301 { if {\u0026gt;X-Forwarded-Proto} is http / https://{host}{url} } } 参考 https://caddyserver.com/ https://www.docker.com/ https://hub.docker.com/_/registry/ https://hub.docker.com/r/konradkleine/docker-registry-frontend/ ","permalink":"https://mioto.me/posts/private-docker-registry-deploy/","summary":"简介 这个东西可能并没有你想象中的那么完美, 适合个人使用, 上传后无法删除镜像, 但是有第三方工具帮你删除后面会讲. 如果这几点你都不介意的话, 可以继续往下看了!!!\ndocker 的基础操作我都不会讲, 如果不太了解的话建议去官网学习\n必备的程序 docker-ce, docker-compose.\n本机搭建 registry 的默认端口为 5000\n如果想将 hub.docker.com 上的 alpine 做个镜像.\ndocker pull alpine:latest docker tag alpine:latest localhost:5000/alpine:latest docker push localhost:5000/alpine:latest --- version: \u0026#34;2\u0026#34; services: registry: image: registry:latest restart: always volumes: - registry:/var/lib/registry volumes: registry: 配置前端 registry-frontend 是 registry 的前端, 如果想详细设置可以去 konradkleine/docker-registry-frontend 这里看.\n效果图如下:\n--- version: \u0026#34;2\u0026#34; services: registry: image: registry:latest restart: always volumes: - registry:/var/lib/registry registry-frontend: image: konradkleine/docker-registry-frontend:v2 environment: ENV_DOCKER_REGISTRY_HOST: registry ENV_DOCKER_REGISTRY_PORT: \u0026#34;5000\u0026#34; ENV_MODE_BROWSE_ONLY: \u0026#34;true\u0026#34; depends_on: - registry volumes: registry: 配置域名与认证 我使用的是 caddy 作为我的反向代理服务器, 当然你也可以使用 nginx 等.","title":"私有-docker-registry-搭建"},{"content":"今天遇到个问题, 如何将 [32]byte 转 string\n// https://play.golang.org/p/JkK_B5609GN func main() { hs := sha256.Sum256([]byte(\u0026#34;hahaha\u0026#34;)) fmt.Println(hs) } // ===== // [190 23 140 5 67 235 23 245 243 4 48 33 201 229 252 243 2 133 229 87 164 252 48 156 206 151 255 156 166 24 41 18] 方法1 直接将 hs 转 slice, 但是打印出来的是乱码\n// https://play.golang.org/p/RH8_iHLuWeg func main() { hs := sha256.Sum256([]byte(\u0026#34;hahaha\u0026#34;)) fmt.Println(string(hs[:])) } // ===== // �\u0017�\u0005C�\u0017��\u00040!����\u0002��W��0�Η���\u0018)\u0012 方法2 // https://play.golang.org/p/Z1-pU0mjX_B func main() { hs := sha256.Sum256([]byte(\u0026#34;hahaha\u0026#34;)) fmt.Println(fmt.Sprintf(\u0026#34;%x\u0026#34;, hs)) } // ===== // be178c0543eb17f5f3043021c9e5fcf30285e557a4fc309cce97ff9ca6182912 方法3 // https://play.golang.org/p/x8ovK9CkRlG func main() { hs := sha256.Sum256([]byte(\u0026#34;hahaha\u0026#34;)) fmt.Println(hex.EncodeToString(hs[:])) } // ===== // be178c0543eb17f5f3043021c9e5fcf30285e557a4fc309cce97ff9ca6182912 参考 https://stackoverflow.com/questions/14230145/what-is-the-best-way-to-convert-byte-array-to-string ","permalink":"https://mioto.me/posts/go-bytearray-tostring/","summary":"\u003cp\u003e今天遇到个问题, 如何将 \u003ccode\u003e[32]byte\u003c/code\u003e 转 \u003ccode\u003estring\u003c/code\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-go\" data-lang=\"go\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e// https://play.golang.org/p/JkK_B5609GN\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kd\"\u003efunc\u003c/span\u003e \u003cspan class=\"nf\"\u003emain\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nx\"\u003ehs\u003c/span\u003e \u003cspan class=\"o\"\u003e:=\u003c/span\u003e \u003cspan class=\"nx\"\u003esha256\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eSum256\u003c/span\u003e\u003cspan class=\"p\"\u003e([]\u003c/span\u003e\u003cspan class=\"nb\"\u003ebyte\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;hahaha\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nx\"\u003efmt\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003ePrintln\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"nx\"\u003ehs\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e// =====\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e// [190 23 140 5 67 235 23 245 243 4 48 33 201 229 252 243 2 133 229 87 164 252 48 156 206 151 255 156 166 24 41 18]\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e","title":"Go byte 数组转 string"},{"content":"今天被一道题目恶心到了, 发现不研究这些东西可能真的活不下去了, 狠下心来读了一个多小时的源码, 写下些自己对 Slice 的见解吧.\n先说说那个题目.\n// https://play.golang.org/p/2fA3BylTgtf // 请问 s1 和 s2 的值分别是? func main() { s1 := []int{1, 2, 3} s2 := s1[:0] s2 = append(s2, 4) fmt.Println(s1) fmt.Println(s2) } //========== // [4 2 3] // [4] Slice 定义 先看看 Slice 在 Go 底层的定义\n// https://github.com/golang/go/blob/master/src/reflect/value.go#L1806 type sliceHeader struct { Data unsafe.Pointer // Array pointer Len int // slice length Cap int // slice capacity } 原理讲解 第一行 s1 := []int{1, 2, 3} 是将 [1, 2, 3] 的首地址 存入了 Data 中, 设置了 Len 为 3, 设置了 Cap 为 3.\n// https://play.golang.org/p/bjP8BKtwQQl // 验证代码. func main() { s1 := []int{1, 2, 3} // 我们可以先将它转成 *reflect.SliceHeader 类型. // *reflect.SliceHeader // 定义: https://github.com/golang/go/blob/master/src/reflect/value.go#L1800 // 顺带着再说一句 uintptr: uintptr 是整型, 可以足够保存指针的值得范围, // 在 32 平台下为 4 字节,在 64 位平台下是 8 字节 sliceHeader1 := (*reflect.SliceHeader)((unsafe.Pointer)(\u0026amp;s1)) fmt.Printf(\u0026#34;data address: %#0x, len: %d, cap: %d\\n\u0026#34;, sliceHeader1.Data, sliceHeader1.Len, sliceHeader1.Cap) } //===== // data address: 0x10414020, len: 3, cap: 3 第二行 s2 := s1[:0] 是将 s1 的 Data 中的值, 赋值给了 s2 的 Data 中, 设置 Len 为 0, s1 的 Cap 赋值给了 s2 的 Cap.\n上面这一段有可能不太好理解, 我直接拿出源码来说.\n// https://github.com/golang/go/blob/master/src/reflect/value.go#1559 func (v Value) Slice(i, j int) Value { // ... 略过无用代码 switch kind := v.kind(); kind { // ... case Slice: typ = (*sliceType)(unsafe.Pointer(v.typ)) s := (*sliceHeader)(v.ptr) base = s.Data cap = s.Cap } // ... // Declare slice so that gc can see the base pointer in it. var x []unsafe.Pointer // Reinterpret as *sliceHeader to edit. s := (*sliceHeader)(unsafe.Pointer(\u0026amp;x)) // 这里是给 s2.Len 进行赋值. s1[:0] i 没有传所以为 0, j 也为 0, 所以 j - i ... s.Len = j - i // 这里是给 s2.Cap 进行赋值. cap 在上面的 case 中 被赋值为 3, 3 - 0 emmm... s.Cap = cap - i // if 为真 if cap-i \u0026gt; 0 { // 所以这里是给 s2.Data 进行赋值. // arrayAt 的 4个参数类型: // p unsafe.Pointer, i int, eltSize uintptr, whySafe string // base 是 s1.Data, i 是 0, eltSize 这个值是根据类型来的, // 在当前例子里是 []int, 在 Go 中 int 在根据系统, 32 平台下为 4 字节, // 在 64 位平台下是 8 字节 // 最后一个参数 whySafe 可能是为了做个记录吧... 而且必须说明为啥安全... s.Data = arrayAt(base, i, typ.elem.Size(), \u0026#34;i \u0026lt; cap\u0026#34;) } else { // do not advance pointer, to avoid pointing beyond end of slice s.Data = base } } // https://github.com/golang/go/blob/master/src/reflect/value.go#1826 func arrayAt(p unsafe.Pointer, i int, eltSize uintptr, whySafe string) unsafe.Pointer { // 在 Go 中以系统 64 位 为例 // 传的值分别是 s1.Data(0x10414020), 0*8, \u0026#34;i \u0026lt; len\u0026#34; return add(p, uintptr(i)*eltSize, \u0026#34;i \u0026lt; len\u0026#34;) } // https://github.com/golang/go/blob/master/src/reflect/type.go#1079 func add(p unsafe.Pointer, x uintptr, whySafe string) unsafe.Pointer { // 所以这里就相当于 0x10414020+0 return unsafe.Pointer(uintptr(p) + x) } // https://play.golang.org/p/pA6coJh2bSg // 验证代码 func main() { s1 := []int{1, 2, 3} s2 := s1[:0] sliceHeader2 := (*reflect.SliceHeader)((unsafe.Pointer)(\u0026amp;s2)) fmt.Printf(\u0026#34;data address: %#0x, len: %d, cap: %d\\n\u0026#34;, sliceHeader2.Data, sliceHeader2.Len, sliceHeader2.Cap) } //===== // data address: 0x10414020, len: 0, cap: 3 可以看见 s1.Data 和 s2.Data 地址都是 0x10414020\n到了这里你可能会问如果地址一样, 为什么 访问 s2[2] 会报错. runtime error: index out of range\n其实猜也能大概猜到, 因为你获取数据的时候 程序是判断了 s2.Len 的.\n代码位置在: https://github.com/golang/go/blob/master/src/reflect/type.go#870 这个函数里面有写.\n结论 emm.. 不知道\u0026hellip;.\n","permalink":"https://mioto.me/posts/go-slice-analysis/","summary":"今天被一道题目恶心到了, 发现不研究这些东西可能真的活不下去了, 狠下心来读了一个多小时的源码, 写下些自己对 Slice 的见解吧.\n先说说那个题目.\n// https://play.golang.org/p/2fA3BylTgtf // 请问 s1 和 s2 的值分别是? func main() { s1 := []int{1, 2, 3} s2 := s1[:0] s2 = append(s2, 4) fmt.Println(s1) fmt.Println(s2) } //========== // [4 2 3] // [4] Slice 定义 先看看 Slice 在 Go 底层的定义\n// https://github.com/golang/go/blob/master/src/reflect/value.go#L1806 type sliceHeader struct { Data unsafe.Pointer // Array pointer Len int // slice length Cap int // slice capacity } 原理讲解 第一行 s1 := []int{1, 2, 3} 是将 [1, 2, 3] 的首地址 存入了 Data 中, 设置了 Len 为 3, 设置了 Cap 为 3.","title":"Go Slice 原理解析"},{"content":"就贴一段代码\u0026hellip;\npackage main import ( \u0026#34;bytes\u0026#34; \u0026#34;errors\u0026#34; \u0026#34;io\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;net/rpc\u0026#34; \u0026#34;net/rpc/jsonrpc\u0026#34; ) type Args struct { A, B int } type Quotient struct { Quo, Rem int } type Arith int func (t *Arith) Multiply(args *Args, reply *int) error { *reply = args.A * args.B return nil } func (t *Arith) Divide(args *Args, quo *Quotient) error { if args.B == 0 { return errors.New(\u0026#34;divide by zero\u0026#34;) } quo.Quo = args.A / args.B quo.Rem = args.A % args.B return nil } // rpcRequest represents a RPC request. // rpcRequest implements the io.ReadWriteCloser interface. type rpcRequest struct { r io.Reader // holds the JSON formated RPC request rw io.ReadWriter // holds the JSON formated RPC response done chan bool // signals then end of the RPC request } // NewRPCRequest returns a new rpcRequest. func NewRPCRequest(r io.Reader) *rpcRequest { var buf bytes.Buffer done := make(chan bool) return \u0026amp;rpcRequest{r, \u0026amp;buf, done} } // Read implements the io.ReadWriteCloser Read method. func (r *rpcRequest) Read(p []byte) (n int, err error) { return r.r.Read(p) } // Write implements the io.ReadWriteCloser Write method. func (r *rpcRequest) Write(p []byte) (n int, err error) { return r.rw.Write(p) } // Close implements the io.ReadWriteCloser Close method. func (r *rpcRequest) Close() error { r.done \u0026lt;- true return nil } // Call invokes the RPC request, waits for it to complete, and returns the results. func (r *rpcRequest) Call() io.Reader { go jsonrpc.ServeConn(r) \u0026lt;-r.done return r.rw } func main() { arith := new(Arith) rpc.Register(arith) http.HandleFunc(\u0026#34;/\u0026#34;, func(w http.ResponseWriter, req *http.Request) { defer req.Body.Close() w.Header().Set(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;) res := NewRPCRequest(req.Body).Call() io.Copy(w, res) }) log.Fatal(http.ListenAndServe(\u0026#34;:8080\u0026#34;, nil)) } ","permalink":"https://mioto.me/posts/go-http-jsonrpc-service/","summary":"就贴一段代码\u0026hellip;\npackage main import ( \u0026#34;bytes\u0026#34; \u0026#34;errors\u0026#34; \u0026#34;io\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;net/rpc\u0026#34; \u0026#34;net/rpc/jsonrpc\u0026#34; ) type Args struct { A, B int } type Quotient struct { Quo, Rem int } type Arith int func (t *Arith) Multiply(args *Args, reply *int) error { *reply = args.A * args.B return nil } func (t *Arith) Divide(args *Args, quo *Quotient) error { if args.B == 0 { return errors.New(\u0026#34;divide by zero\u0026#34;) } quo.Quo = args.","title":"Go HTTP JSONRPC Service"},{"content":"其实 RESTful API 实现权限控制的方法很多很多, 比如在每个 Handler 中进行判断, 但是这种写法会导致工作量无限增加, 万一增加了其他的角色还要不停的更改源码, 所以要以尽量优雅的方式来实现这个部分. 比如 Middleware 的方式.\n资源的分类 /zoos 算一个资源 /employees 也是一个资源\n但是这些资源又有一些不一样的地方.\n栗子:\nGET /zoos 想看动物园的列表, 所有人都可以看, 也不需要登录. PATCH /zoos/ID 更新某个动物园的信息, 只有员工才可以更改, 必须要登录. GET /employees 想看员工列表, 只有是员工, 且还是管理员的人才能看, 必须要登录.\n所以资源是有分类的:\n我归为以下两类.\n角色资源 (Role Resources) 公共资源 (Public Resources) 角色资源: 属于某个角色所有, 只有访问的人属于这个角色才能进行访问. 例: 人事部门 才能对 /employees 资源进行增删改查. 公共资源: 游客,工作人员, 管理人员 都可以进行操作的资源.\n角色 用户 权限 权限组之间的关系 用户: 有哪些角色. 角色: 有哪些权限组 权限. 权限组: 一部分权限的集合(可有可无的一部分, 如果前端每次操作都需要一个一个的去添加权限,为何不把权限打包成一个权限组呢?) 权限: 可以控制访问的资源.\n用户与角色的关系: 一对多 一个用户可以拥有多个权限. 例如:一个用户既是动物园的员工, 也是动物园的管理者. 角色与权限权限组的关系: 一对多 一个角色可以有多个权限组 权限. 例如:管理员 拥有 employees权限组 zoos部分权限. 用户与权限权限组的关系: 一对多 一个用户也可以拥有角色之外的权限权限组. (毕竟有些人就是这么特殊,不考虑不行啊!!)\n表的设计 以下列出的字段只是权限控制中必须的字段, 可以在原先表结构中添加即可.\nResource Nmae Type Description Name string 资源名称 Description string 资源描述 Identity string 资源唯一标识符 (一般可直接使用URL作为唯一标识符后面细讲) Permission Nmae Type Description ResourceID string 资源ID Name string 权限名称 Description string 权限描述 Method string HTTP请求方法 Effect string 作用于自己还是全部 (Allow\u0026amp;Owner) PermissionGroup Nmae Type Description Name string 权限组名称 Description string 权限组描述 PermissionsID []string 权限集合 Role Nmae Type Description Name string 角色名称 Description string 角色描述 PermissionsID []string 权限列表 PermissionGroupsID []string 权限组列表 User Nmae Type Description RolesID []string 角色列表 PermissionsID []string 权限列表 以上所有的表都设计完了, 如果你仔细看上面表的顺序你会发现一点, 他们都是一对多的每一个 Resource 都是根.\n注: Resource 一对多 Permission 一对多 PermissionGroup 一对多 Role 一对多 Role\n权限中间件 以 negroni 为例中间件执行是有顺序的, 根据加载的先后分别执行.\n权限中间件一般位于验证中间件之后, 以下的流程图是以我当前项目为例画出的流程图.\nst=\u0026gt;start: Start ed=\u0026gt;end: End OPmiddlewareBefore=\u0026gt;operation: Before Middleware OPmiddlewareAuth=\u0026gt;operation: Auth Middleware 1. QueryTokenAuth 2. HeaderTokenAuth 3. JWTTokenAuth CDauth=\u0026gt;condition: Logined? OPnoLolin=\u0026gt;operation: Redirect /login OPmiddlewarePermission=\u0026gt;operation: Permission Middleware CDpermission=\u0026gt;condition: Yes or No OPnoPermission=\u0026gt;operation: Return HTTP Code 401 OPmiddlewareAfter=\u0026gt;operation: After Middleware st-\u0026gt;OPmiddlewareBefore-\u0026gt;OPmiddlewareAuth-\u0026gt;CDauth CDauth(no)-\u0026gt;OPnoLolin-\u0026gt;OPmiddlewareBefore CDauth(yes)-\u0026gt;OPmiddlewarePermission-\u0026gt;CDpermission CDpermission(no)-\u0026gt;OPnoPermission CDpermission(yes)-\u0026gt;OPmiddlewareAfter-\u0026gt;ed 以下流程图是 Permission Middleware 内部的具体流程\nst=\u0026gt;start: Start ed=\u0026gt;end: End OPgetResource=\u0026gt;operation: Get Resource conditions: 1. url OPgetPermission=\u0026gt;operation: Get Permission conditions: 1. resourceID 2. http method OPgetPermissionGroup=\u0026gt;operation: Get PermissionGroup conditions: 1. permissionID OPgetRole=\u0026gt;operation: Get Role conditions: 1. permissionID || PermissionGroupID CDResource=\u0026gt;condition: Yes or No OPnoResource=\u0026gt;operation: Return HTTP Code 404 CDpermission=\u0026gt;condition: Yes or No OPnoPermission=\u0026gt;operation: Return HTTP Code 500 CDpermissionGroup=\u0026gt;condition: Yes or No OPnoPermissionGroup=\u0026gt;operation: Return HTTP Code 500 CDrole=\u0026gt;condition: Yes or No OPnoRole=\u0026gt;operation: Return HTTP Code 500 OPvalidUserPermission=\u0026gt;operation: Valid User Permission CDvalidUserPermission=\u0026gt;condition: Yes or No OPuserNoPermission=\u0026gt;operation: Return HTTP Code 401 st-\u0026gt;OPgetResource-\u0026gt;CDResource CDResource(no)-\u0026gt;OPnoResource CDResource(yes)-\u0026gt;OPgetPermission-\u0026gt;CDpermission CDpermission(no)-\u0026gt;OPnoPermission CDpermission(yes)-\u0026gt;OPgetPermissionGroup-\u0026gt;CDpermissionGroup CDpermissionGroup(no)-\u0026gt;OPnoPermissionGroup CDpermissionGroup(yes)-\u0026gt;OPgetRole-\u0026gt;CDrole CDrole(no)-\u0026gt;OPnoRole CDrole(yes)-\u0026gt;OPvalidUserPermission-\u0026gt;CDvalidUserPermission CDvalidUserPermission(no)-\u0026gt;OPuserNoPermission CDvalidUserPermission(yes)-\u0026gt;ed 资源唯一标识符 这里讲一下为什么使用以及如何使用 URL 作为唯一标识符.\n这里以 /users API 为例. 分别对应他的操作有\nGET /users - 获取用户列表 GET /users/{id} - 获取具体用户的信息. POST /users - 创建一个用户 PATCH /users/{id} - 更新一个用户的信息 PATCH /users/{id}/password - 更新用户密码 DELETE /users/{id} - 删除一个用户\n假设现在有两个角色分别是 普通用户, 管理员\n资源表其实有两个 /users, /users/\n/users/ 普通用户有权限 /users 普通用户没有权限\n所以 URL 作为资源唯一标识符到 第一层就可以了. 后面的可变的值如 /users/{id} 的 id 部分并不需要考虑.\n以上, 如有疑问欢迎提出, 如果大神看出了缺陷也请告知哈~~\n参考 RESTful API 设计指南 基于RESTful API 怎么设计用户权限控制？ ","permalink":"https://mioto.me/posts/design-permission-control-based-on-restful/","summary":"\u003cp\u003e其实 \u003ccode\u003eRESTful API\u003c/code\u003e 实现权限控制的方法很多很多, 比如在每个 \u003ccode\u003eHandler\u003c/code\u003e 中进行判断, 但是这种写法会导致工作量无限增加, 万一增加了其他的角色还要不停的更改源码, 所以要以尽量优雅的方式来实现这个部分. 比如 \u003ccode\u003eMiddleware\u003c/code\u003e 的方式.\u003c/p\u003e","title":"基于 Go 的 RESTful API 怎么设计权限控制"},{"content":"最开始主要是想玩玩 Go http 2 Push 的, 但是发现以前那种最简单的自签 Chrome58+ 后就不认了\u0026hellip;\n查询后才知道 Chrome58+ 后只允许包含SAN(Subject Alternative Name)信息的证书.\n重新制作包含SAN的自签证书 生成 Root CA private key openssl genrsa -out rootCA.key 2048 生成 RootCA rootCA.pem.conf 主要是方便自己以后生成的, 不用重复工作.\n[ req ] default_bits = 2048 default_md = sha256 distinguished_name = subject [ subject ] countryName = Country Name (2 letter code) countryName_default = CN stateOrProvinceName = State or Province Name (full name) stateOrProvinceName_default = Beijing localityName = Locality Name (eg, city) localityName_default = Beijing organizationName = Organizational Name organizationName_default = Yaku Mioto Co., Ltd organizationalUnitName = Organizational Unit Name (eg, section) organizationalUnitName_default = commonName = Common Name (e.g. server FQDN or YOUR name) commonName_default = Yaku Mioto Root CA openssl req \\ -new \\ -x509 \\ -nodes \\ -sha256 \\ -days 3650 \\ -key rootCA.key \\ -config rootCA.pem.conf \\ -out rootCA.pem 生成 证书请求 CSR server.csr.conf 同理. 减少工作量.\n[ req ] default_bits = 2048 default_md = sha256 distinguished_name = subject [ subject ] countryName = Country Name (2 letter code) countryName_default = CN stateOrProvinceName = State or Province Name (full name) stateOrProvinceName_default = Beijing localityName = Locality Name (eg, city) localityName_default = Beijing organizationName = Organizational Name organizationName_default = Yaku Mioto Co., Ltd openssl req \\ -new \\ -nodes \\ -sha256 \\ -config server.scr.conf \\ -newkey rsa:2048 \\ -keyout server.key \\ -out server.csr 签发证书 创建 v3.ext file, 支持了多域名多IP. 这是个好东西啊, https 负载均衡.\nauthorityKeyIdentifier=keyid,issuer basicConstraints=CA:FALSE keyUsage = digitalSignature, nonRepudiation, keyEncipherment, dataEncipherment subjectAltName = @alt_names [alt_names] DNS.1 = miotombp.local openssl x509 \\ -req \\ -sha256 \\ -days 3650 \\ -CA rootCA.pem \\ -CAcreateserial \\ -extfile v3.ext \\ -CAkey rootCA.key \\ -in server.csr \\ -out server.crt 大功告成, 至于怎么添加到系统信任, 那就是各个操作系统的事情了.\n参考 Chrome 58不允許沒有SAN的自簽憑證 Chrome 58 - Not secure, certificates must have Subject Alternative Name ","permalink":"https://mioto.me/posts/openssl-self-signed-certificate/","summary":"\u003cp\u003e最开始主要是想玩玩 \u003ccode\u003eGo http 2 Push\u003c/code\u003e 的, 但是发现以前那种最简单的自签 \u003ccode\u003eChrome58+\u003c/code\u003e 后就不认了\u0026hellip;\u003c/p\u003e\n\u003cp\u003e查询后才知道 \u003ccode\u003eChrome58+\u003c/code\u003e 后只允许包含SAN(Subject Alternative Name)信息的证书.\u003c/p\u003e","title":"openssl 自签证书"},{"content":"在解析 jwt 中的 Playload 部分的 base64 时遇到了错误.\n报错代码 enstr := \u0026#34;eyJBY2NvdW50SWQiOiIxIiwiQ2xpZW50IjoiIiwiRW1haWwiOiJ5YWt1Lm1pb3RvQGdtYWlsLmNvbSIsIk1hc3RlckZsYWciOnRydWUsImV4cCI6MTU0ODc0NTY5OSwidHlwZSI6ImVtcGxveWVlcyJ9\u0026#34; // {\u0026#34;AccountId\u0026#34;:\u0026#34;1\u0026#34;,\u0026#34;Client\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;Email\u0026#34;:\u0026#34;yaku.mioto@gmail.com\u0026#34;,\u0026#34;MasterFlag\u0026#34;:true,\u0026#34;exp\u0026#34;:1548745699,\u0026#34;type\u0026#34;:\u0026#34;employees\u0026#34;} debytes, err := base64.StdEncoding.DecodeString(enstr) if err := nil { // ... // err output: illegal base64 data at input byte xxx } // ... 源码: https://golang.org/src/encoding/base64/base64.go\nconst ( StdPadding rune = \u0026#39;=\u0026#39; // Standard padding character NoPadding rune = -1 // No padding ) const encodeStd = \u0026#34;ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/\u0026#34; // StdEncoding is the standard base64 encoding, as defined in // RFC 4648. var StdEncoding = NewEncoding(encodeStd) // RawStdEncoding is the standard raw, unpadded base64 encoding, // as defined in RFC 4648 section 3.2. // This is the same as StdEncoding but omits padding characters. var RawStdEncoding = StdEncoding.WithPadding(NoPadding) // NewEncoding returns a new padded Encoding defined by the given alphabet, // which must be a 64-byte string that does not contain the padding character // or CR / LF (\u0026#39;\\r\u0026#39;, \u0026#39;\\n\u0026#39;). // The resulting Encoding uses the default padding character (\u0026#39;=\u0026#39;), // which may be changed or disabled via WithPadding. func NewEncoding(encoder string) *Encoding { // ... } 原因 jwt 的 base64 是去除填充物的, 所以不能使用 StdEncoding 应该使用 RawStdEncoding\n所以代码应该是这样\nenstr := \u0026#34;eyJBY2NvdW50SWQiOiIxIiwiQ2xpZW50IjoiIiwiRW1haWwiOiJ5YWt1Lm1pb3RvQGdtYWlsLmNvbSIsIk1hc3RlckZsYWciOnRydWUsImV4cCI6MTU0ODc0NTY5OSwidHlwZSI6ImVtcGxveWVlcyJ9\u0026#34; // {\u0026#34;AccountId\u0026#34;:\u0026#34;1\u0026#34;,\u0026#34;Client\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;Email\u0026#34;:\u0026#34;yaku.mioto@gmail.com\u0026#34;,\u0026#34;MasterFlag\u0026#34;:true,\u0026#34;exp\u0026#34;:1548745699,\u0026#34;type\u0026#34;:\u0026#34;employees\u0026#34;} debytes, err := base64.RawStdEncoding.DecodeString(enstr) if err := nil { // ... // err output: illegal base64 data at input byte xxx } // ... 参考 https://stackoverflow.com/a/42683706/9176562 ","permalink":"https://mioto.me/posts/problems-encountered-in-using-gobase64-standard-library/","summary":"\u003cp\u003e在解析 \u003ccode\u003ejwt\u003c/code\u003e 中的 \u003ccode\u003ePlayload\u003c/code\u003e 部分的 \u003ccode\u003ebase64\u003c/code\u003e 时遇到了错误.\u003c/p\u003e\n\u003ch2 id=\"报错代码\"\u003e报错代码\u003c/h2\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-go\" data-lang=\"go\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nx\"\u003eenstr\u003c/span\u003e \u003cspan class=\"o\"\u003e:=\u003c/span\u003e \u003cspan class=\"s\"\u003e\u0026#34;eyJBY2NvdW50SWQiOiIxIiwiQ2xpZW50IjoiIiwiRW1haWwiOiJ5YWt1Lm1pb3RvQGdtYWlsLmNvbSIsIk1hc3RlckZsYWciOnRydWUsImV4cCI6MTU0ODc0NTY5OSwidHlwZSI6ImVtcGxveWVlcyJ9\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e// {\u0026#34;AccountId\u0026#34;:\u0026#34;1\u0026#34;,\u0026#34;Client\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;Email\u0026#34;:\u0026#34;yaku.mioto@gmail.com\u0026#34;,\u0026#34;MasterFlag\u0026#34;:true,\u0026#34;exp\u0026#34;:1548745699,\u0026#34;type\u0026#34;:\u0026#34;employees\u0026#34;}\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nx\"\u003edebytes\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"nx\"\u003eerr\u003c/span\u003e \u003cspan class=\"o\"\u003e:=\u003c/span\u003e \u003cspan class=\"nx\"\u003ebase64\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nx\"\u003eStdEncoding\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eDecodeString\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"nx\"\u003eenstr\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"nx\"\u003eerr\u003c/span\u003e \u003cspan class=\"o\"\u003e:=\u003c/span\u003e \u003cspan class=\"kc\"\u003enil\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"c1\"\u003e// ...\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e  \u003cspan class=\"c1\"\u003e// err output: illegal base64 data at input byte xxx\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e// ...\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e","title":"使用GoBase64标准包遇到的问题"},{"content":" 二话不说先上一张退回后所有的配件\u0026hellip;, 没错就是这么点东西!!!, 所以只要给 Google 寄回坏手机就好了.\n废话不多说开始讲讲大概的流程,\n咨询方法有两种, 打电话和在线聊天, 如果英文够好, 估计也不会来这里了, emmm\u0026hellip;\n联系 Google https://support.google.com/pixelphone, 找到 CONTACT US -\u0026gt; Pixel Device Support -\u0026gt; 对应的手机型号 进行聊天.\n需要注意以下的几点:\n将网站设置成英文, 不然无法看到 CONTACT US. 准备好 双,全币 信用卡 因为要交押金的. 大概是 $869刀, 21天 必须把手机寄到美国,不然会扣钱 准备一个收货地址必须是美国的, 找朋友或者转运公司都行. Google在线聊天工作的时间是 6:00 AM to 9:00 PM PST, 美国的时区是 UTC-8 中国的时区是 UTC+8, 所以中国 10:00 PM 的时候他们刚刚上班\u0026hellip; 如果他们给的方法 (基本联系他们的时候就全部做过了) 全部试过还是无法开机的话. 他们会给你说给你寄送一部翻新机, 在 21天 内将坏手机寄回他们给的地址, 这些东西都会在聊天完毕后给你发一封详细电子邮件. 最好在他们发货的时候就将自己的坏手机准备寄送出去, 因为手机到美国有差不多10多天的才能到.\n","permalink":"https://mioto.me/posts/failure-google-pixel-return-process/","summary":"二话不说先上一张退回后所有的配件\u0026hellip;, 没错就是这么点东西!!!, 所以只要给 Google 寄回坏手机就好了.\n废话不多说开始讲讲大概的流程,\n咨询方法有两种, 打电话和在线聊天, 如果英文够好, 估计也不会来这里了, emmm\u0026hellip;\n联系 Google https://support.google.com/pixelphone, 找到 CONTACT US -\u0026gt; Pixel Device Support -\u0026gt; 对应的手机型号 进行聊天.\n需要注意以下的几点:\n将网站设置成英文, 不然无法看到 CONTACT US. 准备好 双,全币 信用卡 因为要交押金的. 大概是 $869刀, 21天 必须把手机寄到美国,不然会扣钱 准备一个收货地址必须是美国的, 找朋友或者转运公司都行. Google在线聊天工作的时间是 6:00 AM to 9:00 PM PST, 美国的时区是 UTC-8 中国的时区是 UTC+8, 所以中国 10:00 PM 的时候他们刚刚上班\u0026hellip; 如果他们给的方法 (基本联系他们的时候就全部做过了) 全部试过还是无法开机的话. 他们会给你说给你寄送一部翻新机, 在 21天 内将坏手机寄回他们给的地址, 这些东西都会在聊天完毕后给你发一封详细电子邮件. 最好在他们发货的时候就将自己的坏手机准备寄送出去, 因为手机到美国有差不多10多天的才能到.","title":"故障Google Pixel退换流程"},{"content":"原文: https://websiteforstudents.com/configuring-static-ips-ubuntu-17-10-servers/\nUbuntu 17.10 的时候网络配置方法完全改变了, 是否听说过 NetPlan?可能并没有吧~, NetPlan 是 Ubuntu 17.10 中引入的一种新的网络配置工具，用于管理网络设置.\nNetPlan 的配置文件是 YAML 格式的, 所以配置起来也不算麻烦~\nNetPlan 取代了以前在 /etc/network/interfaces 以前用来配置Ubuntu网络接口的文件. 现在你必须使用 /etc/netplan/*.yaml 来配置\n以下是简短的例子教你使用 NetPlan 来配置 Ubuntu 的静态网络.\n新的配置文件目录在 /etc/netplan 文件夹中, 使用名为 01-netcfg.yaml 的文件作为第一的配置文件. 一下是 DHCP 的默认配置.\n# This file describes the network interfaces available on your system # For more information, see netplan(5). network: version: 2 renderer: networkd ethernets: ens33: dhcp4: yes dhcp6: yes 如果需要应用, 就执行以下命令.\nsudo netplan apply 配置静态IP # This file describes the network interfaces available on your system # For more information, see netplan(5). network: version: 2 renderer: networkd ethernets: ens33: dhcp4: no dhcp6: no addresses: [192.168.1.2/24] gateway4: 192.168.1.1 nameservers: addresses: [8.8.8.8,8.8.4.4] 你也可以添加 IPv6 的地址, 用 , 进行分隔\n# This file describes the network interfaces available on your system # For more information, see netplan(5). network: version: 2 renderer: networkd ethernets: ens33: dhcp4: no dhcp6: no addresses: [192.168.1.2/24, \u0026#39;2001:1::2/64\u0026#39;] gateway4: 192.168.1.1 nameservers: addresses: [8.8.8.8,8.8.4.4] ","permalink":"https://mioto.me/posts/configure-static-ip-address-on-ubuntu-17.10-server/","summary":"原文: https://websiteforstudents.com/configuring-static-ips-ubuntu-17-10-servers/\nUbuntu 17.10 的时候网络配置方法完全改变了, 是否听说过 NetPlan?可能并没有吧~, NetPlan 是 Ubuntu 17.10 中引入的一种新的网络配置工具，用于管理网络设置.\nNetPlan 的配置文件是 YAML 格式的, 所以配置起来也不算麻烦~\nNetPlan 取代了以前在 /etc/network/interfaces 以前用来配置Ubuntu网络接口的文件. 现在你必须使用 /etc/netplan/*.yaml 来配置\n以下是简短的例子教你使用 NetPlan 来配置 Ubuntu 的静态网络.\n新的配置文件目录在 /etc/netplan 文件夹中, 使用名为 01-netcfg.yaml 的文件作为第一的配置文件. 一下是 DHCP 的默认配置.\n# This file describes the network interfaces available on your system # For more information, see netplan(5). network: version: 2 renderer: networkd ethernets: ens33: dhcp4: yes dhcp6: yes 如果需要应用, 就执行以下命令.\nsudo netplan apply 配置静态IP # This file describes the network interfaces available on your system # For more information, see netplan(5).","title":"[译] 在Ubuntu 17.10服务器上配置静态IP地址"},{"content":"使用这种实现自动部署 hexo 必须有台自己的服务器, 如果没有的话我也没办法~~\n原理 我实现的原理其实很简单. 当 source 被提交后, 触发 webhook 然后通过执行 bash script 自动进行编译部署\n实现 给 hexo 准备个仓库, 例: github.com/xxxx/hexo-source, 如果你有私有仓库 如 gogs gitlib 等都可以\n在 hexo 的根目录创建一个 deploy.sh 的脚本\n#/bin/bash set -ev export TZ=\u0026#39;Asia/Shanghai\u0026#39; npm install hexo-cli -g npm install hexo g -d 制作 node-caddy 的 docker, 当然也可以使用我已经写好的. yakumioto/node-caddy, 并编写 Caddyfile, 因为我使用的是自己部署的 Gogs 所以引用了 key\n:80 { gzip git { repo git@git.mioto.me:yakumioto/mioto.me.git branch master key /root/.ssh/id_rsa hook /webhook miotoyaku then bash ./deploy.sh } } docker-compose.yaml\nci-blog: image: yakumioto/node-caddy:latest restart: always ports: - \u0026#34;8777:80\u0026#34; volumes: - ~/.ssh:/root/.ssh - ./configs/caddy/Caddyfile.ci:/etc/Caddyfile - ./configs/caddy/.caddy:/root/.caddy - ../volumes/caddy/ci-blog:/srv 到这里基本就算完成了\n","permalink":"https://mioto.me/posts/automated-deployment-of-hexo-using-docker/","summary":"使用这种实现自动部署 hexo 必须有台自己的服务器, 如果没有的话我也没办法~~\n原理 我实现的原理其实很简单. 当 source 被提交后, 触发 webhook 然后通过执行 bash script 自动进行编译部署\n实现 给 hexo 准备个仓库, 例: github.com/xxxx/hexo-source, 如果你有私有仓库 如 gogs gitlib 等都可以\n在 hexo 的根目录创建一个 deploy.sh 的脚本\n#/bin/bash set -ev export TZ=\u0026#39;Asia/Shanghai\u0026#39; npm install hexo-cli -g npm install hexo g -d 制作 node-caddy 的 docker, 当然也可以使用我已经写好的. yakumioto/node-caddy, 并编写 Caddyfile, 因为我使用的是自己部署的 Gogs 所以引用了 key\n:80 { gzip git { repo git@git.mioto.me:yakumioto/mioto.me.git branch master key /root/.ssh/id_rsa hook /webhook miotoyaku then bash .","title":"使用docker自动部署hexo"},{"content":"文件大于 4GB 以下方法一定行不通, 32位操作系统 最大的寻址空间就是 4GB\npackage main import ( \u0026#34;crypto/sha1\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;io/ioutil\u0026#34; \u0026#34;log\u0026#34; ) func main() { bytes, err := ioutil.ReadFile(\u0026#34;file.txt\u0026#34;) if err != nil { log.Fatal(err) } h := sha1.New() h.Write(bytes) fmt.Printf(\u0026#34;% x\u0026#34;, h.Sum(nil)) } 以下方法可以算出大于 4GB 文件的 sha1, 但是如果直接表面理解代码, 给人的感觉是无法运行的\nio.Copy(h, f) 这里给人的感觉也是一次性读取文件到 h 变量中, \u0026ldquo;给人一种把 整个文件读取到内存的感觉\u0026rdquo;\npackage main import ( \u0026#34;crypto/sha1\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; \u0026#34;log\u0026#34; \u0026#34;os\u0026#34; ) func main() { f, err := os.Open(\u0026#34;file.txt\u0026#34;) if err != nil { log.Fatal(err) } defer f.Close() h := sha1.New() if _, err := io.Copy(h, f); err != nil { log.Fatal(err) } fmt.Printf(\u0026#34;% x\u0026#34;, h.Sum(nil)) } 详解 跟踪代码 sha1.New() 找到 sha1 的 Write 方法实现\nio.Copy(h, f) 会使用这个 Write 方法\nfunc (d *digest) Write(p []byte) (nn int, err error) { nn = len(p) d.len += uint64(nn) // 这里 d.nx 大于 0 的时候 进入进行处理数据 if d.nx \u0026gt; 0 { n := copy(d.x[d.nx:], p) d.nx += n if d.nx == chunk { // 处理. \u0026#39;具体不知道怎么实现的.. 没研究过\u0026#39; block(d, d.x[:]) // 但是这里处理完毕后会 清空 d.nx // 所以这里的 Write 函数其实已经在处理 sha1 了 // 并没有多少实际的内存占用 d.nx = 0 } p = p[n:] } if len(p) \u0026gt;= chunk { n := len(p) \u0026amp;^ (chunk - 1) block(d, p[:n]) p = p[n:] } if len(p) \u0026gt; 0 { d.nx = copy(d.x[:], p) } return } ","permalink":"https://mioto.me/posts/go-the-problem-of-finding-hash-in-32-bit-system/","summary":"文件大于 4GB 以下方法一定行不通, 32位操作系统 最大的寻址空间就是 4GB\npackage main import ( \u0026#34;crypto/sha1\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;io/ioutil\u0026#34; \u0026#34;log\u0026#34; ) func main() { bytes, err := ioutil.ReadFile(\u0026#34;file.txt\u0026#34;) if err != nil { log.Fatal(err) } h := sha1.New() h.Write(bytes) fmt.Printf(\u0026#34;% x\u0026#34;, h.Sum(nil)) } 以下方法可以算出大于 4GB 文件的 sha1, 但是如果直接表面理解代码, 给人的感觉是无法运行的\nio.Copy(h, f) 这里给人的感觉也是一次性读取文件到 h 变量中, \u0026ldquo;给人一种把 整个文件读取到内存的感觉\u0026rdquo;\npackage main import ( \u0026#34;crypto/sha1\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; \u0026#34;log\u0026#34; \u0026#34;os\u0026#34; ) func main() { f, err := os.Open(\u0026#34;file.txt\u0026#34;) if err != nil { log.","title":"Go32位系统计算大于4GB文件sha1遇到的问题"},{"content":"问题描述 我使用的是 gogs 作为自己私有的 git server. 正常的将 .ssh 目录直接导入到了 docker 中. 然后启动 docker 报错如下\nWarning: Permanently added the RSA host key for IP address \u0026#39;xx.xx.xx.xx\u0026#39; to the list of known hosts. 想必经常玩 vps 的人对这个提示并不陌生.. 我们每次是有 ssh 尝试连接一台我们从没有连接过服务器都会出现, 但是在 docker 中如何避免这个提示\n解决 其实就是要跳过这个验证, 网上一搜基本就能找到. 将 StrictHostKeyChecking 直接配置到 .ssh/config 中 就可以了\n# 文件 .ssh/config # 以 github.com 为例 自行替换成自己的 git server 地址 Host github.com StrictHostKeyChecking no 这样请求的时候就会跳过跳过验证直接 clone 代码了\n","permalink":"https://mioto.me/posts/docker-caddy-git-clone-private-repo-problem/","summary":"问题描述 我使用的是 gogs 作为自己私有的 git server. 正常的将 .ssh 目录直接导入到了 docker 中. 然后启动 docker 报错如下\nWarning: Permanently added the RSA host key for IP address \u0026#39;xx.xx.xx.xx\u0026#39; to the list of known hosts. 想必经常玩 vps 的人对这个提示并不陌生.. 我们每次是有 ssh 尝试连接一台我们从没有连接过服务器都会出现, 但是在 docker 中如何避免这个提示\n解决 其实就是要跳过这个验证, 网上一搜基本就能找到. 将 StrictHostKeyChecking 直接配置到 .ssh/config 中 就可以了\n# 文件 .ssh/config # 以 github.com 为例 自行替换成自己的 git server 地址 Host github.com StrictHostKeyChecking no 这样请求的时候就会跳过跳过验证直接 clone 代码了","title":"docker caddy 克隆私有仓库遇到的问题"},{"content":"negroni 用了很久很久了, 一直觉得很不错, 目前为止核心源码只有 175 行, 很适合用来学习 Go\n初始化 New 将传入的 handlers 构建成链表并保存的过程\ntype Handler interface { ServeHTTP(rw http.ResponseWriter, r *http.Request, next http.HandlerFunc) } // middleware 是个单向链表 type middleware struct { handler Handler next *middleware } // Negroni type Negroni struct { middleware middleware // 单向链表 handlers []Handler // 用于存储所有传入的 handler } // New 就是用来构建 middleware 链表的方法 func New(handlers ...Handler) *Negroni { return \u0026amp;Negroni{ handlers: handlers, middleware: build(handlers), } } 这里把传入的 handlers 保存并传给了 build 方法.\n构建链表 // voidMiddleware 链表的终点 func voidMiddleware() middleware { return middleware{ HandlerFunc(func(rw http.ResponseWriter, r *http.Request, next http.HandlerFunc) {}), \u0026amp;middleware{}, } } // build 递归构建 middleware, 最终返回一个完整的链表 func build(handlers []Handler) middleware { var next middleware switch { case len(handlers) == 0: return voidMiddleware() case len(handlers) \u0026gt; 1: next = build(handlers[1:]) default: next = voidMiddleware() } return middleware{handlers[0], \u0026amp;next} } Use实现 Use 本质上就是就是重新构建链表的过程\nUseFunc, UseHandler, UseHandlerFunc 本质上就是将 http.Handler 转换为 negroni.Handler 的过程\n// Use adds a Handler onto the middleware stack. Handlers are invoked in the order they are added to a Negroni. func (n *Negroni) Use(handler Handler) { if handler == nil { panic(\u0026#34;handler cannot be nil\u0026#34;) } n.handlers = append(n.handlers, handler) n.middleware = build(n.handlers) } // UseFunc adds a Negroni-style handler function onto the middleware stack. func (n *Negroni) UseFunc(handlerFunc func(rw http.ResponseWriter, r *http.Request, next http.HandlerFunc)) { n.Use(HandlerFunc(handlerFunc)) } // UseHandler adds a http.Handler onto the middleware stack. Handlers are invoked in the order they are added to a Negroni. func (n *Negroni) UseHandler(handler http.Handler) { n.Use(Wrap(handler)) } // UseHandlerFunc adds a http.HandlerFunc-style handler function onto the middleware stack. func (n *Negroni) UseHandlerFunc(handlerFunc func(rw http.ResponseWriter, r *http.Request)) { n.UseHandler(http.HandlerFunc(handlerFunc)) } func Wrap(handler http.Handler) Handler { return HandlerFunc(func(rw http.ResponseWriter, r *http.Request, next http.HandlerFunc) { handler.ServeHTTP(rw, r) next(rw, r) }) } Run 运行!!!\n最终调用了标准库中的 http.ListenAndServe, 证明 Negroni 实现了标准库的 http.Handler 接口, 形成了链表调用\n所以 handler 的顺序很重要, 一般 mux 路由, 都是在最后访入\n// middleware 实现了 `http.Handler` 接口 func (m middleware) ServeHTTP(rw http.ResponseWriter, r *http.Request) { m.handler.ServeHTTP(rw, r, m.next.ServeHTTP) } // Negroni 实现了 `http.Handler` 接口 func (n *Negroni) ServeHTTP(rw http.ResponseWriter, r *http.Request) { n.middleware.ServeHTTP(NewResponseWriter(rw), r) } func (n *Negroni) Run(addr ...string) { l := log.New(os.Stdout, \u0026#34;[negroni] \u0026#34;, 0) finalAddr := detectAddress(addr...) l.Printf(\u0026#34;listening on %s\u0026#34;, finalAddr) l.Fatal(http.ListenAndServe(finalAddr, n)) } ","permalink":"https://mioto.me/posts/negroni-source-code-analysis/","summary":"negroni 用了很久很久了, 一直觉得很不错, 目前为止核心源码只有 175 行, 很适合用来学习 Go\n初始化 New 将传入的 handlers 构建成链表并保存的过程\ntype Handler interface { ServeHTTP(rw http.ResponseWriter, r *http.Request, next http.HandlerFunc) } // middleware 是个单向链表 type middleware struct { handler Handler next *middleware } // Negroni type Negroni struct { middleware middleware // 单向链表 handlers []Handler // 用于存储所有传入的 handler } // New 就是用来构建 middleware 链表的方法 func New(handlers ...Handler) *Negroni { return \u0026amp;Negroni{ handlers: handlers, middleware: build(handlers), } } 这里把传入的 handlers 保存并传给了 build 方法.","title":"Negroni 源码分析"}]