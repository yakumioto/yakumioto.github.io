<!doctype html><html lang=zh dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>神经网络的数据基础 | 一只麻酱</title><meta name=keywords content="DeepLearning"><meta name=description content="神经网络的数据表示 张量(tensor) 是一个数据容器, 它包含的数据几乎总是数值数据, 因此它的数字容器, 张量是矩阵向任意维度的推广, 维度(dimension) 通常也叫作 轴(axis).
标量(scalar): 仅包含一个数字的张量叫作 标量(标量张量, 零维张量, 0D 张量), 一个 float32 或 float64 的数字就是一个标量张量.
x = numpy.array(12) 向量(vector): 数字组成的数组叫作 向量(一维张量, 1D 张量), 张量有一个轴.
x = numpy.array([12, 3, 6, 14, 7]) 矩阵(matrix): 向量组成的数组叫作 矩阵(二维张量, 2D 张量), 矩阵有两个轴(行, 列).
x = numpy.array([ [5, 78, 2, 34, 0], [6, 79, 3, 35, 1], [7, 80, 4, 36, 2]]) 3D张量与更高维的张量: 矩阵组成的数据叫作 3D 张量, 3D 张量组成的数组叫作 4D 张量, 以此类推."><meta name=author content="Mioto Yaku"><link rel=canonical href=https://mioto.me/posts/the-data-foundation-of-neural-networks/><link crossorigin=anonymous href=/assets/css/stylesheet.5cfc680b1eeaeef9efbced92d46c2a9e876b72ee14fba85846afc4cff9e6e6f8.css integrity="sha256-XPxoCx7q7vnvvO2S1Gwqnodrcu4U+6hYRq/Ez/nm5vg=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://mioto.me/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://mioto.me/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://mioto.me/favicon-32x32.png><link rel=apple-touch-icon href=https://mioto.me/apple-touch-icon.png><link rel=mask-icon href=https://mioto.me/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-102233768-1","auto"),ga("send","pageview"))</script><meta property="og:title" content="神经网络的数据基础"><meta property="og:description" content="神经网络的数据表示 张量(tensor) 是一个数据容器, 它包含的数据几乎总是数值数据, 因此它的数字容器, 张量是矩阵向任意维度的推广, 维度(dimension) 通常也叫作 轴(axis).
标量(scalar): 仅包含一个数字的张量叫作 标量(标量张量, 零维张量, 0D 张量), 一个 float32 或 float64 的数字就是一个标量张量.
x = numpy.array(12) 向量(vector): 数字组成的数组叫作 向量(一维张量, 1D 张量), 张量有一个轴.
x = numpy.array([12, 3, 6, 14, 7]) 矩阵(matrix): 向量组成的数组叫作 矩阵(二维张量, 2D 张量), 矩阵有两个轴(行, 列).
x = numpy.array([ [5, 78, 2, 34, 0], [6, 79, 3, 35, 1], [7, 80, 4, 36, 2]]) 3D张量与更高维的张量: 矩阵组成的数据叫作 3D 张量, 3D 张量组成的数组叫作 4D 张量, 以此类推."><meta property="og:type" content="article"><meta property="og:url" content="https://mioto.me/posts/the-data-foundation-of-neural-networks/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2020-09-06T00:00:00+00:00"><meta property="article:modified_time" content="2020-09-06T00:00:00+00:00"><meta property="og:site_name" content="一只麻酱"><meta name=twitter:card content="summary"><meta name=twitter:title content="神经网络的数据基础"><meta name=twitter:description content="神经网络的数据表示 张量(tensor) 是一个数据容器, 它包含的数据几乎总是数值数据, 因此它的数字容器, 张量是矩阵向任意维度的推广, 维度(dimension) 通常也叫作 轴(axis).
标量(scalar): 仅包含一个数字的张量叫作 标量(标量张量, 零维张量, 0D 张量), 一个 float32 或 float64 的数字就是一个标量张量.
x = numpy.array(12) 向量(vector): 数字组成的数组叫作 向量(一维张量, 1D 张量), 张量有一个轴.
x = numpy.array([12, 3, 6, 14, 7]) 矩阵(matrix): 向量组成的数组叫作 矩阵(二维张量, 2D 张量), 矩阵有两个轴(行, 列).
x = numpy.array([ [5, 78, 2, 34, 0], [6, 79, 3, 35, 1], [7, 80, 4, 36, 2]]) 3D张量与更高维的张量: 矩阵组成的数据叫作 3D 张量, 3D 张量组成的数组叫作 4D 张量, 以此类推."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://mioto.me/posts/"},{"@type":"ListItem","position":3,"name":"神经网络的数据基础","item":"https://mioto.me/posts/the-data-foundation-of-neural-networks/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"神经网络的数据基础","name":"神经网络的数据基础","description":"神经网络的数据表示 张量(tensor) 是一个数据容器, 它包含的数据几乎总是数值数据, 因此它的数字容器, 张量是矩阵向任意维度的推广, 维度(dimension) 通常也叫作 轴(axis).\n标量(scalar): 仅包含一个数字的张量叫作 标量(标量张量, 零维张量, 0D 张量), 一个 float32 或 float64 的数字就是一个标量张量.\nx = numpy.array(12) 向量(vector): 数字组成的数组叫作 向量(一维张量, 1D 张量), 张量有一个轴.\nx = numpy.array([12, 3, 6, 14, 7]) 矩阵(matrix): 向量组成的数组叫作 矩阵(二维张量, 2D 张量), 矩阵有两个轴(行, 列).\nx = numpy.array([ [5, 78, 2, 34, 0], [6, 79, 3, 35, 1], [7, 80, 4, 36, 2]]) 3D张量与更高维的张量: 矩阵组成的数据叫作 3D 张量, 3D 张量组成的数组叫作 4D 张量, 以此类推.","keywords":["DeepLearning"],"articleBody":"神经网络的数据表示 张量(tensor) 是一个数据容器, 它包含的数据几乎总是数值数据, 因此它的数字容器, 张量是矩阵向任意维度的推广, 维度(dimension) 通常也叫作 轴(axis).\n标量(scalar): 仅包含一个数字的张量叫作 标量(标量张量, 零维张量, 0D 张量), 一个 float32 或 float64 的数字就是一个标量张量.\nx = numpy.array(12) 向量(vector): 数字组成的数组叫作 向量(一维张量, 1D 张量), 张量有一个轴.\nx = numpy.array([12, 3, 6, 14, 7]) 矩阵(matrix): 向量组成的数组叫作 矩阵(二维张量, 2D 张量), 矩阵有两个轴(行, 列).\nx = numpy.array([ [5, 78, 2, 34, 0], [6, 79, 3, 35, 1], [7, 80, 4, 36, 2]]) 3D张量与更高维的张量: 矩阵组成的数据叫作 3D 张量, 3D 张量组成的数组叫作 4D 张量, 以此类推.\nx = numpy.array([ [[5, 78, 2, 34, 0], [6, 79, 3, 35, 1], [7, 80, 4, 36, 2]], [[5, 78, 2, 34, 0], [6, 79, 3, 35, 1], [7, 80, 4, 36, 2]], [[5, 78, 2, 34, 0], [6, 79, 3, 35, 1], [7, 80, 4, 36, 2]], ]) 深度学习处理的一般是 0D 到 4D 的张量, 但处理视频数据时可能会遇到 5D 张量.\n关键属性 张量是由三个关键属性来定义的.\n轴的个数(阶): 3D 张量有 3 个轴, 矩阵有 2 个轴, 这在 Numpy 等 Python 库中也叫作张量的 ndim. 形状: 这是一个整数元组, 表示张量沿每个轴的维度大小, 举例: 1.1 中的矩阵形状为 (3, 5), 3D 张量为 (3, 3, 5), 向量为 (5,) 标量为 (). 数据类型: 在 Python 库中通常叫作 dtype, 这是张量中包含数据的类型, 张量的类型可以是 uint8, float32, float64 等, 在极少情况下会遇到 字符(char) 张量.\n在 Numpy 中操作张量 # 选择第 10-100 个数字(不包括 100), 有以下三种写法 my_slice = train_images[10:100] my_slice = train_images[10:100, :, :] my_slice = train_images[10:100, 0:28, 0:28] # 取出所有图像右下角 14*14 的像素区域 my_slice = train_images[:, 14:, 14:] # 取出所有图像中间 14*14 的像素区域 my_slice = train_images[:, 7:-7, 7:-7] 数据批量的概念 深度学习中所有数据的张量的第一个 轴(0 轴) 都是 样本轴(samples axis), 深度学习模型不会同时处理整个数据集, 而是将数据分成 N 个小批量.\nbatch = train_images[:128] # 下一批 batch = train_images[128:256] # 然后是第 N 批 batch = train_images[128 * n: 128 * (n + 1)] 现实中的数据张量 在现实中, 需要处理的数据几乎是以下几类别之一.\n向量数据: 2D 张量, 形状为 (samples, features).\n人口统计数据集, 每个人包含 年龄, 收入, 100 000个人的数据集形状为 (100000[samples], 2[features]). 文本文档数据集, 每个文档表示为单词出现的个数 (字典中包含 20 000 个常见的单词), 每个文档可以被编码为包含 20 000 个值的向量中, 整个数据集包含 500 个文档, 因此可以存储在形状为 (500, 20000) 的 2D 张量中. 时间序列\u0026序列数据: 3D 张量, 形状为 (samples, timesteps, features).\n依照惯例, 时间始终是第二轴.\n股票价格数据集, 股票当前价格, 前一分钟最高价格, 前一分钟最低价格 可以看作为 4D 向量形状为 (3[features]), 整个交易日(390分钟)可以编码为一个 2D 张量形状为 (390[samples], 3[features]), 250天的数据集形状为 (250[samples], 390[timesteps], 3[features]). 推文数据集, 每个推文编码为 280 个字符组成的序列, 而每个字又来自与 20 000 个常用单词的字典中, 这种情况下每个字符可以被编码为 20000D 的向量中, 那么每个推文可以被编码为一个形状为 (280[samples], 20000[features]) 的 2D 向量中, 100 万推文的数据集则可以存储在一个形状为 (1000000[samples], 280[steps], 20000[features]) 的 3D 张量. 图像: 4D 张量, 形状为 (samples, height, width, channels) 或 (samples, channels, height, width).\n图片具有三个维度: 高度, 宽度, 和颜色深度 (虽然灰度图像 比如 MNIST 数字图像 只有一个颜色通道, 因此可以保存在 2D 张量中, 但按照惯例图像张量始终都是 3D 张量).\n灰度图像的颜色通道只有一维, 因此如果图像大小为 256*256 ,那么 128 张组成的批量可以保存在形状为 (128, 256, 256, 1) 的 4D 张量中. 彩色图像的颜色通道有 3 个 (R G B), 那么 128 张组成的批量可以保存在形状为 (128, 256, 256, 3) 的 4D 张量中. 图像张量的形状有两种约定: 通道在后(channels-last) 的约定 (在 TensorFlow 中使用) 和 通道在前(channels-first) 的约定 (在 Theano 中使用).\n视频: 5D 张量, 形状为 (samples, frames, height, width, channels) 或 (samples, frames, channels, height, width).\n一个以每秒 24 帧采样的 60 秒 YouTube 视频片段, 视频尺寸为 144*256 这个视频一共有 240 帧, 4 个这样的视频组成的批量将保存在形状为(4[samples], 240[frames], 144[height], 256[width], 3[channels]) 的 5D 张量中. ","wordCount":"439","inLanguage":"zh","datePublished":"2020-09-06T00:00:00Z","dateModified":"2020-09-06T00:00:00Z","author":{"@type":"Person","name":"Mioto Yaku"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://mioto.me/posts/the-data-foundation-of-neural-networks/"},"publisher":{"@type":"Organization","name":"一只麻酱","logo":{"@type":"ImageObject","url":"https://mioto.me/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://mioto.me accesskey=h title="一只麻酱 (Alt + H)">一只麻酱</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://mioto.me/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://mioto.me/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>神经网络的数据基础</h1><div class=post-meta><span title='2020-09-06 00:00:00 +0000 UTC'>九月 6, 2020</span>&nbsp;·&nbsp;3 分钟&nbsp;·&nbsp;Mioto Yaku</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>目录</span></summary><div class=inner><ul><li><a href=#%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%e7%9a%84%e6%95%b0%e6%8d%ae%e8%a1%a8%e7%a4%ba aria-label=神经网络的数据表示>神经网络的数据表示</a></li><li><a href=#%e5%85%b3%e9%94%ae%e5%b1%9e%e6%80%a7 aria-label=关键属性>关键属性</a></li><li><a href=#%e5%9c%a8-numpy-%e4%b8%ad%e6%93%8d%e4%bd%9c%e5%bc%a0%e9%87%8f aria-label="在 Numpy 中操作张量">在 Numpy 中操作张量</a></li><li><a href=#%e6%95%b0%e6%8d%ae%e6%89%b9%e9%87%8f%e7%9a%84%e6%a6%82%e5%bf%b5 aria-label=数据批量的概念>数据批量的概念</a></li><li><a href=#%e7%8e%b0%e5%ae%9e%e4%b8%ad%e7%9a%84%e6%95%b0%e6%8d%ae%e5%bc%a0%e9%87%8f aria-label=现实中的数据张量>现实中的数据张量</a></li></ul></div></details></div><div class=post-content><h2 id=神经网络的数据表示>神经网络的数据表示<a hidden class=anchor aria-hidden=true href=#神经网络的数据表示>#</a></h2><p>张量(tensor) 是一个数据容器, 它包含的数据几乎总是数值数据, 因此它的数字容器, 张量是矩阵向任意维度的推广, 维度(dimension) 通常也叫作 轴(axis).</p><p><strong>标量(scalar)</strong>: 仅包含一个数字的张量叫作 标量(标量张量, 零维张量, 0D 张量), 一个 float32 或 float64 的数字就是一个标量张量.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>x</span> <span class=o>=</span> <span class=n>numpy</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=mi>12</span><span class=p>)</span>
</span></span></code></pre></div><p><strong>向量(vector)</strong>: 数字组成的数组叫作 向量(一维张量, 1D 张量), 张量有一个轴.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>x</span> <span class=o>=</span> <span class=n>numpy</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=mi>12</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>7</span><span class=p>])</span>
</span></span></code></pre></div><p><strong>矩阵(matrix)</strong>: 向量组成的数组叫作 矩阵(二维张量, 2D 张量), 矩阵有两个轴(行, 列).</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>x</span> <span class=o>=</span> <span class=n>numpy</span><span class=o>.</span><span class=n>array</span><span class=p>([</span>
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>5</span><span class=p>,</span> <span class=mi>78</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>34</span><span class=p>,</span> <span class=mi>0</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>6</span><span class=p>,</span> <span class=mi>79</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>35</span><span class=p>,</span> <span class=mi>1</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>7</span><span class=p>,</span> <span class=mi>80</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>36</span><span class=p>,</span> <span class=mi>2</span><span class=p>]])</span>
</span></span></code></pre></div><p><strong>3D张量与更高维的张量</strong>: 矩阵组成的数据叫作 3D 张量, 3D 张量组成的数组叫作 4D 张量, 以此类推.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>x</span> <span class=o>=</span> <span class=n>numpy</span><span class=o>.</span><span class=n>array</span><span class=p>([</span>
</span></span><span class=line><span class=cl>    <span class=p>[[</span><span class=mi>5</span><span class=p>,</span> <span class=mi>78</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>34</span><span class=p>,</span> <span class=mi>0</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>6</span><span class=p>,</span> <span class=mi>79</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>35</span><span class=p>,</span> <span class=mi>1</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>7</span><span class=p>,</span> <span class=mi>80</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>36</span><span class=p>,</span> <span class=mi>2</span><span class=p>]],</span>
</span></span><span class=line><span class=cl>    <span class=p>[[</span><span class=mi>5</span><span class=p>,</span> <span class=mi>78</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>34</span><span class=p>,</span> <span class=mi>0</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>6</span><span class=p>,</span> <span class=mi>79</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>35</span><span class=p>,</span> <span class=mi>1</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>7</span><span class=p>,</span> <span class=mi>80</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>36</span><span class=p>,</span> <span class=mi>2</span><span class=p>]],</span>
</span></span><span class=line><span class=cl>    <span class=p>[[</span><span class=mi>5</span><span class=p>,</span> <span class=mi>78</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>34</span><span class=p>,</span> <span class=mi>0</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>6</span><span class=p>,</span> <span class=mi>79</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>35</span><span class=p>,</span> <span class=mi>1</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>7</span><span class=p>,</span> <span class=mi>80</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>36</span><span class=p>,</span> <span class=mi>2</span><span class=p>]],</span>
</span></span><span class=line><span class=cl>    <span class=p>])</span>
</span></span></code></pre></div><p>深度学习处理的一般是 0D 到 4D 的张量, 但处理视频数据时可能会遇到 5D 张量.</p><h2 id=关键属性>关键属性<a hidden class=anchor aria-hidden=true href=#关键属性>#</a></h2><p>张量是由三个关键属性来定义的.</p><p><strong>轴的个数(阶)</strong>: 3D 张量有 3 个轴, 矩阵有 2 个轴, 这在 Numpy 等 Python 库中也叫作张量的 ndim.
<strong>形状</strong>: 这是一个整数元组, 表示张量沿每个轴的维度大小, 举例: 1.1 中的矩阵形状为 (3, 5), 3D 张量为 (3, 3, 5), 向量为 (5,) 标量为 ().
<strong>数据类型</strong>: 在 Python 库中通常叫作 dtype, 这是张量中包含数据的类型, 张量的类型可以是 uint8, float32, float64 等, 在极少情况下会遇到 字符(char) 张量.</p><h2 id=在-numpy-中操作张量>在 Numpy 中操作张量<a hidden class=anchor aria-hidden=true href=#在-numpy-中操作张量>#</a></h2><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 选择第 10-100 个数字(不包括 100), 有以下三种写法</span>
</span></span><span class=line><span class=cl><span class=n>my_slice</span> <span class=o>=</span> <span class=n>train_images</span><span class=p>[</span><span class=mi>10</span><span class=p>:</span><span class=mi>100</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>my_slice</span> <span class=o>=</span> <span class=n>train_images</span><span class=p>[</span><span class=mi>10</span><span class=p>:</span><span class=mi>100</span><span class=p>,</span> <span class=p>:,</span> <span class=p>:]</span>
</span></span><span class=line><span class=cl><span class=n>my_slice</span> <span class=o>=</span> <span class=n>train_images</span><span class=p>[</span><span class=mi>10</span><span class=p>:</span><span class=mi>100</span><span class=p>,</span> <span class=mi>0</span><span class=p>:</span><span class=mi>28</span><span class=p>,</span> <span class=mi>0</span><span class=p>:</span><span class=mi>28</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=c1># 取出所有图像右下角 14*14 的像素区域</span>
</span></span><span class=line><span class=cl><span class=n>my_slice</span> <span class=o>=</span> <span class=n>train_images</span><span class=p>[:,</span> <span class=mi>14</span><span class=p>:,</span> <span class=mi>14</span><span class=p>:]</span>
</span></span><span class=line><span class=cl><span class=c1># 取出所有图像中间 14*14 的像素区域</span>
</span></span><span class=line><span class=cl><span class=n>my_slice</span> <span class=o>=</span> <span class=n>train_images</span><span class=p>[:,</span> <span class=mi>7</span><span class=p>:</span><span class=o>-</span><span class=mi>7</span><span class=p>,</span> <span class=mi>7</span><span class=p>:</span><span class=o>-</span><span class=mi>7</span><span class=p>]</span>
</span></span></code></pre></div><h2 id=数据批量的概念>数据批量的概念<a hidden class=anchor aria-hidden=true href=#数据批量的概念>#</a></h2><p>深度学习中所有数据的张量的第一个 轴(0 轴) 都是 样本轴(samples axis), 深度学习模型不会同时处理整个数据集, 而是将数据分成 N 个小批量.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>batch</span> <span class=o>=</span> <span class=n>train_images</span><span class=p>[:</span><span class=mi>128</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=c1># 下一批</span>
</span></span><span class=line><span class=cl><span class=n>batch</span> <span class=o>=</span> <span class=n>train_images</span><span class=p>[</span><span class=mi>128</span><span class=p>:</span><span class=mi>256</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=c1># 然后是第 N 批</span>
</span></span><span class=line><span class=cl><span class=n>batch</span> <span class=o>=</span> <span class=n>train_images</span><span class=p>[</span><span class=mi>128</span> <span class=o>*</span> <span class=n>n</span><span class=p>:</span> <span class=mi>128</span> <span class=o>*</span> <span class=p>(</span><span class=n>n</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)]</span>
</span></span></code></pre></div><h2 id=现实中的数据张量>现实中的数据张量<a hidden class=anchor aria-hidden=true href=#现实中的数据张量>#</a></h2><p>在现实中, 需要处理的数据几乎是以下几类别之一.</p><p><strong>向量数据</strong>: 2D 张量, 形状为 (samples, features).</p><ol><li>人口统计数据集, 每个人包含 年龄, 收入, 100 000个人的数据集形状为 (100000[samples], 2[features]).</li><li>文本文档数据集, 每个文档表示为单词出现的个数 (字典中包含 20 000 个常见的单词), 每个文档可以被编码为包含 20 000 个值的向量中, 整个数据集包含 500 个文档, 因此可以存储在形状为 (500, 20000) 的 2D 张量中.</li></ol><p><strong>时间序列&序列数据</strong>: 3D 张量, 形状为 (samples, timesteps, features).</p><p>依照惯例, 时间始终是第二轴.</p><ol><li>股票价格数据集, 股票当前价格, 前一分钟最高价格, 前一分钟最低价格 可以看作为 4D 向量形状为 (3[features]), 整个交易日(390分钟)可以编码为一个 2D 张量形状为 (390[samples], 3[features]), 250天的数据集形状为 (250[samples], 390[timesteps], 3[features]).</li><li>推文数据集, 每个推文编码为 280 个字符组成的序列, 而每个字又来自与 20 000 个常用单词的字典中, 这种情况下每个字符可以被编码为 20000D 的向量中, 那么每个推文可以被编码为一个形状为 (280[samples], 20000[features]) 的 2D 向量中, 100 万推文的数据集则可以存储在一个形状为 (1000000[samples], 280[steps], 20000[features]) 的 3D 张量.</li></ol><p><strong>图像</strong>: 4D 张量, 形状为 (samples, height, width, channels) 或 (samples, channels, height, width).</p><p>图片具有三个维度: 高度, 宽度, 和颜色深度 (虽然灰度图像 比如 MNIST 数字图像 只有一个颜色通道, 因此可以保存在 2D 张量中, 但按照惯例图像张量始终都是 3D 张量).</p><ol><li>灰度图像的颜色通道只有一维, 因此如果图像大小为 256*256 ,那么 128 张组成的批量可以保存在形状为 (128, 256, 256, 1) 的 4D 张量中.</li><li>彩色图像的颜色通道有 3 个 (R G B), 那么 128 张组成的批量可以保存在形状为 (128, 256, 256, 3) 的 4D 张量中.</li></ol><p>图像张量的形状有两种约定: <strong>通道在后(channels-last)</strong> 的约定 (在 TensorFlow 中使用) 和 <strong>通道在前(channels-first)</strong> 的约定 (在 Theano 中使用).</p><p><strong>视频</strong>: 5D 张量, 形状为 (samples, frames, height, width, channels) 或 (samples, frames, channels, height, width).</p><ol><li>一个以每秒 24 帧采样的 60 秒 YouTube 视频片段, 视频尺寸为 144*256 这个视频一共有 240 帧, 4 个这样的视频组成的批量将保存在形状为(4[samples], 240[frames], 144[height], 256[width], 3[channels]) 的 5D 张量中.</li></ol></div><footer class=post-footer><ul class=post-tags><li><a href=https://mioto.me/tags/deeplearning/>DeepLearning</a></li></ul></footer><div id=disqus_thread></div><script type=application/javascript>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//yakumioto.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></article></main><footer class=footer><span>&copy; 2023 <a href=https://mioto.me>一只麻酱</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>